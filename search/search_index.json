{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home \u00a4 # Create delightful software with Jupyter Notebooks ### Write, test, document, and distribute software packages and technical articles \u2014 all in one place, your notebook. Get started [ ](images/card.png) ## Trusted in industry ## Interactive programming without compromise ### Traditional programming environments throw away the result of your exploration in REPLs or notebooks. nbdev makes exploration an integral part of your workflow, all while promoting software engineering best practices. ![](images/nbs/images/docs.svg) Beautiful technical documentation and scientific articles with Quarto ![](images/nbs/images/testing.svg) Out-of-the-box continuous integration with GitHub Actions ![](images/nbs/images/packaging.svg) Publish code to PyPI and conda, and prose to GitHub Pages ![](images/nbs/images/vscode.svg) Two-way sync with your favourite IDEs ![](images/nbs/images/jupyter.svg) Write prose, code, and tests in notebooks \u2014 no context-switching ![](images/nbs/images/git.svg) Git-friendly notebooks: human-readable merge conflicts; no unwanted metadata ## Here\u2019s what experts are saying [![](images/nbs/images/chris-lattner.png)](images/nbs/images/chris-lattner.png) # Chris Lattner ## Inventor of Swift and LLVM ### I really do think \\[nbdev\\] is a huge step forward for programming environments. [![](images/nbs/images/fernando-p\u00e9rez.jpeg)](images/nbs/images/fernando-p\u00e9rez.jpeg) # Fernando P\u00e9rez ## Creator of Jupyter ### \\[nbdev\\] should be celebrated and used a lot more \u2014 I have kept a tab with your original nbdev blog post open for months in Chrome because of how often I refer to it and point others to this work. [![](images/nbs/images/david-berg.jpeg)](images/nbs/images/david-berg.jpeg) # David Berg ## Software Engineer, Netflix ### Prior to using nbdev, documentation was the most cumbersome aspect of our software development process\u2026 Using nbdev allows us to spend more time creating rich prose around the many code snippets guaranteeing the whole experience is robust. nbdev has turned what was once a chore into a natural extension of the notebook-based testing we were already doing. [![](images/nbs/images/erik-gaasedelen.jpeg)](images/nbs/images/erik-gaasedelen.jpeg) # Erik Gaasedelen ## Software Engineer, Lyft ### I use this in production at my company. It\u2019s an awesome tool\u2026 nbdev streamlines everything so I can write docs, tests, and code all in one place\u2026 The packaging is also really well thought out. From my point of view it is close to a Pareto improvement over traditional Python library development. [![](images/nbs/images/roxanna-pourzand.jpeg)](images/nbs/images/roxanna-pourzand.jpeg) # Roxanna Pourzand ## Product Manager, Transform ### We\u2019re so excited about using nbdev. Our product is technical so our resulting documentation includes a lot of code-based examples. Before nbdev, we had no way of maintaining our code examples and ensuring that it was up-to-date for both command inputs and outputs. It was all manual. With nbdev, we now have this under control in a sustainable way. Since we\u2019ve deployed these docs, we also had a situation where we were able to identify a bug in one of our interfaces, which we found by seeing the error that was output in the documentation. [![](images/nbs/images/hugo-bowne-anderson.jpeg)](images/nbs/images/hugo-bowne-anderson.jpeg) # Hugo Bowne-Anderson ## Head of Developer Relations, Outerbounds ### Nbdev has transformed the way we write documentation. Gone are the days of worrying about broken code examples when our API changes or due to human errors associated with copying & pasting code into markdown files. The authoring experience of nbdev is also powerful, allowing us to write prose and live code in a unified interface, which allows more experimentation with technical content. On top of this, nbdev allows us to include unit tests in our documentation which mitigates the burden of maintaining the docs over time. ## Get started in seconds Install nbdev","title":"Home"},{"location":"#home","text":"# Create delightful software with Jupyter Notebooks ### Write, test, document, and distribute software packages and technical articles \u2014 all in one place, your notebook. Get started [ ](images/card.png) ## Trusted in industry ## Interactive programming without compromise ### Traditional programming environments throw away the result of your exploration in REPLs or notebooks. nbdev makes exploration an integral part of your workflow, all while promoting software engineering best practices. ![](images/nbs/images/docs.svg) Beautiful technical documentation and scientific articles with Quarto ![](images/nbs/images/testing.svg) Out-of-the-box continuous integration with GitHub Actions ![](images/nbs/images/packaging.svg) Publish code to PyPI and conda, and prose to GitHub Pages ![](images/nbs/images/vscode.svg) Two-way sync with your favourite IDEs ![](images/nbs/images/jupyter.svg) Write prose, code, and tests in notebooks \u2014 no context-switching ![](images/nbs/images/git.svg) Git-friendly notebooks: human-readable merge conflicts; no unwanted metadata ## Here\u2019s what experts are saying [![](images/nbs/images/chris-lattner.png)](images/nbs/images/chris-lattner.png) # Chris Lattner ## Inventor of Swift and LLVM ### I really do think \\[nbdev\\] is a huge step forward for programming environments. [![](images/nbs/images/fernando-p\u00e9rez.jpeg)](images/nbs/images/fernando-p\u00e9rez.jpeg) # Fernando P\u00e9rez ## Creator of Jupyter ### \\[nbdev\\] should be celebrated and used a lot more \u2014 I have kept a tab with your original nbdev blog post open for months in Chrome because of how often I refer to it and point others to this work. [![](images/nbs/images/david-berg.jpeg)](images/nbs/images/david-berg.jpeg) # David Berg ## Software Engineer, Netflix ### Prior to using nbdev, documentation was the most cumbersome aspect of our software development process\u2026 Using nbdev allows us to spend more time creating rich prose around the many code snippets guaranteeing the whole experience is robust. nbdev has turned what was once a chore into a natural extension of the notebook-based testing we were already doing. [![](images/nbs/images/erik-gaasedelen.jpeg)](images/nbs/images/erik-gaasedelen.jpeg) # Erik Gaasedelen ## Software Engineer, Lyft ### I use this in production at my company. It\u2019s an awesome tool\u2026 nbdev streamlines everything so I can write docs, tests, and code all in one place\u2026 The packaging is also really well thought out. From my point of view it is close to a Pareto improvement over traditional Python library development. [![](images/nbs/images/roxanna-pourzand.jpeg)](images/nbs/images/roxanna-pourzand.jpeg) # Roxanna Pourzand ## Product Manager, Transform ### We\u2019re so excited about using nbdev. Our product is technical so our resulting documentation includes a lot of code-based examples. Before nbdev, we had no way of maintaining our code examples and ensuring that it was up-to-date for both command inputs and outputs. It was all manual. With nbdev, we now have this under control in a sustainable way. Since we\u2019ve deployed these docs, we also had a situation where we were able to identify a bug in one of our interfaces, which we found by seeing the error that was output in the documentation. [![](images/nbs/images/hugo-bowne-anderson.jpeg)](images/nbs/images/hugo-bowne-anderson.jpeg) # Hugo Bowne-Anderson ## Head of Developer Relations, Outerbounds ### Nbdev has transformed the way we write documentation. Gone are the days of worrying about broken code examples when our API changes or due to human errors associated with copying & pasting code into markdown files. The authoring experience of nbdev is also powerful, allowing us to write prose and live code in a unified interface, which allows more experimentation with technical content. On top of this, nbdev allows us to include unit tests in our documentation which mitigates the burden of maintaining the docs over time. ## Get started in seconds Install nbdev","title":"Home"},{"location":"CHANGELOG/","text":"Release notes \u00a4 2.3.9 \u00a4 New Features \u00a4 utility that creates a requirements.txt file from settings.ini ( #1202 ), thanks to @hamelsmu user-friendly error if py file has # %% comments with unexpected format ( #1211 ), thanks to @seeM add parameter for name to nb_export ( #1204 ), thanks to @hamelsmu ensure newline at end of _modidx.py ( #1186 ) Bugs Squashed \u00a4 end sidebar.yml with newline ( #1212 ), thanks to @seeM fix: incorrect regex pattern for setting output-file ( #1210 ), thanks to @seeM ensure newline at end of _modidx.py ( #1209 ), thanks to @seeM fix: nbdev_install_quarto may install and remove unrelated packages ( #1208 ), thanks to @seeM fix: key error if widgets is missing state ( #1207 ), thanks to @seeM - nbdev_install_quarto may install and remove unrelated packages ( #1182 ) Key error if widgets is missing state ( #1167 ) 2.3.8 \u00a4 New Features \u00a4 better error messages for nbdev_migrate ( #1177 ) experimental: Users can provide extra processors via the procs key in settings.ini ( #1157 ), thanks to @seeM enable Documentation Only Sites With nbdev ( + tutorial ) ( #1121 ), thanks to @hamelsmu support non-library projects ( #1119 ) throw a warning when imports and code are mixed in a cell ( #714 ) Bugs Squashed \u00a4 fix duplicated sections in the sidebar ( #1165 ), thanks to @seeM setting #| echo in a cell with show_doc causes a Quarto error ( #1163 ) fix copying of index assets ( #1143 ), thanks to @hamelsmu images in index.ipynb causing deployments issues ( #1140 ) clean takes forever on notebooks with large output ( #1132 ) nbdev_update includes folders starting with _ or . (e.g. .ipynb_checkpoints ) ( #1130 ), thanks to @seeM nbdev_new defaults bool parameters to False (e.g. put_version_in_init ) ( #1129 ), thanks to @seeM black_formatting setting is ignored ( #1122 ), thanks to @jmoralez nbdev_readme() fails on the second run for the notebook with support files (e.g. Fig image). ( #1106 ) nbdev_new fails with AttributeError: path_ ( #1063 ) fix #1041 ( #1049 ), thanks to @seeM 2.3.7 \u00a4 New Features \u00a4 Set recursive True by default ( #1117 ), thanks to @seeM exec_doc supports re-rendering widgets ( #1113 ), thanks to @seeM If users update widgets with the exec_doc directive, the widget \"view\" is updated (in the cell output), but the old widget \"state\" is used (in notebook metadata). This refreshes widget state using ipywidgets.Widget.get_manager_state . nbdev_new pins on major+minor version of nbdev-template ( #1091 ) nbdev_proc_nbs completes all steps to build _proc for publishing ( #1086 ) nbdev_new defaults nbs_path setting to 'nbs' ( #1083 ) Since all website files (quarto config, css, images, etc) are in nbs_path , the current default nbs_path='.' can clutter the root folder. nbdev_new queries branch from GitHub ( #1080 ) Bugs Squashed \u00a4 fix exporting patch_to which is decorated with staticmethod ( #1100 ), thanks to @seeM show_doc errors if a dependency in the nbdev group has a sub-dependency that isn't installed ( #1097 ) Running nbdev_migrate while upgrading removes nbdev2 compatible directives ( #1089 ) respect #|hide and #|include: false for showdoc ( #1079 ), thanks to @hamelsmu Export class to library but hide from documentation ( #1076 ) nbdev_clean removes widget state ( #1069 ) If widget state is present, it means the user had intentionally changed settings in their notebook editor. 2.3.4 \u00a4 New Features \u00a4 improve jekyll migration ( #1078 ), thanks to @hamelsmu Bugs Squashed \u00a4 skip _docs and _site in processing ( #1085 ) fix alias bug ( #1075 ), thanks to @hamelsmu 2.3.3 \u00a4 New Features \u00a4 auto-upgrade _quarto.yml for v1.2 ( #1073 ) Add Blog Tutorial ( #1061 ), thanks to @hamelsmu 2.3.2 \u00a4 New Features \u00a4 Support GitHub Enterprise ( #944 ) Bugs Squashed \u00a4 nbdev_new fails with AttributeError: path_ ( #1063 ) 2.3.1 \u00a4 Breaking Changes \u00a4 _quarto.yml no longer replaced with automatically generated version ( #1059 ) This was listed in 2.3.0 but wasn't actually included in the release Bugs Squashed \u00a4 fix nbdev_update ( #1058 ), thanks to @seeM fix bug in nbdev.maker.update_import which meant that nbdev_update didn't convert relative imports without None module (e.g from . import foo -> from pkg import foo ) fix FileNotFoundError in nbdev_update by passing the correct py module and corresponding notebook paths fix nbdev_update introducing whitespace changes to notebooks 2.3.0 \u00a4 Breaking Changes \u00a4 _quarto.yml no longer replaced with automatically generated version You can now customise your _quarto.yml file and it will not be overridden by nbdev This means that custom_host and custom_port in settings.ini are no longer supported -- use the standard quarto configuration instead Parallel ipynb filter ( #961 ) ipynb-filters in _quarto.yml is no longer needed or recommended. Instead, nbdev preprocesses your notebooks in parallel into a folder called _proc before calling quarto The new processing system generally results in speedups of around 10x compared to the previous approach Deprecate config_key in favor of get_config ( #856 ), thanks to @seeM New Features \u00a4 Setting put_version_in_init to make adding __version__ to __init__.py optional ( #1051 ), thanks to @MichaelJFishmanBA nbdev_new support for GitHub Enterprise ( #1043 ), thanks to @seeM Use GITHUB_TOKEN if present for nbdev.release ( #1025 ) Support non qmd py rendering scripts ( #1014 ) Use penultimate suffix for extension of rendered .py scripts ( #1010 ) Print nbdev_test cell errors to stderr instead of using logging.warning ( #1003 ) Make nb meta display_name consistent with name to simplify diffs ( #995 ) Windows support for clean nb ( #989 ), thanks to @jvanelteren Preview support for parallel filter ( #976 ) Settings.ini option for choosing preview listen port ( #967 ) Vscode extension for nbdev which cleans notebooks ( #952 ) Authenticate nbdev-template github API call ( #940 ) Add printit arg to nbdev_filter so it can be called with fname and still print to stdout ( #931 ), thanks to @seeM Run nbdev_readme in nbdev_new ( #919 ), thanks to @seeM Improve config documentation in read module ( #864 ), thanks to @seeM Simplify jupyter_hooks configuration ( #780 ), thanks to @seeM Bugs Squashed \u00a4 Class method doclinks target mod.html#method instead of mod.html#class.method ( #1046 ), thanks to @seeM \"Bad credentials\" error in nbdev_new if GitHub Enterprise GH_HOST and GITHUB_TOKEN are used ( #1038 ) Suppress UserWarning for unset GITHUB_TOKEN in nbdev_new ( #1028 ), thanks to @seeM nbdev.release uses cfg.lib_name instead of cfg.repo ( #1024 ), thanks to @seeM nbdev_test does not restore the original working directory ( #1004 ) clean_ids corrupts string outputs ( #794 ), thanks to @seeM 2.2.10 \u00a4 Bugs Squashed \u00a4 missing doc_path.name in _docs move ( #973 ) 2.2.9 \u00a4 New Features \u00a4 Experimental: pre-commit hooks ( #959 ), thanks to @seeM setup GitHub repo automatically ( #955 ), thanks to @hamelsmu Authenticate nbdev-template github API call ( #940 ) Support module level docstrings ( #473 ) Bugs Squashed \u00a4 show_doc includes parsed sections from numpy docstrings ( #964 ) AnnAssign object has no attribute 'targets' ( #953 ) Exported images not found in docs ( #951 ) fix #769 ( #946 ), thanks to @hamelsmu recursive in settings.ini ignored ( #942 ) Wrong source link when using @patch ( #939 ) Deploy Action fails with ModuleNotFoundError: No module named 'https://github' ( #936 ) Recursive mode doesn't seem to work when running nbdev_preview ( #935 ) Update All Python Scripts to nbs similar to nbdev_update_lib in v1 ( #769 ) 2.2.7 \u00a4 New Features \u00a4 Add printit arg to nbdev_filter so it can be called with fname and still print to stdout ( #931 ), thanks to @seeM Run nbdev_readme in nbdev_new ( #919 ), thanks to @seeM In nbdev_prepare() auto render README if needed ( #913 ) Filter keys stored in modidx settings ( #903 ) Regression: reintroduce [source] link ( #692 ) Bugs Squashed \u00a4 Deploy Action fails with ModuleNotFoundError: No module named 'https://github' ( #936 ) Correct cell index in nbdev_update ( #934 ), thanks to @hamelsmu Handle repo names with dashes and correct index page rendering with file attachments ( #930 ), thanks to @hamelsmu IPython.display.Image(embed=True) results in incorrect image reference in GitHub Pages ( #924 ) nbdev_preview not starting if there is a folder with no notebook in it ( #922 ) Fix images ( #918 ), thanks to @seeM nbdev_update creates a new cell, instead of updating the original code ( #775 ) 2.2.6 \u00a4 New Features \u00a4 Build _modidx.py on demand in order to git conflicts ( #911 ) Add source link to index ( #909 ) Order left navigation sections using numeric prefix ( #901 ) Automatic rendering of python files with frontmatter ( #895 ) Bugs Squashed \u00a4 Make sure #|exec_doc triggers an update even when there is no export or show_doc ( #906 ), thanks to @hamelsmu allow nbdev directives to work with cell magic ( #905 ), thanks to @hamelsmu 2.2.0 \u00a4 Breaking Changes \u00a4 Combine preprocs and postprocs into new Processor class ( #874 ) Rename nbdev.read to nbdev.config ( #879 ) Use H3 for functions and properties, instead of H4 ( #875 ) Remove nbflags directive ( #871 ) Deprecate config_key in favor of get_config ( #856 ), thanks to @seeM New Features \u00a4 Add simple qmd generation functions in nbdev.qmd ( #893 ) Add FrontmatterProc ( #890 ) Improvements to nbdev_new and nbdev_create_config ( #878 ), thanks to @seeM nbdev_create_config infers settings from git/GitHub, prompts for missing settings, and renders the settings file with commented sections nbdev_new uses nbdev_create_config instead of a file provided by nbdev-template , which means it'll benefit from future improvements to nbdev_create_config as well as always using latest defaults Add frontmatter bullet point processor ( #873 ) Allow specifying port for preview ( #872 ), thanks to @dleen nbdev_new renders notebooks with information from your config file ( #866 ), thanks to @seeM Improve config documentation in read module ( #864 ), thanks to @seeM Install quarto without root access ( #860 ) Explain more detail during quarto installation process ( #859 ) Automatically maintain __version__ in __init__.py ( #854 ) Prettify output for nbdev_test ( #849 ), thanks to @deven367 Ignore .ipynb_checkpoints folder in module dir ( #848 ), thanks to @dleen Escape Footnotes from Docments Table ( #847 ), thanks to @hamelsmu Include filename in nbdev_export warning when nbdev1 syntax is used ( #838 ), thanks to @seeM Show title if nbdev_filter errors ( #828 ), thanks to @hamelsmu Added \"topics\" to match GitHub's terminology ( #817 ), thanks to @tylere Accelerate quarto preview ( #748 ) Throw a warning when imports and code are mixed in a cell ( #714 ) Make conda release work for anyone ( #653 ) Bugs Squashed \u00a4 _all_ works for strings but not objects in py3.7 ( #870 ) show_doc title_level argument has no effect ( #869 ) show_doc sometimes does not show wrapped functions correctly ( #863 ) show_doc treats functions decorated with lru_cache as classes ( #862 ), thanks to @seeM Fix show_doc signature whitespace removal ( #855 ), thanks to @seeM nbdev_new doesn't infer anything if no gitconfig ( #846 ) show_doc paremeter default may render as footnote ( #796 ) Conda description is empty ( #745 ) 2.1.6 \u00a4 New Features \u00a4 add nbdev_conda to create and upload conda packages ( #850 ) 2.1.4 \u00a4 New Features \u00a4 Add custom_quarto_yml setting ( #842 ), thanks to @benoit-cty Display multiline docstrings ( #841 ) Include filename in nbdev_export warning when nbdev1 syntax is used ( #835 ) Streamline nbdev_new : outputs are now in color, you can pass --lib_name , and it calls nbdev_export ( #820 ), thanks to @seeM A command for uploading to the test pypi server ( #818 ), thanks to @tourdownunder Include notebook title in nbdev_preview error message ( #802 ) Migrate collapsible code cell directives ( #783 ), thanks to @hamelsmu Simplify jupyter_hooks configuration ( #780 ), thanks to @seeM Support nbdev_install_hooks in non-nbdev repos ( #779 ), thanks to @seeM Allow users to provide user-level settings in ~/.config/nbdev/settings.ini ( #778 ), thanks to @seeM Support nbdev_install_hooks in non-nbdev repos ( #777 ) Port doc() from nbdev1 ( #772 ) Make show_doc for function parameter defaults concise and deterministic ( #771 ) Clean id from text repr outputs to further avoid git merge conflicts ( #749 ) Add repo root to sys path on exec ( #735 ) Use frontmatter eval and showdoc for controlling notebook execution ( #734 ) Bugs Squashed \u00a4 |exports directive does not show source code in the docs ( #822 ) \u00a4 nbdev commands fail when doc_path contains whitespace ( #813 ), thanks to @mone27 show_doc html renderer is incorrectly formatted ( #808 ) show_doc cell output is incorrectly styled ( #807 ) links aren't rendered as code ( #795 ), thanks to @seeM clean_ids corrupts string outputs ( #794 ), thanks to @seeM quarto frontmatter is removed ( #789 ) nbdev_merge fails on git stash pop conflict ( #787 ), thanks to @seeM Hooks search Jupyter start directory instead of notebook directory for settings file ( #784 ), thanks to @dleen Allow for dash in Quarto directives ( #782 ), thanks to @hamelsmu Fix directive migration when there is no test flag ( #781 ), thanks to @hamelsmu nbdev_prepare throws BrokenProcessPool error on MacOS ( #731 ) settings.ini not inferred by nbdev_new on newly cloned repo on MacOS ( #710 ) 2.1.2 \u00a4 New Features \u00a4 use global defaults instead of respecifying each time ( #770 ), thanks to @seeM get_config works without a settings file ( #768 ), thanks to @seeM add site url ( #767 ), thanks to @hamelsmu add show_src to display rich source code ( #763 ), thanks to @seeM add support for #|exports ( #762 ) nbdev_merge prints info like git merge ( #753 ) helpers to convert fp front matter to quarto front matter ( #750 ), thanks to @hamelsmu Streamline default settings ( #747 ) Config keys (and their defaults) should all be documented in one place add user option to jupyter_hooks setting ( #738 ), thanks to @seeM Add appropriate output-file to existing frontmatter ( #728 ) Bugs Squashed \u00a4 nbdev_prepare sometimes throws BrokenProcessPool error on MacOS ( #731 ) Incorrect relative import from package root inside nested module ( #773 ) Jupyter hooks break in environments without nbdev installed ( #760 ) nbdev_fix breaks with empty ours patch ( #752 ) fix nbdev_merge during rebase; fix nbdev_fix nobackup default ( #737 ), thanks to @seeM non-notebooks do not have nbformat field ( #732 ), thanks to @dleen 2.1.1 \u00a4 New Features \u00a4 add tools from fastrelease to nbdev ( #733 ) Bugs Squashed \u00a4 fix nbdev_test with no --fname in non-nbdev repos ( #730 ), thanks to @seeM Auto-generated showdoc headers not in ToC ( #703 ) 2.1.0 \u00a4 Breaking Changes \u00a4 nbdev_sidebar now looks for .qmd files instead of .md files New Features \u00a4 automatically add output:asis for showdoc cells ( #726 ) accelerate nbdev_readme ( #715 ) deterministic show_doc and DocmentTbl repr ( #707 ), thanks to @seeM Bugs Squashed \u00a4 KeyError 'repo' when trying to create a new nbdev project with nbdev_new ( #720 ) show_doc ends the details column at any | character ( #712 ) only add to .gitattributes if missing ( #706 ), thanks to @seeM 2.0.7 \u00a4 New Features \u00a4 git merge hooks: automatically resolve conflicts and render markers as separate cells ( #704 ), thanks to @seeM Allow clean to keep some metadata keys ( #672 ), thanks to @dleen enable mac terminal install instead of visual installer ( #705 ), thanks to @hamelsmu Conditional content for markdown vs HTML for README ( #694 ), thanks to @hamelsmu Export a single module ( #652 ) Bugs Squashed \u00a4 Re-enable Mac CI #425 ) 2.0.6 \u00a4 New Features \u00a4 new jupyter save hook to clean NBs ( #697 ), thanks to @seeM new directive exec_doc to auto-exec cell when building docs ( #699 ) automatically escape YAML strings for title and description in frontmatter ( #691 ) add unbump param to nbdev_bump_version ( #689 ) install ghapi automatically ( #690 ) 2.0.5 \u00a4 New Features \u00a4 add nbdev_readme ( #688 ) 2.0.4 \u00a4 New Features \u00a4 add readme_nb config option ( #668 ) Bugs Squashed \u00a4 exporti cells can cause showdocs exec to fail ( #679 ) missing .html suffix in links ( #674 ) Add early return ( #670 ), thanks to @dleen 2.0.0 \u00a4 From-scratch rewrite of nbdev! nbdev now uses Quarto to create beautiful and full-featured websites nbdev2 is much faster than previous versions Note that you should run nbdev_migrate_directives after upgrading to use the new comment directive format (e.g #| export instead of #export ) 1.2.11 \u00a4 New Features \u00a4 support py310 style union annotations ( #636 ), thanks to @seeM Bugs Squashed \u00a4 fix show_doc for properties ( #635 ), thanks to @seeM nbdev_nb2md throws error when called in a notebook ( #381 ) 1.2.10 \u00a4 New Features \u00a4 Added webrick spec to Gemfile. ( #615 ), thanks to @MarkB2 Change doc() default for docments ( #611 ), thanks to @muellerzr Better checks for cls and self ( #596 ), thanks to @muellerzr Use the kernel defined in the kernelspec ( #594 ), thanks to @dleen Add in repr for delegates ( #589 ), thanks to @muellerzr Bugs Squashed \u00a4 Keep module in name when getting the \"qualname\" ( #606 ), thanks to @muellerzr Fix decimal bug ( #604 ), thanks to @muellerzr Use the kernel defined in the kernelspec ( #594 ), thanks to @dleen Misc bug fixes + tests ( #593 ), thanks to @muellerzr 1.2.9 \u00a4 New Features \u00a4 Implement show_doc for dataclass ( #622 ), thanks to @MarkB2 Bugs Squashed \u00a4 Fix show doc for object, class methods. ( #621 ), thanks to @v-ahuja Fix show doc for keywords. ( #619 ), thanks to @v-ahuja Including @dataclass breaks nbdev_build_lib ( #595 ) nbdev_nb2md throws error when called in a notebook ( #381 ) 1.2.7 \u00a4 Bugs Squashed \u00a4 Don't build NBs with no #default_exp 1.2.6 \u00a4 New Features \u00a4 nbdev_build_libs now works on a single file even without a settings.ini or any #default_exp cell Handle #| as directive prefix Bugs Squashed \u00a4 nbdev_nb2md throws error when called in a notebook ( #381 ) 1.2.5 \u00a4 New Features \u00a4 Update dependencies 1.2.3 \u00a4 Bugs Squashed \u00a4 Pin jinja2 due to deprecation bug in nbconvert 1.2.2 \u00a4 New Features \u00a4 Update dependencies 1.2.1 \u00a4 New Features \u00a4 Make sure docments have linking capability ( #585 ), thanks to @muellerzr better logging for duplicate titles ( #584 ), thanks to @hamelsmu Bugs Squashed \u00a4 Fix repr issue with show_doc ( #588 ), thanks to @muellerzr 1.2.0 \u00a4 upgrade nbconvert dep to v6 1.1.23 \u00a4 Bugs Squashed \u00a4 fix verbose flag 1.1.20 \u00a4 New Features \u00a4 skip symlinks in recursive glob ( #515 ) 1.1.15 \u00a4 Breaking Changes \u00a4 make recursive behavior for nbdev_build_docs consistent with nbdev_build_lib ( #467 ), thanks to @hamelsmu New Features \u00a4 Allow for a one-time only (potentially) .py -> .ipynb generation ( #369 ) Bugs Squashed \u00a4 Images with attachment: break export ( #501 ), thanks to @yacchin1205 Docs nav doesn't work on gitlab ( #488 ), thanks to @tcapelle clean up all instances of recursive ( #470 ), thanks to @hamelsmu After 'conda install -c fastai nbdev', error \" HTMLExporter object has no attribute template_path \" ( #431 ) 1.1.13 \u00a4 New Features \u00a4 support windows ( #392 ), thanks to @mszhanyi nbdev_new : get template from latest release asset ( #382 ), thanks to @hamelsmu Add more license options Bugs Squashed \u00a4 Fix recursive flag ( #433 ), thanks to @hamelsmu conda not installing nbdev properly on WSL2 ( #430 ) fix nb2md ( #424 ), thanks to @hamelsmu nbdev_build_lib seems to convert more notebooks than expected ( #423 ) fix default arg issue with nbdev_update_lib ( #416 ), thanks to @hamelsmu nbdev_update_lib errors out when fname not supplied ( #415 ) nbdev_new fails on calling the GitHub API without guidance ( #404 ) fix recurse issue ( #391 ), thanks to @hamelsmu nbdev_build_docs ----ModuleNotFoundError: No module named 'fastcore' ( #390 ) nbdev_test_nbs --fname broke in 1.1.7 ( #388 ) set recursive=True for docs ( #387 ), thanks to @hamelsmu fix url for getting branch ( #386 ), thanks to @hamelsmu nbdev_nb2md throws error when called in a notebook ( #381 ) 1.1.12 \u00a4 New Features \u00a4 nbdev_new should grab files from a release asset in nbdev_template ( #383 ) Use Jekyll Theme instead of vendoring all required files ( #379 ) Create relevant directories in docs/_data if do not already exist ( #377 ) 1.1.6 \u00a4 New Features \u00a4 Clean Google Colab metadata and line endings ( #364 ), thanks to @muellerzr add ability to find notebooks recursively ( #359 ), thanks to @hamelsmu Add bare flag to nbdev_build_lib ( #336 ) install git hooks in nbdev_new ( #308 ) nbdev_new now works on an existing cloned repo, instead of creating a new repo ( #307 ) Bugs Squashed \u00a4 nbdev_update_lib --fname notebook.ipynb crashes (while nbdev_update_lib works) ( #341 ) Copy new files only if they don't exist for nbdev_new ( #309 ) 1.1.3 \u00a4 New Features \u00a4 Place source code below heading on #exports ( #265 ), thanks to @hamelsmu 1.1.2 \u00a4 Bugs Squashed \u00a4 update fastcore requirement ( #281 ) 1.1.1 \u00a4 New Features \u00a4 Make CLI faster by removing unneeded imports and moving CLI commands to source modules ( #271 ) Move Config to fastcore ( #280 ) 1.1.0 \u00a4 Breaking Changes \u00a4 Remove magics ( #269 ) Removed callbacks ( #253 ), thanks to @pete88b move conda packager to fastrelease ( #252 ) New Features \u00a4 Place source code below heading on #exports ( #265 ), thanks to @hamelsmu always skip cells labeled \"skip\" in test ( #257 ) 1.0.17 \u00a4 Bugs Squashed \u00a4 restrict nbconvert<6 to avoid upgrade problems ( #249 ) 1.0.16 \u00a4 Bugs Squashed \u00a4 When generating docs, import cells are run even if not exported ( #248 ) 1.0.15 \u00a4 New Features \u00a4 add option to not exec nb for fastpages ( #244 ) Enable Codespaces for nbdev ( #243 ) Bugs Squashed \u00a4 Fix: correct notebook2html path operation for Windows. ( #239 ) 1.0.13 \u00a4 New Features \u00a4 remove numpy conda dep and update to fastcore 1.0.5 ( #241 ) Bugs Squashed \u00a4 allow nbdev imports when not in an nbdev project ( #238 ) 1.0.10 \u00a4 New Features \u00a4 Magic flags for tests ( #232 ) Add ability to have Colab badges on pages ( #210 ) Support for doc_path ( #235 ) Bugs Squashed \u00a4 Remove colab vendor specific tags which cause nbdev_build_docs to fail ( #207 ) hooks folder inside .git must be manually created before nbdev_install_git_hooks ( #230 ) updates to how backtick names are converted to doc links ( #218 ) Version 1.0.0 \u00a4 Initial release","title":"Releases"},{"location":"CHANGELOG/#release-notes","text":"","title":"Release notes"},{"location":"CHANGELOG/#239","text":"","title":"2.3.9"},{"location":"CHANGELOG/#new-features","text":"utility that creates a requirements.txt file from settings.ini ( #1202 ), thanks to @hamelsmu user-friendly error if py file has # %% comments with unexpected format ( #1211 ), thanks to @seeM add parameter for name to nb_export ( #1204 ), thanks to @hamelsmu ensure newline at end of _modidx.py ( #1186 )","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed","text":"end sidebar.yml with newline ( #1212 ), thanks to @seeM fix: incorrect regex pattern for setting output-file ( #1210 ), thanks to @seeM ensure newline at end of _modidx.py ( #1209 ), thanks to @seeM fix: nbdev_install_quarto may install and remove unrelated packages ( #1208 ), thanks to @seeM fix: key error if widgets is missing state ( #1207 ), thanks to @seeM - nbdev_install_quarto may install and remove unrelated packages ( #1182 ) Key error if widgets is missing state ( #1167 )","title":"Bugs Squashed"},{"location":"CHANGELOG/#238","text":"","title":"2.3.8"},{"location":"CHANGELOG/#new-features_1","text":"better error messages for nbdev_migrate ( #1177 ) experimental: Users can provide extra processors via the procs key in settings.ini ( #1157 ), thanks to @seeM enable Documentation Only Sites With nbdev ( + tutorial ) ( #1121 ), thanks to @hamelsmu support non-library projects ( #1119 ) throw a warning when imports and code are mixed in a cell ( #714 )","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_1","text":"fix duplicated sections in the sidebar ( #1165 ), thanks to @seeM setting #| echo in a cell with show_doc causes a Quarto error ( #1163 ) fix copying of index assets ( #1143 ), thanks to @hamelsmu images in index.ipynb causing deployments issues ( #1140 ) clean takes forever on notebooks with large output ( #1132 ) nbdev_update includes folders starting with _ or . (e.g. .ipynb_checkpoints ) ( #1130 ), thanks to @seeM nbdev_new defaults bool parameters to False (e.g. put_version_in_init ) ( #1129 ), thanks to @seeM black_formatting setting is ignored ( #1122 ), thanks to @jmoralez nbdev_readme() fails on the second run for the notebook with support files (e.g. Fig image). ( #1106 ) nbdev_new fails with AttributeError: path_ ( #1063 ) fix #1041 ( #1049 ), thanks to @seeM","title":"Bugs Squashed"},{"location":"CHANGELOG/#237","text":"","title":"2.3.7"},{"location":"CHANGELOG/#new-features_2","text":"Set recursive True by default ( #1117 ), thanks to @seeM exec_doc supports re-rendering widgets ( #1113 ), thanks to @seeM If users update widgets with the exec_doc directive, the widget \"view\" is updated (in the cell output), but the old widget \"state\" is used (in notebook metadata). This refreshes widget state using ipywidgets.Widget.get_manager_state . nbdev_new pins on major+minor version of nbdev-template ( #1091 ) nbdev_proc_nbs completes all steps to build _proc for publishing ( #1086 ) nbdev_new defaults nbs_path setting to 'nbs' ( #1083 ) Since all website files (quarto config, css, images, etc) are in nbs_path , the current default nbs_path='.' can clutter the root folder. nbdev_new queries branch from GitHub ( #1080 )","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_2","text":"fix exporting patch_to which is decorated with staticmethod ( #1100 ), thanks to @seeM show_doc errors if a dependency in the nbdev group has a sub-dependency that isn't installed ( #1097 ) Running nbdev_migrate while upgrading removes nbdev2 compatible directives ( #1089 ) respect #|hide and #|include: false for showdoc ( #1079 ), thanks to @hamelsmu Export class to library but hide from documentation ( #1076 ) nbdev_clean removes widget state ( #1069 ) If widget state is present, it means the user had intentionally changed settings in their notebook editor.","title":"Bugs Squashed"},{"location":"CHANGELOG/#234","text":"","title":"2.3.4"},{"location":"CHANGELOG/#new-features_3","text":"improve jekyll migration ( #1078 ), thanks to @hamelsmu","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_3","text":"skip _docs and _site in processing ( #1085 ) fix alias bug ( #1075 ), thanks to @hamelsmu","title":"Bugs Squashed"},{"location":"CHANGELOG/#233","text":"","title":"2.3.3"},{"location":"CHANGELOG/#new-features_4","text":"auto-upgrade _quarto.yml for v1.2 ( #1073 ) Add Blog Tutorial ( #1061 ), thanks to @hamelsmu","title":"New Features"},{"location":"CHANGELOG/#232","text":"","title":"2.3.2"},{"location":"CHANGELOG/#new-features_5","text":"Support GitHub Enterprise ( #944 )","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_4","text":"nbdev_new fails with AttributeError: path_ ( #1063 )","title":"Bugs Squashed"},{"location":"CHANGELOG/#231","text":"","title":"2.3.1"},{"location":"CHANGELOG/#breaking-changes","text":"_quarto.yml no longer replaced with automatically generated version ( #1059 ) This was listed in 2.3.0 but wasn't actually included in the release","title":"Breaking Changes"},{"location":"CHANGELOG/#bugs-squashed_5","text":"fix nbdev_update ( #1058 ), thanks to @seeM fix bug in nbdev.maker.update_import which meant that nbdev_update didn't convert relative imports without None module (e.g from . import foo -> from pkg import foo ) fix FileNotFoundError in nbdev_update by passing the correct py module and corresponding notebook paths fix nbdev_update introducing whitespace changes to notebooks","title":"Bugs Squashed"},{"location":"CHANGELOG/#230","text":"","title":"2.3.0"},{"location":"CHANGELOG/#breaking-changes_1","text":"_quarto.yml no longer replaced with automatically generated version You can now customise your _quarto.yml file and it will not be overridden by nbdev This means that custom_host and custom_port in settings.ini are no longer supported -- use the standard quarto configuration instead Parallel ipynb filter ( #961 ) ipynb-filters in _quarto.yml is no longer needed or recommended. Instead, nbdev preprocesses your notebooks in parallel into a folder called _proc before calling quarto The new processing system generally results in speedups of around 10x compared to the previous approach Deprecate config_key in favor of get_config ( #856 ), thanks to @seeM","title":"Breaking Changes"},{"location":"CHANGELOG/#new-features_6","text":"Setting put_version_in_init to make adding __version__ to __init__.py optional ( #1051 ), thanks to @MichaelJFishmanBA nbdev_new support for GitHub Enterprise ( #1043 ), thanks to @seeM Use GITHUB_TOKEN if present for nbdev.release ( #1025 ) Support non qmd py rendering scripts ( #1014 ) Use penultimate suffix for extension of rendered .py scripts ( #1010 ) Print nbdev_test cell errors to stderr instead of using logging.warning ( #1003 ) Make nb meta display_name consistent with name to simplify diffs ( #995 ) Windows support for clean nb ( #989 ), thanks to @jvanelteren Preview support for parallel filter ( #976 ) Settings.ini option for choosing preview listen port ( #967 ) Vscode extension for nbdev which cleans notebooks ( #952 ) Authenticate nbdev-template github API call ( #940 ) Add printit arg to nbdev_filter so it can be called with fname and still print to stdout ( #931 ), thanks to @seeM Run nbdev_readme in nbdev_new ( #919 ), thanks to @seeM Improve config documentation in read module ( #864 ), thanks to @seeM Simplify jupyter_hooks configuration ( #780 ), thanks to @seeM","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_6","text":"Class method doclinks target mod.html#method instead of mod.html#class.method ( #1046 ), thanks to @seeM \"Bad credentials\" error in nbdev_new if GitHub Enterprise GH_HOST and GITHUB_TOKEN are used ( #1038 ) Suppress UserWarning for unset GITHUB_TOKEN in nbdev_new ( #1028 ), thanks to @seeM nbdev.release uses cfg.lib_name instead of cfg.repo ( #1024 ), thanks to @seeM nbdev_test does not restore the original working directory ( #1004 ) clean_ids corrupts string outputs ( #794 ), thanks to @seeM","title":"Bugs Squashed"},{"location":"CHANGELOG/#2210","text":"","title":"2.2.10"},{"location":"CHANGELOG/#bugs-squashed_7","text":"missing doc_path.name in _docs move ( #973 )","title":"Bugs Squashed"},{"location":"CHANGELOG/#229","text":"","title":"2.2.9"},{"location":"CHANGELOG/#new-features_7","text":"Experimental: pre-commit hooks ( #959 ), thanks to @seeM setup GitHub repo automatically ( #955 ), thanks to @hamelsmu Authenticate nbdev-template github API call ( #940 ) Support module level docstrings ( #473 )","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_8","text":"show_doc includes parsed sections from numpy docstrings ( #964 ) AnnAssign object has no attribute 'targets' ( #953 ) Exported images not found in docs ( #951 ) fix #769 ( #946 ), thanks to @hamelsmu recursive in settings.ini ignored ( #942 ) Wrong source link when using @patch ( #939 ) Deploy Action fails with ModuleNotFoundError: No module named 'https://github' ( #936 ) Recursive mode doesn't seem to work when running nbdev_preview ( #935 ) Update All Python Scripts to nbs similar to nbdev_update_lib in v1 ( #769 )","title":"Bugs Squashed"},{"location":"CHANGELOG/#227","text":"","title":"2.2.7"},{"location":"CHANGELOG/#new-features_8","text":"Add printit arg to nbdev_filter so it can be called with fname and still print to stdout ( #931 ), thanks to @seeM Run nbdev_readme in nbdev_new ( #919 ), thanks to @seeM In nbdev_prepare() auto render README if needed ( #913 ) Filter keys stored in modidx settings ( #903 ) Regression: reintroduce [source] link ( #692 )","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_9","text":"Deploy Action fails with ModuleNotFoundError: No module named 'https://github' ( #936 ) Correct cell index in nbdev_update ( #934 ), thanks to @hamelsmu Handle repo names with dashes and correct index page rendering with file attachments ( #930 ), thanks to @hamelsmu IPython.display.Image(embed=True) results in incorrect image reference in GitHub Pages ( #924 ) nbdev_preview not starting if there is a folder with no notebook in it ( #922 ) Fix images ( #918 ), thanks to @seeM nbdev_update creates a new cell, instead of updating the original code ( #775 )","title":"Bugs Squashed"},{"location":"CHANGELOG/#226","text":"","title":"2.2.6"},{"location":"CHANGELOG/#new-features_9","text":"Build _modidx.py on demand in order to git conflicts ( #911 ) Add source link to index ( #909 ) Order left navigation sections using numeric prefix ( #901 ) Automatic rendering of python files with frontmatter ( #895 )","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_10","text":"Make sure #|exec_doc triggers an update even when there is no export or show_doc ( #906 ), thanks to @hamelsmu allow nbdev directives to work with cell magic ( #905 ), thanks to @hamelsmu","title":"Bugs Squashed"},{"location":"CHANGELOG/#220","text":"","title":"2.2.0"},{"location":"CHANGELOG/#breaking-changes_2","text":"Combine preprocs and postprocs into new Processor class ( #874 ) Rename nbdev.read to nbdev.config ( #879 ) Use H3 for functions and properties, instead of H4 ( #875 ) Remove nbflags directive ( #871 ) Deprecate config_key in favor of get_config ( #856 ), thanks to @seeM","title":"Breaking Changes"},{"location":"CHANGELOG/#new-features_10","text":"Add simple qmd generation functions in nbdev.qmd ( #893 ) Add FrontmatterProc ( #890 ) Improvements to nbdev_new and nbdev_create_config ( #878 ), thanks to @seeM nbdev_create_config infers settings from git/GitHub, prompts for missing settings, and renders the settings file with commented sections nbdev_new uses nbdev_create_config instead of a file provided by nbdev-template , which means it'll benefit from future improvements to nbdev_create_config as well as always using latest defaults Add frontmatter bullet point processor ( #873 ) Allow specifying port for preview ( #872 ), thanks to @dleen nbdev_new renders notebooks with information from your config file ( #866 ), thanks to @seeM Improve config documentation in read module ( #864 ), thanks to @seeM Install quarto without root access ( #860 ) Explain more detail during quarto installation process ( #859 ) Automatically maintain __version__ in __init__.py ( #854 ) Prettify output for nbdev_test ( #849 ), thanks to @deven367 Ignore .ipynb_checkpoints folder in module dir ( #848 ), thanks to @dleen Escape Footnotes from Docments Table ( #847 ), thanks to @hamelsmu Include filename in nbdev_export warning when nbdev1 syntax is used ( #838 ), thanks to @seeM Show title if nbdev_filter errors ( #828 ), thanks to @hamelsmu Added \"topics\" to match GitHub's terminology ( #817 ), thanks to @tylere Accelerate quarto preview ( #748 ) Throw a warning when imports and code are mixed in a cell ( #714 ) Make conda release work for anyone ( #653 )","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_11","text":"_all_ works for strings but not objects in py3.7 ( #870 ) show_doc title_level argument has no effect ( #869 ) show_doc sometimes does not show wrapped functions correctly ( #863 ) show_doc treats functions decorated with lru_cache as classes ( #862 ), thanks to @seeM Fix show_doc signature whitespace removal ( #855 ), thanks to @seeM nbdev_new doesn't infer anything if no gitconfig ( #846 ) show_doc paremeter default may render as footnote ( #796 ) Conda description is empty ( #745 )","title":"Bugs Squashed"},{"location":"CHANGELOG/#216","text":"","title":"2.1.6"},{"location":"CHANGELOG/#new-features_11","text":"add nbdev_conda to create and upload conda packages ( #850 )","title":"New Features"},{"location":"CHANGELOG/#214","text":"","title":"2.1.4"},{"location":"CHANGELOG/#new-features_12","text":"Add custom_quarto_yml setting ( #842 ), thanks to @benoit-cty Display multiline docstrings ( #841 ) Include filename in nbdev_export warning when nbdev1 syntax is used ( #835 ) Streamline nbdev_new : outputs are now in color, you can pass --lib_name , and it calls nbdev_export ( #820 ), thanks to @seeM A command for uploading to the test pypi server ( #818 ), thanks to @tourdownunder Include notebook title in nbdev_preview error message ( #802 ) Migrate collapsible code cell directives ( #783 ), thanks to @hamelsmu Simplify jupyter_hooks configuration ( #780 ), thanks to @seeM Support nbdev_install_hooks in non-nbdev repos ( #779 ), thanks to @seeM Allow users to provide user-level settings in ~/.config/nbdev/settings.ini ( #778 ), thanks to @seeM Support nbdev_install_hooks in non-nbdev repos ( #777 ) Port doc() from nbdev1 ( #772 ) Make show_doc for function parameter defaults concise and deterministic ( #771 ) Clean id from text repr outputs to further avoid git merge conflicts ( #749 ) Add repo root to sys path on exec ( #735 ) Use frontmatter eval and showdoc for controlling notebook execution ( #734 )","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_12","text":"","title":"Bugs Squashed"},{"location":"CHANGELOG/#exports-directive-does-not-show-source-code-in-the-docs-822","text":"nbdev commands fail when doc_path contains whitespace ( #813 ), thanks to @mone27 show_doc html renderer is incorrectly formatted ( #808 ) show_doc cell output is incorrectly styled ( #807 ) links aren't rendered as code ( #795 ), thanks to @seeM clean_ids corrupts string outputs ( #794 ), thanks to @seeM quarto frontmatter is removed ( #789 ) nbdev_merge fails on git stash pop conflict ( #787 ), thanks to @seeM Hooks search Jupyter start directory instead of notebook directory for settings file ( #784 ), thanks to @dleen Allow for dash in Quarto directives ( #782 ), thanks to @hamelsmu Fix directive migration when there is no test flag ( #781 ), thanks to @hamelsmu nbdev_prepare throws BrokenProcessPool error on MacOS ( #731 ) settings.ini not inferred by nbdev_new on newly cloned repo on MacOS ( #710 )","title":"|exports directive does not show source code in the docs (#822)"},{"location":"CHANGELOG/#212","text":"","title":"2.1.2"},{"location":"CHANGELOG/#new-features_13","text":"use global defaults instead of respecifying each time ( #770 ), thanks to @seeM get_config works without a settings file ( #768 ), thanks to @seeM add site url ( #767 ), thanks to @hamelsmu add show_src to display rich source code ( #763 ), thanks to @seeM add support for #|exports ( #762 ) nbdev_merge prints info like git merge ( #753 ) helpers to convert fp front matter to quarto front matter ( #750 ), thanks to @hamelsmu Streamline default settings ( #747 ) Config keys (and their defaults) should all be documented in one place add user option to jupyter_hooks setting ( #738 ), thanks to @seeM Add appropriate output-file to existing frontmatter ( #728 )","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_13","text":"nbdev_prepare sometimes throws BrokenProcessPool error on MacOS ( #731 ) Incorrect relative import from package root inside nested module ( #773 ) Jupyter hooks break in environments without nbdev installed ( #760 ) nbdev_fix breaks with empty ours patch ( #752 ) fix nbdev_merge during rebase; fix nbdev_fix nobackup default ( #737 ), thanks to @seeM non-notebooks do not have nbformat field ( #732 ), thanks to @dleen","title":"Bugs Squashed"},{"location":"CHANGELOG/#211","text":"","title":"2.1.1"},{"location":"CHANGELOG/#new-features_14","text":"add tools from fastrelease to nbdev ( #733 )","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_14","text":"fix nbdev_test with no --fname in non-nbdev repos ( #730 ), thanks to @seeM Auto-generated showdoc headers not in ToC ( #703 )","title":"Bugs Squashed"},{"location":"CHANGELOG/#210","text":"","title":"2.1.0"},{"location":"CHANGELOG/#breaking-changes_3","text":"nbdev_sidebar now looks for .qmd files instead of .md files","title":"Breaking Changes"},{"location":"CHANGELOG/#new-features_15","text":"automatically add output:asis for showdoc cells ( #726 ) accelerate nbdev_readme ( #715 ) deterministic show_doc and DocmentTbl repr ( #707 ), thanks to @seeM","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_15","text":"KeyError 'repo' when trying to create a new nbdev project with nbdev_new ( #720 ) show_doc ends the details column at any | character ( #712 ) only add to .gitattributes if missing ( #706 ), thanks to @seeM","title":"Bugs Squashed"},{"location":"CHANGELOG/#207","text":"","title":"2.0.7"},{"location":"CHANGELOG/#new-features_16","text":"git merge hooks: automatically resolve conflicts and render markers as separate cells ( #704 ), thanks to @seeM Allow clean to keep some metadata keys ( #672 ), thanks to @dleen enable mac terminal install instead of visual installer ( #705 ), thanks to @hamelsmu Conditional content for markdown vs HTML for README ( #694 ), thanks to @hamelsmu Export a single module ( #652 )","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_16","text":"Re-enable Mac CI #425 )","title":"Bugs Squashed"},{"location":"CHANGELOG/#206","text":"","title":"2.0.6"},{"location":"CHANGELOG/#new-features_17","text":"new jupyter save hook to clean NBs ( #697 ), thanks to @seeM new directive exec_doc to auto-exec cell when building docs ( #699 ) automatically escape YAML strings for title and description in frontmatter ( #691 ) add unbump param to nbdev_bump_version ( #689 ) install ghapi automatically ( #690 )","title":"New Features"},{"location":"CHANGELOG/#205","text":"","title":"2.0.5"},{"location":"CHANGELOG/#new-features_18","text":"add nbdev_readme ( #688 )","title":"New Features"},{"location":"CHANGELOG/#204","text":"","title":"2.0.4"},{"location":"CHANGELOG/#new-features_19","text":"add readme_nb config option ( #668 )","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_17","text":"exporti cells can cause showdocs exec to fail ( #679 ) missing .html suffix in links ( #674 ) Add early return ( #670 ), thanks to @dleen","title":"Bugs Squashed"},{"location":"CHANGELOG/#200","text":"From-scratch rewrite of nbdev! nbdev now uses Quarto to create beautiful and full-featured websites nbdev2 is much faster than previous versions Note that you should run nbdev_migrate_directives after upgrading to use the new comment directive format (e.g #| export instead of #export )","title":"2.0.0"},{"location":"CHANGELOG/#1211","text":"","title":"1.2.11"},{"location":"CHANGELOG/#new-features_20","text":"support py310 style union annotations ( #636 ), thanks to @seeM","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_18","text":"fix show_doc for properties ( #635 ), thanks to @seeM nbdev_nb2md throws error when called in a notebook ( #381 )","title":"Bugs Squashed"},{"location":"CHANGELOG/#1210","text":"","title":"1.2.10"},{"location":"CHANGELOG/#new-features_21","text":"Added webrick spec to Gemfile. ( #615 ), thanks to @MarkB2 Change doc() default for docments ( #611 ), thanks to @muellerzr Better checks for cls and self ( #596 ), thanks to @muellerzr Use the kernel defined in the kernelspec ( #594 ), thanks to @dleen Add in repr for delegates ( #589 ), thanks to @muellerzr","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_19","text":"Keep module in name when getting the \"qualname\" ( #606 ), thanks to @muellerzr Fix decimal bug ( #604 ), thanks to @muellerzr Use the kernel defined in the kernelspec ( #594 ), thanks to @dleen Misc bug fixes + tests ( #593 ), thanks to @muellerzr","title":"Bugs Squashed"},{"location":"CHANGELOG/#129","text":"","title":"1.2.9"},{"location":"CHANGELOG/#new-features_22","text":"Implement show_doc for dataclass ( #622 ), thanks to @MarkB2","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_20","text":"Fix show doc for object, class methods. ( #621 ), thanks to @v-ahuja Fix show doc for keywords. ( #619 ), thanks to @v-ahuja Including @dataclass breaks nbdev_build_lib ( #595 ) nbdev_nb2md throws error when called in a notebook ( #381 )","title":"Bugs Squashed"},{"location":"CHANGELOG/#127","text":"","title":"1.2.7"},{"location":"CHANGELOG/#bugs-squashed_21","text":"Don't build NBs with no #default_exp","title":"Bugs Squashed"},{"location":"CHANGELOG/#126","text":"","title":"1.2.6"},{"location":"CHANGELOG/#new-features_23","text":"nbdev_build_libs now works on a single file even without a settings.ini or any #default_exp cell Handle #| as directive prefix","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_22","text":"nbdev_nb2md throws error when called in a notebook ( #381 )","title":"Bugs Squashed"},{"location":"CHANGELOG/#125","text":"","title":"1.2.5"},{"location":"CHANGELOG/#new-features_24","text":"Update dependencies","title":"New Features"},{"location":"CHANGELOG/#123","text":"","title":"1.2.3"},{"location":"CHANGELOG/#bugs-squashed_23","text":"Pin jinja2 due to deprecation bug in nbconvert","title":"Bugs Squashed"},{"location":"CHANGELOG/#122","text":"","title":"1.2.2"},{"location":"CHANGELOG/#new-features_25","text":"Update dependencies","title":"New Features"},{"location":"CHANGELOG/#121","text":"","title":"1.2.1"},{"location":"CHANGELOG/#new-features_26","text":"Make sure docments have linking capability ( #585 ), thanks to @muellerzr better logging for duplicate titles ( #584 ), thanks to @hamelsmu","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_24","text":"Fix repr issue with show_doc ( #588 ), thanks to @muellerzr","title":"Bugs Squashed"},{"location":"CHANGELOG/#120","text":"upgrade nbconvert dep to v6","title":"1.2.0"},{"location":"CHANGELOG/#1123","text":"","title":"1.1.23"},{"location":"CHANGELOG/#bugs-squashed_25","text":"fix verbose flag","title":"Bugs Squashed"},{"location":"CHANGELOG/#1120","text":"","title":"1.1.20"},{"location":"CHANGELOG/#new-features_27","text":"skip symlinks in recursive glob ( #515 )","title":"New Features"},{"location":"CHANGELOG/#1115","text":"","title":"1.1.15"},{"location":"CHANGELOG/#breaking-changes_4","text":"make recursive behavior for nbdev_build_docs consistent with nbdev_build_lib ( #467 ), thanks to @hamelsmu","title":"Breaking Changes"},{"location":"CHANGELOG/#new-features_28","text":"Allow for a one-time only (potentially) .py -> .ipynb generation ( #369 )","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_26","text":"Images with attachment: break export ( #501 ), thanks to @yacchin1205 Docs nav doesn't work on gitlab ( #488 ), thanks to @tcapelle clean up all instances of recursive ( #470 ), thanks to @hamelsmu After 'conda install -c fastai nbdev', error \" HTMLExporter object has no attribute template_path \" ( #431 )","title":"Bugs Squashed"},{"location":"CHANGELOG/#1113","text":"","title":"1.1.13"},{"location":"CHANGELOG/#new-features_29","text":"support windows ( #392 ), thanks to @mszhanyi nbdev_new : get template from latest release asset ( #382 ), thanks to @hamelsmu Add more license options","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_27","text":"Fix recursive flag ( #433 ), thanks to @hamelsmu conda not installing nbdev properly on WSL2 ( #430 ) fix nb2md ( #424 ), thanks to @hamelsmu nbdev_build_lib seems to convert more notebooks than expected ( #423 ) fix default arg issue with nbdev_update_lib ( #416 ), thanks to @hamelsmu nbdev_update_lib errors out when fname not supplied ( #415 ) nbdev_new fails on calling the GitHub API without guidance ( #404 ) fix recurse issue ( #391 ), thanks to @hamelsmu nbdev_build_docs ----ModuleNotFoundError: No module named 'fastcore' ( #390 ) nbdev_test_nbs --fname broke in 1.1.7 ( #388 ) set recursive=True for docs ( #387 ), thanks to @hamelsmu fix url for getting branch ( #386 ), thanks to @hamelsmu nbdev_nb2md throws error when called in a notebook ( #381 )","title":"Bugs Squashed"},{"location":"CHANGELOG/#1112","text":"","title":"1.1.12"},{"location":"CHANGELOG/#new-features_30","text":"nbdev_new should grab files from a release asset in nbdev_template ( #383 ) Use Jekyll Theme instead of vendoring all required files ( #379 ) Create relevant directories in docs/_data if do not already exist ( #377 )","title":"New Features"},{"location":"CHANGELOG/#116","text":"","title":"1.1.6"},{"location":"CHANGELOG/#new-features_31","text":"Clean Google Colab metadata and line endings ( #364 ), thanks to @muellerzr add ability to find notebooks recursively ( #359 ), thanks to @hamelsmu Add bare flag to nbdev_build_lib ( #336 ) install git hooks in nbdev_new ( #308 ) nbdev_new now works on an existing cloned repo, instead of creating a new repo ( #307 )","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_28","text":"nbdev_update_lib --fname notebook.ipynb crashes (while nbdev_update_lib works) ( #341 ) Copy new files only if they don't exist for nbdev_new ( #309 )","title":"Bugs Squashed"},{"location":"CHANGELOG/#113","text":"","title":"1.1.3"},{"location":"CHANGELOG/#new-features_32","text":"Place source code below heading on #exports ( #265 ), thanks to @hamelsmu","title":"New Features"},{"location":"CHANGELOG/#112","text":"","title":"1.1.2"},{"location":"CHANGELOG/#bugs-squashed_29","text":"update fastcore requirement ( #281 )","title":"Bugs Squashed"},{"location":"CHANGELOG/#111","text":"","title":"1.1.1"},{"location":"CHANGELOG/#new-features_33","text":"Make CLI faster by removing unneeded imports and moving CLI commands to source modules ( #271 ) Move Config to fastcore ( #280 )","title":"New Features"},{"location":"CHANGELOG/#110","text":"","title":"1.1.0"},{"location":"CHANGELOG/#breaking-changes_5","text":"Remove magics ( #269 ) Removed callbacks ( #253 ), thanks to @pete88b move conda packager to fastrelease ( #252 )","title":"Breaking Changes"},{"location":"CHANGELOG/#new-features_34","text":"Place source code below heading on #exports ( #265 ), thanks to @hamelsmu always skip cells labeled \"skip\" in test ( #257 )","title":"New Features"},{"location":"CHANGELOG/#1017","text":"","title":"1.0.17"},{"location":"CHANGELOG/#bugs-squashed_30","text":"restrict nbconvert<6 to avoid upgrade problems ( #249 )","title":"Bugs Squashed"},{"location":"CHANGELOG/#1016","text":"","title":"1.0.16"},{"location":"CHANGELOG/#bugs-squashed_31","text":"When generating docs, import cells are run even if not exported ( #248 )","title":"Bugs Squashed"},{"location":"CHANGELOG/#1015","text":"","title":"1.0.15"},{"location":"CHANGELOG/#new-features_35","text":"add option to not exec nb for fastpages ( #244 ) Enable Codespaces for nbdev ( #243 )","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_32","text":"Fix: correct notebook2html path operation for Windows. ( #239 )","title":"Bugs Squashed"},{"location":"CHANGELOG/#1013","text":"","title":"1.0.13"},{"location":"CHANGELOG/#new-features_36","text":"remove numpy conda dep and update to fastcore 1.0.5 ( #241 )","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_33","text":"allow nbdev imports when not in an nbdev project ( #238 )","title":"Bugs Squashed"},{"location":"CHANGELOG/#1010","text":"","title":"1.0.10"},{"location":"CHANGELOG/#new-features_37","text":"Magic flags for tests ( #232 ) Add ability to have Colab badges on pages ( #210 ) Support for doc_path ( #235 )","title":"New Features"},{"location":"CHANGELOG/#bugs-squashed_34","text":"Remove colab vendor specific tags which cause nbdev_build_docs to fail ( #207 ) hooks folder inside .git must be manually created before nbdev_install_git_hooks ( #230 ) updates to how backtick names are converted to doc links ( #218 )","title":"Bugs Squashed"},{"location":"CHANGELOG/#version-100","text":"Initial release","title":"Version 1.0.0"},{"location":"SUMMARY/","text":"Getting Started nbdev1 Migration Tutorials Notebook Best Practices Blogging Documentation Only Sites Git-Friendly Jupyter Tutorials Modular nbdev Pre-Commit Hooks Qmd Documents RenderScripts End-To-End Walkthrough Explanations Settings.ini Directives Docs Website Explanations Why nbdev API clean cli config doclinks export frontmatter API maker merge migrate process processors qmd quarto release serve showdoc sync test API nbdev.clean nbdev.cli nbdev.config nbdev.doclinks nbdev.export nbdev.extract_attachments nbdev.frontmatter nbdev.imports nbdev.maker nbdev.merge nbdev.migrate nbdev.process nbdev.processors nbdev.qmd nbdev.quarto nbdev.release nbdev.serve nbdev.serve_drv nbdev.showdoc nbdev.sync nbdev.test CLI nbdev_create_config nbdev_update nbdev_export nbdev_fix nbdev_merge nbdev_trust nbdev_clean nbdev_install_hooks nbdev_filter nbdev_sidebar nbdev_test nbdev_new nbdev_migrate nbdev_install_quarto nbdev_install nbdev_docs nbdev_preview nbdev_prepare nbdev_readme nbdev_release_gh nbdev_release_git nbdev_changelog nbdev_pypi nbdev_conda nbdev_release_both nbdev_bump_version nbdev_proc_nbs nbdev_help Releases","title":"SUMMARY"},{"location":"getting_started/","text":"Getting Started \u00a4 ![CI](https://github.com/fastai/nbdev/actions/workflows/test.yaml/badge.svg) NB: This is nbdev v2, a major upgrade of nbdev. Whilst the differences to nbdev1 aren\u2019t huge, it does require some changes. The old version docs are at nbdev1.fast.ai . You can use version-pinning in settings.ini (i.e 'nbdev<2' ) to stop nbdev from upgrading. To upgrade, follow the migration tutorial . nbdev is a notebook-driven development platform. Simply write notebooks with lightweight markup and get high-quality documentation, tests, continuous integration, and packaging for free! nbdev makes debugging and refactoring your code much easier than in traditional programming environments since you always have live objects at your fingertips. nbdev also promotes software engineering best practices because tests and documentation are first class. Documentation is automatically generated using Quarto and hosted on GitHub Pages . Docs support LaTeX, are searchable, and are automatically hyperlinked (including out-of-the-box support for many packages via nbdev-index ) Publish packages to PyPI and conda as well as tools to simplify package releases. Python best practices are automatically followed, for example, only exported objects are included in __all__ Two-way sync between notebooks and plaintext source code allowing you to use your IDE for code navigation or quick edits Tests written as ordinary notebook cells are run in parallel with a single command Continuous integration out-of-the-box with GitHub Actions that run your tests and rebuild your docs Git-friendly notebooks with Jupyter/Git hooks that clean unwanted metadata and render merge conflicts in a human-readable format \u2026 and much more! Install \u00a4 nbdev works on macOS, Linux, and most Unix-style operating systems. It works on Windows under WSL, but not under cmd or Powershell. You can install nbdev with pip: pip install nbdev \u2026 or with conda (or mamba): conda install -c fastai nbdev Note that nbdev must be installed into the same Python environment that you use for both Jupyter and your project. How to use nbdev \u00a4 The best way to learn how to use nbdev is to complete either the written walkthrough or video walkthrough: Alternatively, there\u2019s a shortened version of the video walkthrough with coding sections sped up using the unsilence Python library \u2013 it\u2019s 27 minutes faster, but a bit harder to follow. You can also run nbdev_help from the terminal to see the full list of available commands: ! nbdev_help nbdev_bump_version Increment version in settings.ini by one nbdev_changelog Create a CHANGELOG.md file from closed and labeled GitHub issues nbdev_clean Clean all notebooks in `fname` to avoid merge conflicts nbdev_conda Create a `meta.yaml` file ready to be built into a package, and optionally build and upload it nbdev_create_config Create a config file. nbdev_deploy Deploy docs to GitHub Pages nbdev_docs Create Quarto docs and README.md nbdev_export Export notebooks in `path` to Python modules nbdev_filter A notebook filter for Quarto nbdev_fix Create working notebook from conflicted notebook `nbname` nbdev_help Show help for all console scripts nbdev_install Install Quarto and the current library nbdev_install_hooks Install Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks nbdev_install_quarto Install latest Quarto on macOS or Linux, prints instructions for Windows nbdev_merge Git merge driver for notebooks nbdev_migrate Convert all directives and callouts in `fname` from v1 to v2 nbdev_new Create an nbdev project. nbdev_prepare Export, test, and clean notebooks, and render README if needed nbdev_preview Preview docs locally nbdev_proc_nbs Process notebooks in `path` for docs rendering nbdev_pypi Create and upload Python package to PyPI nbdev_readme None nbdev_release_both Release both conda and PyPI packages nbdev_release_gh Calls `nbdev_changelog`, lets you edit the result, then pushes to git and calls `nbdev_release_git` nbdev_release_git Tag and create a release in GitHub for the current version nbdev_sidebar Create sidebar.yml nbdev_test Test in parallel notebooks matching `path`, passing along `flags` nbdev_trust Trust notebooks matching `fname` nbdev_update Propagate change in modules matching `fname` to notebooks that created them FAQ \u00a4 Q: What is the warning \u201cFound a cell containing mix of imports and computations. Please use separate cells\u201d? \u00a4 A: You should not have cells that are not exported, and contain a mix of import statements along with other code. For instance, don\u2019t do this in a single cell: import some_module some_module . something () Instead, split this into two cells, one which does import some_module , and the other which does some_module.something() . The reason for this is that when we create your documentation website, we ensure that all of the signatures for functions you document are up to date, by running the imports, exported cells, and show_doc functions in your notebooks. When you mix imports with other code, that other code will be run too, which can cause errors (or at least slowdowns) when creating your website. Q: Why is nbdev asking for root access? How do I install Quarto without root access? \u00a4 A: When you setup your first project, nbdev will attempt to automatically download and install Quarto for you. This is the program that we use to create your documentation website. Quarto\u2019s standard installation process requires root access, and nbdev will therefore ask for your root password during installation. For most people, this will work fine and everything will be handled automatically \u2013 if so, you can skip over the rest of this section, which talks about installing without root access. If you need to install Quarto without root access on Linux, first cd to wherever you want to store it, then download Quarto , and type: dpkg -x quarto*.deb . mv opt/quarto ./ rmdir opt mkdir -p ~/.local/bin ln -s \" $( pwd ) \" /quarto/bin/quarto ~/.local/bin To use this non-root version of Quarto, you\u2019ll need ~/.local/bin in your PATH environment variable . (Alternatively, change the ln -s step to place the symlink somewhere else in your path.) Q: Someone told me not to use notebooks for \u201cserious\u201d software development! \u00a4 A: Watch this video . Don\u2019t worry, we still get this too, despite having used nbdev for a wide range of \u201cvery serious\u201d software projects over the last three years, including deep learning libraries , API clients , Python language extensions , terminal user interfaces , and more! Contributing \u00a4 If you want to contribute to nbdev , be sure to review the contributions guidelines . This project adheres to fastai\u2019s code of conduct . By participating, you are expected to uphold this code. In general, we strive to abide by generally accepted best practices in open-source software development. Make sure you have nbdev \u2019s git hooks installed by running nbdev_install_hooks in the cloned repository. Copyright \u00a4 Copyright \u00a9 2019 onward fast.ai, Inc. Licensed under the Apache License, Version 2.0 (the \u201cLicense\u201d); you may not use this project\u2019s files except in compliance with the License. A copy of the License is provided in the LICENSE file in this repository.","title":"Getting Started"},{"location":"getting_started/#getting-started","text":"![CI](https://github.com/fastai/nbdev/actions/workflows/test.yaml/badge.svg) NB: This is nbdev v2, a major upgrade of nbdev. Whilst the differences to nbdev1 aren\u2019t huge, it does require some changes. The old version docs are at nbdev1.fast.ai . You can use version-pinning in settings.ini (i.e 'nbdev<2' ) to stop nbdev from upgrading. To upgrade, follow the migration tutorial . nbdev is a notebook-driven development platform. Simply write notebooks with lightweight markup and get high-quality documentation, tests, continuous integration, and packaging for free! nbdev makes debugging and refactoring your code much easier than in traditional programming environments since you always have live objects at your fingertips. nbdev also promotes software engineering best practices because tests and documentation are first class. Documentation is automatically generated using Quarto and hosted on GitHub Pages . Docs support LaTeX, are searchable, and are automatically hyperlinked (including out-of-the-box support for many packages via nbdev-index ) Publish packages to PyPI and conda as well as tools to simplify package releases. Python best practices are automatically followed, for example, only exported objects are included in __all__ Two-way sync between notebooks and plaintext source code allowing you to use your IDE for code navigation or quick edits Tests written as ordinary notebook cells are run in parallel with a single command Continuous integration out-of-the-box with GitHub Actions that run your tests and rebuild your docs Git-friendly notebooks with Jupyter/Git hooks that clean unwanted metadata and render merge conflicts in a human-readable format \u2026 and much more!","title":"Getting Started"},{"location":"getting_started/#install","text":"nbdev works on macOS, Linux, and most Unix-style operating systems. It works on Windows under WSL, but not under cmd or Powershell. You can install nbdev with pip: pip install nbdev \u2026 or with conda (or mamba): conda install -c fastai nbdev Note that nbdev must be installed into the same Python environment that you use for both Jupyter and your project.","title":"Install"},{"location":"getting_started/#how-to-use-nbdev","text":"The best way to learn how to use nbdev is to complete either the written walkthrough or video walkthrough: Alternatively, there\u2019s a shortened version of the video walkthrough with coding sections sped up using the unsilence Python library \u2013 it\u2019s 27 minutes faster, but a bit harder to follow. You can also run nbdev_help from the terminal to see the full list of available commands: ! nbdev_help nbdev_bump_version Increment version in settings.ini by one nbdev_changelog Create a CHANGELOG.md file from closed and labeled GitHub issues nbdev_clean Clean all notebooks in `fname` to avoid merge conflicts nbdev_conda Create a `meta.yaml` file ready to be built into a package, and optionally build and upload it nbdev_create_config Create a config file. nbdev_deploy Deploy docs to GitHub Pages nbdev_docs Create Quarto docs and README.md nbdev_export Export notebooks in `path` to Python modules nbdev_filter A notebook filter for Quarto nbdev_fix Create working notebook from conflicted notebook `nbname` nbdev_help Show help for all console scripts nbdev_install Install Quarto and the current library nbdev_install_hooks Install Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks nbdev_install_quarto Install latest Quarto on macOS or Linux, prints instructions for Windows nbdev_merge Git merge driver for notebooks nbdev_migrate Convert all directives and callouts in `fname` from v1 to v2 nbdev_new Create an nbdev project. nbdev_prepare Export, test, and clean notebooks, and render README if needed nbdev_preview Preview docs locally nbdev_proc_nbs Process notebooks in `path` for docs rendering nbdev_pypi Create and upload Python package to PyPI nbdev_readme None nbdev_release_both Release both conda and PyPI packages nbdev_release_gh Calls `nbdev_changelog`, lets you edit the result, then pushes to git and calls `nbdev_release_git` nbdev_release_git Tag and create a release in GitHub for the current version nbdev_sidebar Create sidebar.yml nbdev_test Test in parallel notebooks matching `path`, passing along `flags` nbdev_trust Trust notebooks matching `fname` nbdev_update Propagate change in modules matching `fname` to notebooks that created them","title":"How to use nbdev"},{"location":"getting_started/#faq","text":"","title":"FAQ"},{"location":"getting_started/#q-what-is-the-warning-found-a-cell-containing-mix-of-imports-and-computations-please-use-separate-cells","text":"A: You should not have cells that are not exported, and contain a mix of import statements along with other code. For instance, don\u2019t do this in a single cell: import some_module some_module . something () Instead, split this into two cells, one which does import some_module , and the other which does some_module.something() . The reason for this is that when we create your documentation website, we ensure that all of the signatures for functions you document are up to date, by running the imports, exported cells, and show_doc functions in your notebooks. When you mix imports with other code, that other code will be run too, which can cause errors (or at least slowdowns) when creating your website.","title":"Q: What is the warning \u201cFound a cell containing mix of imports and computations. Please use separate cells\u201d?"},{"location":"getting_started/#q-why-is-nbdev-asking-for-root-access-how-do-i-install-quarto-without-root-access","text":"A: When you setup your first project, nbdev will attempt to automatically download and install Quarto for you. This is the program that we use to create your documentation website. Quarto\u2019s standard installation process requires root access, and nbdev will therefore ask for your root password during installation. For most people, this will work fine and everything will be handled automatically \u2013 if so, you can skip over the rest of this section, which talks about installing without root access. If you need to install Quarto without root access on Linux, first cd to wherever you want to store it, then download Quarto , and type: dpkg -x quarto*.deb . mv opt/quarto ./ rmdir opt mkdir -p ~/.local/bin ln -s \" $( pwd ) \" /quarto/bin/quarto ~/.local/bin To use this non-root version of Quarto, you\u2019ll need ~/.local/bin in your PATH environment variable . (Alternatively, change the ln -s step to place the symlink somewhere else in your path.)","title":"Q: Why is nbdev asking for root access? How do I install Quarto without root access?"},{"location":"getting_started/#q-someone-told-me-not-to-use-notebooks-for-serious-software-development","text":"A: Watch this video . Don\u2019t worry, we still get this too, despite having used nbdev for a wide range of \u201cvery serious\u201d software projects over the last three years, including deep learning libraries , API clients , Python language extensions , terminal user interfaces , and more!","title":"Q: Someone told me not to use notebooks for \u201cserious\u201d software development!"},{"location":"getting_started/#contributing","text":"If you want to contribute to nbdev , be sure to review the contributions guidelines . This project adheres to fastai\u2019s code of conduct . By participating, you are expected to uphold this code. In general, we strive to abide by generally accepted best practices in open-source software development. Make sure you have nbdev \u2019s git hooks installed by running nbdev_install_hooks in the cloned repository.","title":"Contributing"},{"location":"getting_started/#copyright","text":"Copyright \u00a9 2019 onward fast.ai, Inc. Licensed under the Apache License, Version 2.0 (the \u201cLicense\u201d); you may not use this project\u2019s files except in compliance with the License. A copy of the License is provided in the LICENSE file in this repository.","title":"Copyright"},{"location":"migrating/","text":"nbdev1 Migration \u00a4 nbdev v2 is a new from-scratch rewrite of nbdev that\u2019s not backwards compatible. This page describes the changes you need to make to upgrade your nbdev v1 repo to work with the new version. The steps shown here should work on macOS or Linux (including Windows WSL) The biggest change is that nbdev2 uses Quarto to generate your website, whereas nbdev1 used nbconvert and jekyll. You can use all of Quarto\u2019s features directly in nbdev, so checkout the Quarto website to see all the amazing functionality it supports. Initial setup \u00a4 If you\u2019ve pinned nbdev in requirements.txt or settings.ini (e.g nbdev<2 ) remove the version pin. ( If you don\u2019t know what this means, then you don\u2019t have it, so you can ignore this step ). Install the latest version of nbdev by typing: pip install -U nbdev or: conda install -c fastai nbdev You may need to restart your terminal for the new commands to be visible to your shell. Upgrade directives \u00a4 nbdev has slightly changed how \u201cdirective comments\u201d like export and default_exp work, in order to align with how Quarto does things. Now, instead of just adding a # to the start to indicate a directive (e.g #export ), you now need to use #| (e.g #|export ). You can also optionally add a space (e.g #| export ). To automatically upgrade your directives to the new format, run in the root of your repo: nbdev_migrate You should now test that you can export your module by running: nbdev_export Note that nbdev_export replaces nbdev_build_lib . Run nbdev_export -h to see the options you can pass to it (normally you won\u2019t need to pass any). To see a list of all the commands available in nbdev2, run nbdev_help . Add and remove files \u00a4 First set a variable with the name of your library, by running the following (replacing \u201cyourlib\u201d with the name of your library\u2019s subdirectory) export LIBNAME=yourlib Now run the following: git rm Makefile git add $LIBNAME /_modidx.py rm -rf docs rm -f .gitconfig rm -f .git/hooks/post-merge rm -f setup.py curl -O https://raw.githubusercontent.com/fastai/nbdev-template/master/styles.css curl -O https://raw.githubusercontent.com/fastai/nbdev-template/master/setup.py cat >>.gitignore <<EOF _docs/ _proc/ EOF As you see above, we\u2019ve remove the Makefile \u2013 that\u2019s because all the things done by make before are now handled by nbdev commands directly. > **Note** > > All documentation related files should be included in your `nbs_path`, > and all paths should be relative to it. If you have set the `nbs_path` > in your `settings.ini` file, then copy your `styles.css` file inside > of your `nbs_path` folder. If you use GitHub Actions for continuous integration (CI) you can update this to use nbdev too as follows: rm -f .github/workflows/main.yml curl -O https://raw.githubusercontent.com/fastai/nbdev-template/master/.github/workflows/test.yaml curl -O https://raw.githubusercontent.com/fastai/nbdev-template/master/.github/workflows/deploy.yaml mv deploy.yaml test.yaml .github/workflows/ Update directive names \u00a4 A number of directives have changed names. We\u2019ll use perl to fix them. Run these lines in the root of your repo: find . -name '*.ipynb' -exec perl -pi -e 's/#\\|\\s*hide_input/#| echo: false/' {} + find . -name '*.ipynb' -exec perl -pi -e 's/#\\|\\s*hide_output/#| output: false/' {} + find . -name '*.ipynb' -exec perl -pi -e 's/#\\|\\s*skip/#| eval: false/' {} + find . -name '*.ipynb' -exec perl -pi -e 's/from nbdev.export import notebook2script/from nbdev import nbdev_export/' {} + find . -name '*.ipynb' -exec perl -pi -e 's/notebook2script/nbdev_export/' {} + These change the following directives to use functionality built into Quarto: hide_input \u2013> echo: false hide_output \u2013> output: false skip \u2013> eval: false They also update the new location and name of the nbdev_export python function. If you have any notebooks that you\u2019ve asked nbdev1 to skip (using all_slow ), you\u2019ll need to add a raw cell to the top of your notebook containing YAML frontmatter. The frontmatter needs to include skip_showdoc: true to avoid running cells when rendering docs, and skip_exec: true to skip this notebook when running tests. E.g to do both, you would add a raw cell (or update your existing frontmatter raw cell) to contain: --- skip_showdoc: true skip_exec: true --- Or you can also add these flags in a markdown cell, # title > description - skip_showdoc: true - skip_exec: true Edit Workflow Permissions \u00a4 Make sure your workflow permissions are set to \u201cRead and write permissions\u201d, which you can find in Settings \u2192 Actions \u2192 General \u2192 Workflow permissions: > **Important** > > Failure to set the correct permissions may result in an error message > like this: > > fatal: unable to access 'https://github.com/user/repo.git/': The requested URL returned error: 403 > Error: Action failed with \"The process '/usr/bin/git' failed with exit code 128\" Edit GitHub Pages Permissions \u00a4 At this point you will want to commit the files with the changes you made to GitHub. Wait for GitHub Actions to run and pass. A new branch in your repo will automatically be created called gh-pages . You want to enable GitHub Pages to work off this branch by configuring your Pages to settings to look like this: Access this screen under Settings \u2192 Pages Select \u201cDeploy from a branch\u201d in the drop down list for Source. Specify gh-pages as the branch Specify the /root as the location Click save Final steps \u00a4 You should now edit settings.ini , and change doc_path from docs to _docs , since that\u2019s where nbdev2 will build your website. If you use a custom domain for your website, you should move your CNAME file into the directory containing your notebooks. Before pushing to GitHub, check that your website looks OK locally by running: nbdev_preview Now prepare to commit to GitHub: nbdev_prepare You can now commit to GitHub as usual. Finally, update Github Pages by clicking on the Settings tab in your repo, then click Pages on the left side bar. Set \u201cSource\u201d to gh-pages branch and the /root folder.","title":"nbdev1 Migration"},{"location":"migrating/#nbdev1-migration","text":"nbdev v2 is a new from-scratch rewrite of nbdev that\u2019s not backwards compatible. This page describes the changes you need to make to upgrade your nbdev v1 repo to work with the new version. The steps shown here should work on macOS or Linux (including Windows WSL) The biggest change is that nbdev2 uses Quarto to generate your website, whereas nbdev1 used nbconvert and jekyll. You can use all of Quarto\u2019s features directly in nbdev, so checkout the Quarto website to see all the amazing functionality it supports.","title":"nbdev1 Migration"},{"location":"migrating/#initial-setup","text":"If you\u2019ve pinned nbdev in requirements.txt or settings.ini (e.g nbdev<2 ) remove the version pin. ( If you don\u2019t know what this means, then you don\u2019t have it, so you can ignore this step ). Install the latest version of nbdev by typing: pip install -U nbdev or: conda install -c fastai nbdev You may need to restart your terminal for the new commands to be visible to your shell.","title":"Initial setup"},{"location":"migrating/#upgrade-directives","text":"nbdev has slightly changed how \u201cdirective comments\u201d like export and default_exp work, in order to align with how Quarto does things. Now, instead of just adding a # to the start to indicate a directive (e.g #export ), you now need to use #| (e.g #|export ). You can also optionally add a space (e.g #| export ). To automatically upgrade your directives to the new format, run in the root of your repo: nbdev_migrate You should now test that you can export your module by running: nbdev_export Note that nbdev_export replaces nbdev_build_lib . Run nbdev_export -h to see the options you can pass to it (normally you won\u2019t need to pass any). To see a list of all the commands available in nbdev2, run nbdev_help .","title":"Upgrade directives"},{"location":"migrating/#add-and-remove-files","text":"First set a variable with the name of your library, by running the following (replacing \u201cyourlib\u201d with the name of your library\u2019s subdirectory) export LIBNAME=yourlib Now run the following: git rm Makefile git add $LIBNAME /_modidx.py rm -rf docs rm -f .gitconfig rm -f .git/hooks/post-merge rm -f setup.py curl -O https://raw.githubusercontent.com/fastai/nbdev-template/master/styles.css curl -O https://raw.githubusercontent.com/fastai/nbdev-template/master/setup.py cat >>.gitignore <<EOF _docs/ _proc/ EOF As you see above, we\u2019ve remove the Makefile \u2013 that\u2019s because all the things done by make before are now handled by nbdev commands directly. > **Note** > > All documentation related files should be included in your `nbs_path`, > and all paths should be relative to it. If you have set the `nbs_path` > in your `settings.ini` file, then copy your `styles.css` file inside > of your `nbs_path` folder. If you use GitHub Actions for continuous integration (CI) you can update this to use nbdev too as follows: rm -f .github/workflows/main.yml curl -O https://raw.githubusercontent.com/fastai/nbdev-template/master/.github/workflows/test.yaml curl -O https://raw.githubusercontent.com/fastai/nbdev-template/master/.github/workflows/deploy.yaml mv deploy.yaml test.yaml .github/workflows/","title":"Add and remove files"},{"location":"migrating/#update-directive-names","text":"A number of directives have changed names. We\u2019ll use perl to fix them. Run these lines in the root of your repo: find . -name '*.ipynb' -exec perl -pi -e 's/#\\|\\s*hide_input/#| echo: false/' {} + find . -name '*.ipynb' -exec perl -pi -e 's/#\\|\\s*hide_output/#| output: false/' {} + find . -name '*.ipynb' -exec perl -pi -e 's/#\\|\\s*skip/#| eval: false/' {} + find . -name '*.ipynb' -exec perl -pi -e 's/from nbdev.export import notebook2script/from nbdev import nbdev_export/' {} + find . -name '*.ipynb' -exec perl -pi -e 's/notebook2script/nbdev_export/' {} + These change the following directives to use functionality built into Quarto: hide_input \u2013> echo: false hide_output \u2013> output: false skip \u2013> eval: false They also update the new location and name of the nbdev_export python function. If you have any notebooks that you\u2019ve asked nbdev1 to skip (using all_slow ), you\u2019ll need to add a raw cell to the top of your notebook containing YAML frontmatter. The frontmatter needs to include skip_showdoc: true to avoid running cells when rendering docs, and skip_exec: true to skip this notebook when running tests. E.g to do both, you would add a raw cell (or update your existing frontmatter raw cell) to contain: --- skip_showdoc: true skip_exec: true --- Or you can also add these flags in a markdown cell, # title > description - skip_showdoc: true - skip_exec: true","title":"Update directive names"},{"location":"migrating/#edit-workflow-permissions","text":"Make sure your workflow permissions are set to \u201cRead and write permissions\u201d, which you can find in Settings \u2192 Actions \u2192 General \u2192 Workflow permissions: > **Important** > > Failure to set the correct permissions may result in an error message > like this: > > fatal: unable to access 'https://github.com/user/repo.git/': The requested URL returned error: 403 > Error: Action failed with \"The process '/usr/bin/git' failed with exit code 128\"","title":"Edit Workflow Permissions"},{"location":"migrating/#edit-github-pages-permissions","text":"At this point you will want to commit the files with the changes you made to GitHub. Wait for GitHub Actions to run and pass. A new branch in your repo will automatically be created called gh-pages . You want to enable GitHub Pages to work off this branch by configuring your Pages to settings to look like this: Access this screen under Settings \u2192 Pages Select \u201cDeploy from a branch\u201d in the drop down list for Source. Specify gh-pages as the branch Specify the /root as the location Click save","title":"Edit GitHub Pages Permissions"},{"location":"migrating/#final-steps","text":"You should now edit settings.ini , and change doc_path from docs to _docs , since that\u2019s where nbdev2 will build your website. If you use a custom domain for your website, you should move your CNAME file into the directory containing your notebooks. Before pushing to GitHub, check that your website looks OK locally by running: nbdev_preview Now prepare to commit to GitHub: nbdev_prepare You can now commit to GitHub as usual. Finally, update Github Pages by clicking on the Settings tab in your repo, then click Pages on the left side bar. Set \u201cSource\u201d to gh-pages branch and the /root folder.","title":"Final steps"},{"location":"api/","text":"API \u00a4 This section contains API details for each of nbdev\u2019s python submodules. This reference documentation is mainly useful for people looking to customise or build on top of nbdev, or wanting detailed information about how nbdev works.","title":"API"},{"location":"api/#api","text":"This section contains API details for each of nbdev\u2019s python submodules. This reference documentation is mainly useful for people looking to customise or build on top of nbdev, or wanting detailed information about how nbdev works.","title":"API"},{"location":"api/clean/","text":"clean \u00a4 To avoid pointless conflicts while working with jupyter notebooks (with different execution counts or cell metadata), it is recommended to clean the notebooks before committing anything (done automatically if you install the git hooks with nbdev_install_hooks ). The following functions are used to do that. Trust \u00a4 source nbdev_trust \u00a4 nbdev_trust (fname:str=None, force_all:bool=False) Trust notebooks matching fname Type Default Details fname str None A notebook name or glob to trust force_all bool False Also trust notebooks that haven\u2019t changed Clean \u00a4 source clean_nb \u00a4 clean_nb (nb, clear_all=False, allowed_metadata_keys:list=None, allowed_cell_metadata_keys:list=None, clean_ids=True) Clean nb from superfluous metadata Type Default Details nb The notebook to clean clear_all bool False Remove all cell metadata and cell outputs? allowed_metadata_keys list None Preserve the list of keys in the main notebook metadata allowed_cell_metadata_keys list None Preserve the list of keys in cell level metadata clean_ids bool True Remove ids from plaintext reprs? The test notebook has metadata in both the main metadata section and contains cell level metadata in the second cell: test_nb = read_nb ( '../../tests/metadata.ipynb' ) assert { 'meta' , 'jekyll' , 'my_extra_key' , 'my_removed_key' } <= test_nb . metadata . keys () assert { 'meta' , 'hide_input' , 'my_extra_cell_key' , 'my_removed_cell_key' } == test_nb . cells [ 1 ] . metadata . keys () After cleaning the notebook, all extra metadata is removed, only some keys are allowed by default: clean_nb ( test_nb ) assert { 'jekyll' , 'kernelspec' } == test_nb . metadata . keys () assert { 'hide_input' } == test_nb . cells [ 1 ] . metadata . keys () We can preserve some additional keys at the notebook or cell levels: test_nb = read_nb ( '../../tests/metadata.ipynb' ) clean_nb ( test_nb , allowed_metadata_keys = { 'my_extra_key' }, allowed_cell_metadata_keys = { 'my_extra_cell_key' }) assert { 'jekyll' , 'kernelspec' , 'my_extra_key' } == test_nb . metadata . keys () assert { 'hide_input' , 'my_extra_cell_key' } == test_nb . cells [ 1 ] . metadata . keys () Passing clear_all=True removes everything from the cell metadata: test_nb = read_nb ( '../../tests/metadata.ipynb' ) clean_nb ( test_nb , clear_all = True ) assert { 'jekyll' , 'kernelspec' } == test_nb . metadata . keys () test_eq ( test_nb . cells [ 1 ] . metadata , {}) Passing clean_ids=True removes id s from plaintext repr outputs, to avoid notebooks whose contents change on each run since they often lead to git merge conflicts. For example: <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FB4F8979690> becomes: <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28> source process_write \u00a4 process_write (warn_msg, proc_nb, f_in, f_out=None, disp=False) source nbdev_clean \u00a4 nbdev_clean (fname:str=None, clear_all:bool=False, disp:bool=False, stdin:bool=False) Clean all notebooks in fname to avoid merge conflicts Type Default Details fname str None A notebook name or glob to clean clear_all bool False Remove all cell metadata and cell outputs? disp bool False Print the cleaned outputs stdin bool False Read notebook from input stream By default ( fname left to None ), all the notebooks in lib_folder are cleaned. You can opt in to fully clean the notebook by removing every bit of metadata and the cell outputs by passing clear_all=True . If you want to keep some keys in the main notebook metadata you can set allowed_metadata_keys in settings.ini . Similarly for cell level metadata use: allowed_cell_metadata_keys . For example, to preserve both k1 and k2 at both the notebook and cell level adding the following in settings.ini : ... allowed_metadata_keys = k1 k2 allowed_cell_metadata_keys = k1 k2 ... source clean_jupyter \u00a4 clean_jupyter (path, model, **kwargs) Clean Jupyter model pre save to path This cleans notebooks on-save to avoid unnecessary merge conflicts. The easiest way to install it for both Jupyter Notebook and Lab is by running nbdev_install_hooks . It works by implementing a pre_save_hook from Jupyter\u2019s file save hook API . Hooks \u00a4 source nbdev_install_hooks \u00a4 nbdev_install_hooks () Install Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks See clean_jupyter and nbdev_merge for more about how each hook works.","title":"clean"},{"location":"api/clean/#clean","text":"To avoid pointless conflicts while working with jupyter notebooks (with different execution counts or cell metadata), it is recommended to clean the notebooks before committing anything (done automatically if you install the git hooks with nbdev_install_hooks ). The following functions are used to do that.","title":"clean"},{"location":"api/clean/#trust","text":"source","title":"Trust"},{"location":"api/clean/#nbdev_trust","text":"nbdev_trust (fname:str=None, force_all:bool=False) Trust notebooks matching fname Type Default Details fname str None A notebook name or glob to trust force_all bool False Also trust notebooks that haven\u2019t changed","title":"nbdev_trust"},{"location":"api/clean/#clean_1","text":"source","title":"Clean"},{"location":"api/clean/#clean_nb","text":"clean_nb (nb, clear_all=False, allowed_metadata_keys:list=None, allowed_cell_metadata_keys:list=None, clean_ids=True) Clean nb from superfluous metadata Type Default Details nb The notebook to clean clear_all bool False Remove all cell metadata and cell outputs? allowed_metadata_keys list None Preserve the list of keys in the main notebook metadata allowed_cell_metadata_keys list None Preserve the list of keys in cell level metadata clean_ids bool True Remove ids from plaintext reprs? The test notebook has metadata in both the main metadata section and contains cell level metadata in the second cell: test_nb = read_nb ( '../../tests/metadata.ipynb' ) assert { 'meta' , 'jekyll' , 'my_extra_key' , 'my_removed_key' } <= test_nb . metadata . keys () assert { 'meta' , 'hide_input' , 'my_extra_cell_key' , 'my_removed_cell_key' } == test_nb . cells [ 1 ] . metadata . keys () After cleaning the notebook, all extra metadata is removed, only some keys are allowed by default: clean_nb ( test_nb ) assert { 'jekyll' , 'kernelspec' } == test_nb . metadata . keys () assert { 'hide_input' } == test_nb . cells [ 1 ] . metadata . keys () We can preserve some additional keys at the notebook or cell levels: test_nb = read_nb ( '../../tests/metadata.ipynb' ) clean_nb ( test_nb , allowed_metadata_keys = { 'my_extra_key' }, allowed_cell_metadata_keys = { 'my_extra_cell_key' }) assert { 'jekyll' , 'kernelspec' , 'my_extra_key' } == test_nb . metadata . keys () assert { 'hide_input' , 'my_extra_cell_key' } == test_nb . cells [ 1 ] . metadata . keys () Passing clear_all=True removes everything from the cell metadata: test_nb = read_nb ( '../../tests/metadata.ipynb' ) clean_nb ( test_nb , clear_all = True ) assert { 'jekyll' , 'kernelspec' } == test_nb . metadata . keys () test_eq ( test_nb . cells [ 1 ] . metadata , {}) Passing clean_ids=True removes id s from plaintext repr outputs, to avoid notebooks whose contents change on each run since they often lead to git merge conflicts. For example: <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7FB4F8979690> becomes: <PIL.PngImagePlugin.PngImageFile image mode=L size=28x28> source","title":"clean_nb"},{"location":"api/clean/#process_write","text":"process_write (warn_msg, proc_nb, f_in, f_out=None, disp=False) source","title":"process_write"},{"location":"api/clean/#nbdev_clean","text":"nbdev_clean (fname:str=None, clear_all:bool=False, disp:bool=False, stdin:bool=False) Clean all notebooks in fname to avoid merge conflicts Type Default Details fname str None A notebook name or glob to clean clear_all bool False Remove all cell metadata and cell outputs? disp bool False Print the cleaned outputs stdin bool False Read notebook from input stream By default ( fname left to None ), all the notebooks in lib_folder are cleaned. You can opt in to fully clean the notebook by removing every bit of metadata and the cell outputs by passing clear_all=True . If you want to keep some keys in the main notebook metadata you can set allowed_metadata_keys in settings.ini . Similarly for cell level metadata use: allowed_cell_metadata_keys . For example, to preserve both k1 and k2 at both the notebook and cell level adding the following in settings.ini : ... allowed_metadata_keys = k1 k2 allowed_cell_metadata_keys = k1 k2 ... source","title":"nbdev_clean"},{"location":"api/clean/#clean_jupyter","text":"clean_jupyter (path, model, **kwargs) Clean Jupyter model pre save to path This cleans notebooks on-save to avoid unnecessary merge conflicts. The easiest way to install it for both Jupyter Notebook and Lab is by running nbdev_install_hooks . It works by implementing a pre_save_hook from Jupyter\u2019s file save hook API .","title":"clean_jupyter"},{"location":"api/clean/#hooks","text":"source","title":"Hooks"},{"location":"api/clean/#nbdev_install_hooks","text":"nbdev_install_hooks () Install Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks See clean_jupyter and nbdev_merge for more about how each hook works.","title":"nbdev_install_hooks"},{"location":"api/cli/","text":"cli \u00a4 source nbdev_filter \u00a4 nbdev_filter (nb_txt:str=None, fname:str=None, printit:<function bool_arg>=True) A notebook filter for Quarto Type Default Details nb_txt str None Notebook text (uses stdin if not provided) fname str None Notebook to read (uses nb_txt if not provided) printit bool_arg True Print to stdout? source extract_tgz \u00a4 extract_tgz (url, dest='.') source nbdev_new \u00a4 nbdev_new (repo:str=None, branch:str=None, user:str=None, author:str=None, author_email:str=None, description:str=None, path:str='.', cfg_name:str='settings.ini', lib_name='%(repo)s', git_url='https://github.com/%(user)s/%(repo)s', custom_sidebar:<function bool_arg>=False, nbs_path:pathlib.Path='nbs', lib_path:pathlib.Path=None, doc_path:pathlib.Path='_docs', tst_flags='notest', version='0.0.1', doc_host='https://%(user)s.github.io', doc_baseurl='/%(repo)s', keywords='nbdev jupyter notebook python', license='apache2', copyright:str=None, status='3', min_python='3.7', audience='Developers', language='English', recursive:<function bool_arg>=True, black_formatting:<function bool_arg>=False, readme_nb='index.ipynb', title='%(lib_name)s', allowed_metadata_keys='', allowed_cell_metadata_keys='', jupyter_hooks:<function bool_arg>=True, clean_ids:<function bool_arg>=True, clear_all:<function bool_arg>=False, put_version_in_init:<function bool_arg>=True) Create an nbdev project. Type Default Details repo str None Repo name branch str None Repo default branch user str None Repo username author str None Package author\u2019s name author_email str None Package author\u2019s email address description str None Short summary of the package path str . Path to create config file cfg_name str settings.ini Name of config file to create lib_name str %(repo)s Package name git_url str https://github.com/%(user)s/%(repo)s Repo URL custom_sidebar bool_arg False Use a custom sidebar.yml? nbs_path Path nbs Path to notebooks lib_path Path None Path to package root (default: repo with - replaced by _ ) doc_path Path _docs Path to rendered docs tst_flags str notest Test flags version str 0.0.1 Version of this release doc_host str https://%(user)s.github.io Hostname for docs doc_baseurl str /%(repo)s Base URL for docs keywords str nbdev jupyter notebook python Package keywords license str apache2 License for the package copyright str None Copyright for the package, defaults to \u2018 current_year onwards, author \u2019 status str 3 Development status PyPI classifier min_python str 3.7 Minimum Python version PyPI classifier audience str Developers Intended audience PyPI classifier language str English Language PyPI classifier recursive bool_arg True Include subfolders in notebook globs? black_formatting bool_arg False Format libraries with black? readme_nb str index.ipynb Notebook to export as repo readme title str %(lib_name)s Quarto website title allowed_metadata_keys str Preserve the list of keys in the main notebook metadata allowed_cell_metadata_keys str Preserve the list of keys in cell level metadata jupyter_hooks bool_arg True Run Jupyter hooks? clean_ids bool_arg True Remove ids from plaintext reprs? clear_all bool_arg False Remove all cell metadata and cell outputs? put_version_in_init bool_arg True Add the version to the main init .py in nbdev_export It works by copying contents from the latest tagged nbdev-template release, and rendering termplate variables using the created settings.ini file. Settings can be passed via command line args; missing settings are inferred from the current git/GitHub repo, otherwise prompted for. Help \u00a4 source chelp \u00a4 chelp () Show help for all console scripts chelp () nbdev_bump_version Increment version in settings.ini by one nbdev_changelog Create a CHANGELOG.md file from closed and labeled GitHub issues nbdev_clean Clean all notebooks in `fname` to avoid merge conflicts nbdev_conda Create a `meta.yaml` file ready to be built into a package, and optionally build and upload it nbdev_create_config Create a config file. nbdev_docs Create Quarto docs and README.md nbdev_export Export notebooks in `path` to Python modules nbdev_filter A notebook filter for Quarto nbdev_fix Create working notebook from conflicted notebook `nbname` nbdev_help Show help for all console scripts nbdev_install Install Quarto and the current library nbdev_install_hooks Install Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks nbdev_install_quarto Install latest Quarto on macOS or Linux, prints instructions for Windows nbdev_merge Git merge driver for notebooks nbdev_migrate Convert all markdown and notebook files in `path` from v1 to v2 nbdev_new Create an nbdev project. nbdev_prepare Export, test, and clean notebooks, and render README if needed nbdev_preview Preview docs locally nbdev_proc_nbs Process notebooks in `path` for docs rendering nbdev_pypi Create and upload Python package to PyPI nbdev_readme None nbdev_release_both Release both conda and PyPI packages nbdev_release_gh Calls `nbdev_changelog`, lets you edit the result, then pushes to git and calls `nbdev_release_git` nbdev_release_git Tag and create a release in GitHub for the current version nbdev_sidebar Create sidebar.yml nbdev_test Test in parallel notebooks matching `path`, passing along `flags` nbdev_trust Trust notebooks matching `fname` nbdev_update Propagate change in modules matching `fname` to notebooks that created them","title":"cli"},{"location":"api/cli/#cli","text":"source","title":"cli"},{"location":"api/cli/#nbdev_filter","text":"nbdev_filter (nb_txt:str=None, fname:str=None, printit:<function bool_arg>=True) A notebook filter for Quarto Type Default Details nb_txt str None Notebook text (uses stdin if not provided) fname str None Notebook to read (uses nb_txt if not provided) printit bool_arg True Print to stdout? source","title":"nbdev_filter"},{"location":"api/cli/#extract_tgz","text":"extract_tgz (url, dest='.') source","title":"extract_tgz"},{"location":"api/cli/#nbdev_new","text":"nbdev_new (repo:str=None, branch:str=None, user:str=None, author:str=None, author_email:str=None, description:str=None, path:str='.', cfg_name:str='settings.ini', lib_name='%(repo)s', git_url='https://github.com/%(user)s/%(repo)s', custom_sidebar:<function bool_arg>=False, nbs_path:pathlib.Path='nbs', lib_path:pathlib.Path=None, doc_path:pathlib.Path='_docs', tst_flags='notest', version='0.0.1', doc_host='https://%(user)s.github.io', doc_baseurl='/%(repo)s', keywords='nbdev jupyter notebook python', license='apache2', copyright:str=None, status='3', min_python='3.7', audience='Developers', language='English', recursive:<function bool_arg>=True, black_formatting:<function bool_arg>=False, readme_nb='index.ipynb', title='%(lib_name)s', allowed_metadata_keys='', allowed_cell_metadata_keys='', jupyter_hooks:<function bool_arg>=True, clean_ids:<function bool_arg>=True, clear_all:<function bool_arg>=False, put_version_in_init:<function bool_arg>=True) Create an nbdev project. Type Default Details repo str None Repo name branch str None Repo default branch user str None Repo username author str None Package author\u2019s name author_email str None Package author\u2019s email address description str None Short summary of the package path str . Path to create config file cfg_name str settings.ini Name of config file to create lib_name str %(repo)s Package name git_url str https://github.com/%(user)s/%(repo)s Repo URL custom_sidebar bool_arg False Use a custom sidebar.yml? nbs_path Path nbs Path to notebooks lib_path Path None Path to package root (default: repo with - replaced by _ ) doc_path Path _docs Path to rendered docs tst_flags str notest Test flags version str 0.0.1 Version of this release doc_host str https://%(user)s.github.io Hostname for docs doc_baseurl str /%(repo)s Base URL for docs keywords str nbdev jupyter notebook python Package keywords license str apache2 License for the package copyright str None Copyright for the package, defaults to \u2018 current_year onwards, author \u2019 status str 3 Development status PyPI classifier min_python str 3.7 Minimum Python version PyPI classifier audience str Developers Intended audience PyPI classifier language str English Language PyPI classifier recursive bool_arg True Include subfolders in notebook globs? black_formatting bool_arg False Format libraries with black? readme_nb str index.ipynb Notebook to export as repo readme title str %(lib_name)s Quarto website title allowed_metadata_keys str Preserve the list of keys in the main notebook metadata allowed_cell_metadata_keys str Preserve the list of keys in cell level metadata jupyter_hooks bool_arg True Run Jupyter hooks? clean_ids bool_arg True Remove ids from plaintext reprs? clear_all bool_arg False Remove all cell metadata and cell outputs? put_version_in_init bool_arg True Add the version to the main init .py in nbdev_export It works by copying contents from the latest tagged nbdev-template release, and rendering termplate variables using the created settings.ini file. Settings can be passed via command line args; missing settings are inferred from the current git/GitHub repo, otherwise prompted for.","title":"nbdev_new"},{"location":"api/cli/#help","text":"source","title":"Help"},{"location":"api/cli/#chelp","text":"chelp () Show help for all console scripts chelp () nbdev_bump_version Increment version in settings.ini by one nbdev_changelog Create a CHANGELOG.md file from closed and labeled GitHub issues nbdev_clean Clean all notebooks in `fname` to avoid merge conflicts nbdev_conda Create a `meta.yaml` file ready to be built into a package, and optionally build and upload it nbdev_create_config Create a config file. nbdev_docs Create Quarto docs and README.md nbdev_export Export notebooks in `path` to Python modules nbdev_filter A notebook filter for Quarto nbdev_fix Create working notebook from conflicted notebook `nbname` nbdev_help Show help for all console scripts nbdev_install Install Quarto and the current library nbdev_install_hooks Install Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks nbdev_install_quarto Install latest Quarto on macOS or Linux, prints instructions for Windows nbdev_merge Git merge driver for notebooks nbdev_migrate Convert all markdown and notebook files in `path` from v1 to v2 nbdev_new Create an nbdev project. nbdev_prepare Export, test, and clean notebooks, and render README if needed nbdev_preview Preview docs locally nbdev_proc_nbs Process notebooks in `path` for docs rendering nbdev_pypi Create and upload Python package to PyPI nbdev_readme None nbdev_release_both Release both conda and PyPI packages nbdev_release_gh Calls `nbdev_changelog`, lets you edit the result, then pushes to git and calls `nbdev_release_git` nbdev_release_git Tag and create a release in GitHub for the current version nbdev_sidebar Create sidebar.yml nbdev_test Test in parallel notebooks matching `path`, passing along `flags` nbdev_trust Trust notebooks matching `fname` nbdev_update Propagate change in modules matching `fname` to notebooks that created them","title":"chelp"},{"location":"api/config/","text":"config \u00a4 Configuring nbdev \u00a4 nbdev is heavily customizeable, thanks to the configuration system defined in this module. There are 2 ways to interact with nbdev\u2019s config: In the terminal: nbdev_create_config creates a config file (if you\u2019re starting a new project use nbdev_new instead) In your library: get_config returns a fastcore.foundation.Config object. Read on for more about how these work. source nbdev_create_config \u00a4 nbdev_create_config (repo:str=None, branch:str=None, user:str=None, author:str=None, author_email:str=None, description:str=None, path:str='.', cfg_name:str='settings.ini', lib_name='%(repo)s', git_url='https://github.com/%(user)s/%(repo)s', custom_sidebar:<function bool_arg>=False, nbs_path:pathlib.Path='nbs', lib_path:pathlib.Path=None, doc_path:pathlib.Path='_docs', tst_flags='notest', version='0.0.1', doc_host='https://%(user)s.github.io', doc_baseurl='/%(repo)s', keywords='nbdev jupyter notebook python', license='apache2', copyright:str=None, status='3', min_python='3.7', audience='Developers', language='English', recursive:<function bool_arg>=True, black_formatting:<function bool_arg>=False, readme_nb='index.ipynb', title='%(lib_name)s', allowed_metadata_keys='', allowed_cell_metadata_keys='', jupyter_hooks:<function bool_arg>=True, clean_ids:<function bool_arg>=True, clear_all:<function bool_arg>=False, put_version_in_init:<function bool_arg>=True) Create a config file. Type Default Details repo str None Repo name branch str None Repo default branch user str None Repo username author str None Package author\u2019s name author_email str None Package author\u2019s email address description str None Short summary of the package path str . Path to create config file cfg_name str settings.ini Name of config file to create lib_name str %(repo)s Package name git_url str https://github.com/%(user)s/%(repo)s Repo URL custom_sidebar bool_arg False Use a custom sidebar.yml? nbs_path Path nbs Path to notebooks lib_path Path None Path to package root (default: repo with - replaced by _ ) doc_path Path _docs Path to rendered docs tst_flags str notest Test flags version str 0.0.1 Version of this release doc_host str https://%(user)s.github.io Hostname for docs doc_baseurl str /%(repo)s Base URL for docs keywords str nbdev jupyter notebook python Package keywords license str apache2 License for the package copyright str None Copyright for the package, defaults to \u2018 current_year onwards, author \u2019 status str 3 Development status PyPI classifier min_python str 3.7 Minimum Python version PyPI classifier audience str Developers Intended audience PyPI classifier language str English Language PyPI classifier recursive bool_arg True Include subfolders in notebook globs? black_formatting bool_arg False Format libraries with black? readme_nb str index.ipynb Notebook to export as repo readme title str %(lib_name)s Quarto website title allowed_metadata_keys str Preserve the list of keys in the main notebook metadata allowed_cell_metadata_keys str Preserve the list of keys in cell level metadata jupyter_hooks bool_arg True Run Jupyter hooks? clean_ids bool_arg True Remove ids from plaintext reprs? clear_all bool_arg False Remove all cell metadata and cell outputs? put_version_in_init bool_arg True Add the version to the main init .py in nbdev_export The table above also serves as a full reference of nbdev\u2019s settings (excluding the path and cfg_name parameters which decide where the config file is saved). For more about PyPI classifiers, see Classifiers . You can create a config file by passing all of the required settings via the command line, as well as any optional settings you\u2019d like to override, for example: nbdev_create_config --repo nbdev --user fastai --author fastai \\ --author_email info@fast.ai --description 'A test project' If you don\u2019t provide required settings from the command line, we\u2019ll try to to infer them from git and GitHub. Finally, you\u2019ll be asked to manually input any required settings that we couldn\u2019t automatically fill in. source get_config \u00a4 get_config (cfg_name='settings.ini', path=None) Return nbdev config. Searches up from path until cfg_name is found. User settings are loaded from ~/.config/nbdev/{cfg_name} . Unspecified optional settings return defaults. See nbdev_create_config for a full reference of nbdev\u2019s settings. cfg = get_config () cfg is a fastcore Config object, so you can access keys as attributes: p = Path . cwd () . parent . parent test_eq ( cfg . lib_name , 'nbdev' ) test_eq ( cfg . git_url , 'https://github.com/fastai/nbdev' ) Its own path and parent are attributes too: test_eq ( cfg . config_path , p ) test_eq ( cfg . config_file , p / 'settings.ini' ) Paths are relative to the project: test_eq ( cfg . doc_path , p / '_docs' ) test_eq ( cfg . lib_path , p / 'nbdev' ) test_eq ( cfg . nbs_path , p / 'nbs' ) It automatically returns defaults for keys not specified in the config file. Here we create an empty config file and access lib_path and copyright even though they weren\u2019t explicitly defined: with tempfile . TemporaryDirectory () as d , working_directory ( d ): Config ( '.' , 'test_settings.ini' , { 'repo' : 'my-project' , 'author' : 'fastai' , 'nbs_path' : 'nbs' }); cfg = get_config ( 'test_settings.ini' , '.' ) test_eq ( cfg . repo , 'my-project' ) test_eq ( cfg . lib_path . name , 'my_project' ) test_eq ( cfg . copyright , '2022 onwards, fastai' ) In fact, you can return a default config even if you don\u2019t have a settings file. This is to support certain nbdev commands work outside of nbdev repos: cfg = get_config ( 'test_settings.ini' , '.' ) test_eq ( cfg . lib_path , Path ( 'nbdev' ) . resolve ()) test_eq ( cfg . nbs_path , Path ( 'nbs' ) . resolve ()) You can customise nbdev for all repositories for your user with a ~/.config/nbdev/settings.ini file (by default, although we follow the broader XDG specification ). For example, you could globally disable nbdev\u2019s Jupyter hooks by creating a user settings file with jupyter_hooks = False . source config_key \u00a4 config_key (c, default=None, path=True, missing_ok=None) Deprecated: use get_config().get or get_config().path instead. Helpers \u00a4 source create_output \u00a4 create_output (txt, mime) Add a cell output containing txt of the mime text MIME sub-type source show_src \u00a4 show_src (src, lang='python') show_src ( \"print(create_output('text', 'text/plain'))\" ) print ( create_output ( 'text' , 'text/plain' )) Exporting a basic module \u00a4 source add_init \u00a4 add_init (path=None) Add __init__.py in all subdirs of path containing python files if it\u2019s not there already. source update_version \u00a4 update_version (path=None) Add or update __version__ in the main __init__.py of the library. Python modules require a __init.py__ file in all directories that are modules. We assume that all directories containing a python file (including in subdirectories of any depth) is a module, and therefore add a __init__.py to each. with tempfile . TemporaryDirectory () as d : d = Path ( d ) ( d / 'a/b' ) . mkdir ( parents = True ) ( d / 'a/b/f.py' ) . touch () ( d / 'a/c' ) . mkdir () add_init ( d ) assert not ( d / 'a/c' / _init ) . exists (), \"Should not add init to dir without py file\" for e in [ d , d / 'a' , d / 'a/b' ]: assert ( e / _init ) . exists (), f \"Missing init in { e } \" source write_cells \u00a4 write_cells (cells, hdr, file, offset=0) Write cells to file along with header hdr starting at index offset (mainly for nbdev internal use). This is a simple exporter with just enough functionality to correctly export this notebook, in order to bootstrap the creation of nbdev itself.","title":"config"},{"location":"api/config/#config","text":"","title":"config"},{"location":"api/config/#configuring-nbdev","text":"nbdev is heavily customizeable, thanks to the configuration system defined in this module. There are 2 ways to interact with nbdev\u2019s config: In the terminal: nbdev_create_config creates a config file (if you\u2019re starting a new project use nbdev_new instead) In your library: get_config returns a fastcore.foundation.Config object. Read on for more about how these work. source","title":"Configuring nbdev"},{"location":"api/config/#nbdev_create_config","text":"nbdev_create_config (repo:str=None, branch:str=None, user:str=None, author:str=None, author_email:str=None, description:str=None, path:str='.', cfg_name:str='settings.ini', lib_name='%(repo)s', git_url='https://github.com/%(user)s/%(repo)s', custom_sidebar:<function bool_arg>=False, nbs_path:pathlib.Path='nbs', lib_path:pathlib.Path=None, doc_path:pathlib.Path='_docs', tst_flags='notest', version='0.0.1', doc_host='https://%(user)s.github.io', doc_baseurl='/%(repo)s', keywords='nbdev jupyter notebook python', license='apache2', copyright:str=None, status='3', min_python='3.7', audience='Developers', language='English', recursive:<function bool_arg>=True, black_formatting:<function bool_arg>=False, readme_nb='index.ipynb', title='%(lib_name)s', allowed_metadata_keys='', allowed_cell_metadata_keys='', jupyter_hooks:<function bool_arg>=True, clean_ids:<function bool_arg>=True, clear_all:<function bool_arg>=False, put_version_in_init:<function bool_arg>=True) Create a config file. Type Default Details repo str None Repo name branch str None Repo default branch user str None Repo username author str None Package author\u2019s name author_email str None Package author\u2019s email address description str None Short summary of the package path str . Path to create config file cfg_name str settings.ini Name of config file to create lib_name str %(repo)s Package name git_url str https://github.com/%(user)s/%(repo)s Repo URL custom_sidebar bool_arg False Use a custom sidebar.yml? nbs_path Path nbs Path to notebooks lib_path Path None Path to package root (default: repo with - replaced by _ ) doc_path Path _docs Path to rendered docs tst_flags str notest Test flags version str 0.0.1 Version of this release doc_host str https://%(user)s.github.io Hostname for docs doc_baseurl str /%(repo)s Base URL for docs keywords str nbdev jupyter notebook python Package keywords license str apache2 License for the package copyright str None Copyright for the package, defaults to \u2018 current_year onwards, author \u2019 status str 3 Development status PyPI classifier min_python str 3.7 Minimum Python version PyPI classifier audience str Developers Intended audience PyPI classifier language str English Language PyPI classifier recursive bool_arg True Include subfolders in notebook globs? black_formatting bool_arg False Format libraries with black? readme_nb str index.ipynb Notebook to export as repo readme title str %(lib_name)s Quarto website title allowed_metadata_keys str Preserve the list of keys in the main notebook metadata allowed_cell_metadata_keys str Preserve the list of keys in cell level metadata jupyter_hooks bool_arg True Run Jupyter hooks? clean_ids bool_arg True Remove ids from plaintext reprs? clear_all bool_arg False Remove all cell metadata and cell outputs? put_version_in_init bool_arg True Add the version to the main init .py in nbdev_export The table above also serves as a full reference of nbdev\u2019s settings (excluding the path and cfg_name parameters which decide where the config file is saved). For more about PyPI classifiers, see Classifiers . You can create a config file by passing all of the required settings via the command line, as well as any optional settings you\u2019d like to override, for example: nbdev_create_config --repo nbdev --user fastai --author fastai \\ --author_email info@fast.ai --description 'A test project' If you don\u2019t provide required settings from the command line, we\u2019ll try to to infer them from git and GitHub. Finally, you\u2019ll be asked to manually input any required settings that we couldn\u2019t automatically fill in. source","title":"nbdev_create_config"},{"location":"api/config/#get_config","text":"get_config (cfg_name='settings.ini', path=None) Return nbdev config. Searches up from path until cfg_name is found. User settings are loaded from ~/.config/nbdev/{cfg_name} . Unspecified optional settings return defaults. See nbdev_create_config for a full reference of nbdev\u2019s settings. cfg = get_config () cfg is a fastcore Config object, so you can access keys as attributes: p = Path . cwd () . parent . parent test_eq ( cfg . lib_name , 'nbdev' ) test_eq ( cfg . git_url , 'https://github.com/fastai/nbdev' ) Its own path and parent are attributes too: test_eq ( cfg . config_path , p ) test_eq ( cfg . config_file , p / 'settings.ini' ) Paths are relative to the project: test_eq ( cfg . doc_path , p / '_docs' ) test_eq ( cfg . lib_path , p / 'nbdev' ) test_eq ( cfg . nbs_path , p / 'nbs' ) It automatically returns defaults for keys not specified in the config file. Here we create an empty config file and access lib_path and copyright even though they weren\u2019t explicitly defined: with tempfile . TemporaryDirectory () as d , working_directory ( d ): Config ( '.' , 'test_settings.ini' , { 'repo' : 'my-project' , 'author' : 'fastai' , 'nbs_path' : 'nbs' }); cfg = get_config ( 'test_settings.ini' , '.' ) test_eq ( cfg . repo , 'my-project' ) test_eq ( cfg . lib_path . name , 'my_project' ) test_eq ( cfg . copyright , '2022 onwards, fastai' ) In fact, you can return a default config even if you don\u2019t have a settings file. This is to support certain nbdev commands work outside of nbdev repos: cfg = get_config ( 'test_settings.ini' , '.' ) test_eq ( cfg . lib_path , Path ( 'nbdev' ) . resolve ()) test_eq ( cfg . nbs_path , Path ( 'nbs' ) . resolve ()) You can customise nbdev for all repositories for your user with a ~/.config/nbdev/settings.ini file (by default, although we follow the broader XDG specification ). For example, you could globally disable nbdev\u2019s Jupyter hooks by creating a user settings file with jupyter_hooks = False . source","title":"get_config"},{"location":"api/config/#config_key","text":"config_key (c, default=None, path=True, missing_ok=None) Deprecated: use get_config().get or get_config().path instead.","title":"config_key"},{"location":"api/config/#helpers","text":"source","title":"Helpers"},{"location":"api/config/#create_output","text":"create_output (txt, mime) Add a cell output containing txt of the mime text MIME sub-type source","title":"create_output"},{"location":"api/config/#show_src","text":"show_src (src, lang='python') show_src ( \"print(create_output('text', 'text/plain'))\" ) print ( create_output ( 'text' , 'text/plain' ))","title":"show_src"},{"location":"api/config/#exporting-a-basic-module","text":"source","title":"Exporting a basic module"},{"location":"api/config/#add_init","text":"add_init (path=None) Add __init__.py in all subdirs of path containing python files if it\u2019s not there already. source","title":"add_init"},{"location":"api/config/#update_version","text":"update_version (path=None) Add or update __version__ in the main __init__.py of the library. Python modules require a __init.py__ file in all directories that are modules. We assume that all directories containing a python file (including in subdirectories of any depth) is a module, and therefore add a __init__.py to each. with tempfile . TemporaryDirectory () as d : d = Path ( d ) ( d / 'a/b' ) . mkdir ( parents = True ) ( d / 'a/b/f.py' ) . touch () ( d / 'a/c' ) . mkdir () add_init ( d ) assert not ( d / 'a/c' / _init ) . exists (), \"Should not add init to dir without py file\" for e in [ d , d / 'a' , d / 'a/b' ]: assert ( e / _init ) . exists (), f \"Missing init in { e } \" source","title":"update_version"},{"location":"api/config/#write_cells","text":"write_cells (cells, hdr, file, offset=0) Write cells to file along with header hdr starting at index offset (mainly for nbdev internal use). This is a simple exporter with just enough functionality to correctly export this notebook, in order to bootstrap the creation of nbdev itself.","title":"write_cells"},{"location":"api/doclinks/","text":"doclinks \u00a4 Create the module index \u00a4 source patch_name \u00a4 patch_name (o) If o is decorated with patch or patch_to , return its class-prefix name def _test_patch ( code ): return patch_name ( ast . parse ( code ) . body [ 0 ]) s = \"@patch \\n def _f(self:_T): ...\" test_eq ( '_T._f' , _test_patch ( s )) s = \"@patch_to(_T) \\n def _g(self): ...\" test_eq ( '_T._g' , _test_patch ( s )) # Get all patched classes when patching with a union s = \"@patch \\n def _f(self:_T|_U|_V): ...\" test_eq ( _test_patch ( s ), [ '_T._f' , '_U._f' , '_V._f' ]) # _build_modidx() Export a notebook \u00a4 source nbglob \u00a4 nbglob (path=None, skip_folder_re='^[_.]', file_glob='*.ipynb', skip_file_re='^[_.]', key='nbs_path', as_path=False, recursive:bool=True, symlinks:bool=True, file_re:str=None, folder_re:str=None, skip_file_glob:str=None, func:<built- infunctioncallable>=<function join>, ret_folders:bool=False) Find all files in a directory matching an extension given a config key. Type Default Details path Path | str path to start searching skip_folder_re str None Skip folders matching regex, file_glob str None Only include files matching glob skip_file_re str None Skip files matching regex key str nbs_path as_path bool False recursive bool True search subfolders symlinks bool True follow symlinks? file_re str None Only include files matching regex folder_re str None Only enter folders matching regex skip_file_glob str None Skip files matching glob func callable join function to apply to each matched file ret_folders bool False return folders, not just files Returns L Paths to matched files source nbglob_cli \u00a4 nbglob_cli (path:str=None, symlinks:bool=False, file_glob:str='*.ipynb', file_re:str=None, folder_re:str=None, skip_file_glob:str=None, skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]') Find all files in a directory matching an extension given a config key. Type Default Details path str None Path to notebooks symlinks bool False Follow symlinks? file_glob str *.ipynb Only include files matching glob file_re str None Only include files matching regex folder_re str None Only enter folders matching regex skip_file_glob str None Skip files matching glob skip_file_re str ^[_.] Skip files matching regex skip_folder_re str ^[_.] Skip folders matching regex source nbdev_export \u00a4 nbdev_export (path:str=None, symlinks:bool=False, file_glob:str='*.ipynb', file_re:str=None, folder_re:str=None, skip_file_glob:str=None, skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]') Export notebooks in path to Python modules Type Default Details path str None Path or filename symlinks bool False Follow symlinks? file_glob str *.ipynb Only include files matching glob file_re str None Only include files matching regex folder_re str None Only enter folders matching regex skip_file_glob str None Skip files matching glob skip_file_re str ^[_.] Skip files matching regex skip_folder_re str ^[_.] Skip folders matching regex Query the module index \u00a4 source NbdevLookup \u00a4 NbdevLookup (strip_libs=None, incl_libs=None, skip_mods=None) Mapping from symbol names to docs and source URLs Indexing returns a link to the symbol\u2019s docs, along with the name of the source file the source URL if available. c = NbdevLookup () c [ 'nbdev.doclinks.NbdevLookup' ] ('https://nbdev.fast.ai/api/doclinks.html#nbdevlookup', 'nbdev/doclinks.py', 'https://github.com/fastai/nbdev/blob/master/nbdev/doclinks.py') source NbdevLookup.doc \u00a4 NbdevLookup.doc (sym) Link to docs for sym c . doc ( 'nbdev.doclinks.NbdevLookup' ) 'https://nbdev.fast.ai/api/doclinks.html#nbdevlookup' Symbol names are taken from libraries registered using the \u2018nbdev\u2019 entry point. By default, all libraries with this entry point are searched, but full symbol names (including module prefix) are required. assert c . doc ( 'numpy.array' ) . startswith ( 'http' ) assert c . doc ( 'NbdevLookup' ) . endswith ( '#nbdevlookup' ) assert not c . doc ( 'array' ) Pass strip_libs to list libraries which should be available without requiring a module prefix. c = NbdevLookup ( strip_libs = ( 'nbdev' , 'nbdev_numpy' )) assert c . doc ( 'array' ) . startswith ( 'http' ) source NbdevLookup.code \u00a4 NbdevLookup.code (sym) Link to source code for sym NbdevLookup () . code ( 'fastcore.net.urlsend' ) 'https://github.com/fastai/fastcore/blob/master/fastcore/net.py#LNone' source NbdevLookup.linkify \u00a4 NbdevLookup.linkify (md) md = \"\"\"This is a link to `numpy.array` and to `get_config` but not a link to `foobar`. And not a link to <code>dict2nb</code>. This is not a link to `get_config` This isn\u2019t a link to get_config either ``` \"\"\" ``` python print(NbdevLookup('nbdev').linkify(md)) This is a link to [`numpy.array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array) and to [`get_config`](https://nbdev.fast.ai/api/config.html#get_config) but not a link to `foobar`. And not a link to <code>dict2nb</code>. This is not a link to `get_config` This isn\u2019t a link to get_config either","title":"doclinks"},{"location":"api/doclinks/#doclinks","text":"","title":"doclinks"},{"location":"api/doclinks/#create-the-module-index","text":"source","title":"Create the module index"},{"location":"api/doclinks/#patch_name","text":"patch_name (o) If o is decorated with patch or patch_to , return its class-prefix name def _test_patch ( code ): return patch_name ( ast . parse ( code ) . body [ 0 ]) s = \"@patch \\n def _f(self:_T): ...\" test_eq ( '_T._f' , _test_patch ( s )) s = \"@patch_to(_T) \\n def _g(self): ...\" test_eq ( '_T._g' , _test_patch ( s )) # Get all patched classes when patching with a union s = \"@patch \\n def _f(self:_T|_U|_V): ...\" test_eq ( _test_patch ( s ), [ '_T._f' , '_U._f' , '_V._f' ]) # _build_modidx()","title":"patch_name"},{"location":"api/doclinks/#export-a-notebook","text":"source","title":"Export a notebook"},{"location":"api/doclinks/#nbglob","text":"nbglob (path=None, skip_folder_re='^[_.]', file_glob='*.ipynb', skip_file_re='^[_.]', key='nbs_path', as_path=False, recursive:bool=True, symlinks:bool=True, file_re:str=None, folder_re:str=None, skip_file_glob:str=None, func:<built- infunctioncallable>=<function join>, ret_folders:bool=False) Find all files in a directory matching an extension given a config key. Type Default Details path Path | str path to start searching skip_folder_re str None Skip folders matching regex, file_glob str None Only include files matching glob skip_file_re str None Skip files matching regex key str nbs_path as_path bool False recursive bool True search subfolders symlinks bool True follow symlinks? file_re str None Only include files matching regex folder_re str None Only enter folders matching regex skip_file_glob str None Skip files matching glob func callable join function to apply to each matched file ret_folders bool False return folders, not just files Returns L Paths to matched files source","title":"nbglob"},{"location":"api/doclinks/#nbglob_cli","text":"nbglob_cli (path:str=None, symlinks:bool=False, file_glob:str='*.ipynb', file_re:str=None, folder_re:str=None, skip_file_glob:str=None, skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]') Find all files in a directory matching an extension given a config key. Type Default Details path str None Path to notebooks symlinks bool False Follow symlinks? file_glob str *.ipynb Only include files matching glob file_re str None Only include files matching regex folder_re str None Only enter folders matching regex skip_file_glob str None Skip files matching glob skip_file_re str ^[_.] Skip files matching regex skip_folder_re str ^[_.] Skip folders matching regex source","title":"nbglob_cli"},{"location":"api/doclinks/#nbdev_export","text":"nbdev_export (path:str=None, symlinks:bool=False, file_glob:str='*.ipynb', file_re:str=None, folder_re:str=None, skip_file_glob:str=None, skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]') Export notebooks in path to Python modules Type Default Details path str None Path or filename symlinks bool False Follow symlinks? file_glob str *.ipynb Only include files matching glob file_re str None Only include files matching regex folder_re str None Only enter folders matching regex skip_file_glob str None Skip files matching glob skip_file_re str ^[_.] Skip files matching regex skip_folder_re str ^[_.] Skip folders matching regex","title":"nbdev_export"},{"location":"api/doclinks/#query-the-module-index","text":"source","title":"Query the module index"},{"location":"api/doclinks/#nbdevlookup","text":"NbdevLookup (strip_libs=None, incl_libs=None, skip_mods=None) Mapping from symbol names to docs and source URLs Indexing returns a link to the symbol\u2019s docs, along with the name of the source file the source URL if available. c = NbdevLookup () c [ 'nbdev.doclinks.NbdevLookup' ] ('https://nbdev.fast.ai/api/doclinks.html#nbdevlookup', 'nbdev/doclinks.py', 'https://github.com/fastai/nbdev/blob/master/nbdev/doclinks.py') source","title":"NbdevLookup"},{"location":"api/doclinks/#nbdevlookupdoc","text":"NbdevLookup.doc (sym) Link to docs for sym c . doc ( 'nbdev.doclinks.NbdevLookup' ) 'https://nbdev.fast.ai/api/doclinks.html#nbdevlookup' Symbol names are taken from libraries registered using the \u2018nbdev\u2019 entry point. By default, all libraries with this entry point are searched, but full symbol names (including module prefix) are required. assert c . doc ( 'numpy.array' ) . startswith ( 'http' ) assert c . doc ( 'NbdevLookup' ) . endswith ( '#nbdevlookup' ) assert not c . doc ( 'array' ) Pass strip_libs to list libraries which should be available without requiring a module prefix. c = NbdevLookup ( strip_libs = ( 'nbdev' , 'nbdev_numpy' )) assert c . doc ( 'array' ) . startswith ( 'http' ) source","title":"NbdevLookup.doc"},{"location":"api/doclinks/#nbdevlookupcode","text":"NbdevLookup.code (sym) Link to source code for sym NbdevLookup () . code ( 'fastcore.net.urlsend' ) 'https://github.com/fastai/fastcore/blob/master/fastcore/net.py#LNone' source","title":"NbdevLookup.code"},{"location":"api/doclinks/#nbdevlookuplinkify","text":"NbdevLookup.linkify (md) md = \"\"\"This is a link to `numpy.array` and to `get_config` but not a link to `foobar`. And not a link to <code>dict2nb</code>. This is not a link to `get_config` This isn\u2019t a link to get_config either ``` \"\"\" ``` python print(NbdevLookup('nbdev').linkify(md)) This is a link to [`numpy.array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array) and to [`get_config`](https://nbdev.fast.ai/api/config.html#get_config) but not a link to `foobar`. And not a link to <code>dict2nb</code>. This is not a link to `get_config` This isn\u2019t a link to get_config either","title":"NbdevLookup.linkify"},{"location":"api/export/","text":"export \u00a4 source ExportModuleProc \u00a4 ExportModuleProc () A processor which exports code to a module Specify dest where the module(s) will be exported to, and optionally a class to use to create the module ( ModuleMaker , by default). Exported cells are stored in a dict called modules , where the keys are the modules exported to. Those without an explicit module are stored in the '#' key, which will be exported to default_exp . everything_fn = '../../tests/01_everything.ipynb' exp = ExportModuleProc () proc = NBProcessor ( everything_fn , exp ) proc . process () test_eq ( exp . default_exp , 'everything' ) assert 'print_function' in exp . modules [ '#' ][ 0 ] . source assert 'h_n' in exp . in_all [ 'some.thing' ][ 0 ] . source source black_format \u00a4 black_format (cell, force=False) Processor to format code with black Type Default Details cell Cell to format force bool False Turn black formatting on regardless of settings.ini _cell = read_nb ( '../../tests/black.ipynb' )[ 'cells' ][ 0 ] black_format ( _cell , force = True ) test_eq ( _cell . source , 'j = [1, 2, 3]' ) source nb_export \u00a4 nb_export (nbname, lib_path=None, procs=<function black_format>, debug=False, mod_maker=<class 'nbdev.maker.ModuleMaker'>, name=None) Create module(s) from notebook Let\u2019s check we can import a test file: shutil . rmtree ( 'tmp' , ignore_errors = True ) nb_export ( '../../tests/00_some.thing.ipynb' , 'tmp' ) g = exec_new ( 'import tmp.some.thing' ) test_eq ( g [ 'tmp' ] . some . thing . __all__ , [ 'a' ]) test_eq ( g [ 'tmp' ] . some . thing . a , 1 ) We\u2019ll also check that our \u2018everything\u2019 file exports correctly: nb_export ( everything_fn , 'tmp' ) g = exec_new ( 'import tmp.everything; from tmp.everything import *' ) _alls = L ( \"a b d e m n o p q\" . split ()) for s in _alls . map ( \" {} _y\" ): assert s in g , s for s in \"c_y_nall _f_y_nall g_n h_n i_n j_n k_n l_n\" . split (): assert s not in g , s for s in _alls . map ( \" {} _y\" ) + [ \"c_y_nall\" , \"_f_y_nall\" ]: assert hasattr ( g [ 'tmp' ] . everything , s ), s That notebook should also export one extra function to tmp.some.thing : del ( sys . modules [ 'tmp.some.thing' ]) # remove from module cache g = exec_new ( 'import tmp.some.thing' ) test_eq ( g [ 'tmp' ] . some . thing . __all__ , [ 'a' , 'h_n' ]) test_eq ( g [ 'tmp' ] . some . thing . h_n (), None ) Path ( '../nbdev/export.py' ) . unlink ( missing_ok = True ) nb_export ( '04a_export.ipynb' ) g = exec_new ( 'import nbdev.export' ) assert hasattr ( g [ 'nbdev' ] . export , 'nb_export' )","title":"export"},{"location":"api/export/#export","text":"source","title":"export"},{"location":"api/export/#exportmoduleproc","text":"ExportModuleProc () A processor which exports code to a module Specify dest where the module(s) will be exported to, and optionally a class to use to create the module ( ModuleMaker , by default). Exported cells are stored in a dict called modules , where the keys are the modules exported to. Those without an explicit module are stored in the '#' key, which will be exported to default_exp . everything_fn = '../../tests/01_everything.ipynb' exp = ExportModuleProc () proc = NBProcessor ( everything_fn , exp ) proc . process () test_eq ( exp . default_exp , 'everything' ) assert 'print_function' in exp . modules [ '#' ][ 0 ] . source assert 'h_n' in exp . in_all [ 'some.thing' ][ 0 ] . source source","title":"ExportModuleProc"},{"location":"api/export/#black_format","text":"black_format (cell, force=False) Processor to format code with black Type Default Details cell Cell to format force bool False Turn black formatting on regardless of settings.ini _cell = read_nb ( '../../tests/black.ipynb' )[ 'cells' ][ 0 ] black_format ( _cell , force = True ) test_eq ( _cell . source , 'j = [1, 2, 3]' ) source","title":"black_format"},{"location":"api/export/#nb_export","text":"nb_export (nbname, lib_path=None, procs=<function black_format>, debug=False, mod_maker=<class 'nbdev.maker.ModuleMaker'>, name=None) Create module(s) from notebook Let\u2019s check we can import a test file: shutil . rmtree ( 'tmp' , ignore_errors = True ) nb_export ( '../../tests/00_some.thing.ipynb' , 'tmp' ) g = exec_new ( 'import tmp.some.thing' ) test_eq ( g [ 'tmp' ] . some . thing . __all__ , [ 'a' ]) test_eq ( g [ 'tmp' ] . some . thing . a , 1 ) We\u2019ll also check that our \u2018everything\u2019 file exports correctly: nb_export ( everything_fn , 'tmp' ) g = exec_new ( 'import tmp.everything; from tmp.everything import *' ) _alls = L ( \"a b d e m n o p q\" . split ()) for s in _alls . map ( \" {} _y\" ): assert s in g , s for s in \"c_y_nall _f_y_nall g_n h_n i_n j_n k_n l_n\" . split (): assert s not in g , s for s in _alls . map ( \" {} _y\" ) + [ \"c_y_nall\" , \"_f_y_nall\" ]: assert hasattr ( g [ 'tmp' ] . everything , s ), s That notebook should also export one extra function to tmp.some.thing : del ( sys . modules [ 'tmp.some.thing' ]) # remove from module cache g = exec_new ( 'import tmp.some.thing' ) test_eq ( g [ 'tmp' ] . some . thing . __all__ , [ 'a' , 'h_n' ]) test_eq ( g [ 'tmp' ] . some . thing . h_n (), None ) Path ( '../nbdev/export.py' ) . unlink ( missing_ok = True ) nb_export ( '04a_export.ipynb' ) g = exec_new ( 'import nbdev.export' ) assert hasattr ( g [ 'nbdev' ] . export , 'nb_export' )","title":"nb_export"},{"location":"api/frontmatter/","text":"frontmatter \u00a4 source FrontmatterProc \u00a4 FrontmatterProc (nb) A YAML and formatted-markdown frontmatter processor YAML frontmatter can be added to notebooks in one of two ways: By adding a raw notebook cell with --- as the first and last lines, and YAML between them, or A specially formatted markdown cell. The first line should be start with a single # (creating an H1 heading), and becomes the title. Then, optionally, a line beginning with > (creating a quote block), which becomes the description. Finally, zero or more lines beginning with - (creating a list), each of which contains YAML. (If you already have \u201ctitle\u201d defined in frontmatter in a raw cell, then markdown cells will be ignored.) For instance, our test notebook contains the following markdown cell: # a title > A description - key1: value1 - key2: value2 - categories: [c1, c2] It also contains the following raw cell: --- execute: echo: false --- When we process with FrontmatterProc , these will both be removed, and a single raw cell will be added to the top, containing the combined YAML frontmatter: nbp = NBProcessor ( _test_file , procs = FrontmatterProc ) nbp . process () print ( nbp . nb . cells [ 0 ] . source ) --- categories: - c1 - c2 description: A description execute: echo: false key1: value1 key2: value2 output-file: docs_test.html title: a title --- In addition, a frontmatter_ attr will be added to the notebook, containing this information as a dict : d = nbp . nb . frontmatter_ d {'execute': {'echo': False}, 'title': 'a title', 'description': 'A description', 'key1': 'value1', 'key2': 'value2', 'categories': ['c1', 'c2'], 'output-file': 'docs_test.html'}","title":"frontmatter"},{"location":"api/frontmatter/#frontmatter","text":"source","title":"frontmatter"},{"location":"api/frontmatter/#frontmatterproc","text":"FrontmatterProc (nb) A YAML and formatted-markdown frontmatter processor YAML frontmatter can be added to notebooks in one of two ways: By adding a raw notebook cell with --- as the first and last lines, and YAML between them, or A specially formatted markdown cell. The first line should be start with a single # (creating an H1 heading), and becomes the title. Then, optionally, a line beginning with > (creating a quote block), which becomes the description. Finally, zero or more lines beginning with - (creating a list), each of which contains YAML. (If you already have \u201ctitle\u201d defined in frontmatter in a raw cell, then markdown cells will be ignored.) For instance, our test notebook contains the following markdown cell: # a title > A description - key1: value1 - key2: value2 - categories: [c1, c2] It also contains the following raw cell: --- execute: echo: false --- When we process with FrontmatterProc , these will both be removed, and a single raw cell will be added to the top, containing the combined YAML frontmatter: nbp = NBProcessor ( _test_file , procs = FrontmatterProc ) nbp . process () print ( nbp . nb . cells [ 0 ] . source ) --- categories: - c1 - c2 description: A description execute: echo: false key1: value1 key2: value2 output-file: docs_test.html title: a title --- In addition, a frontmatter_ attr will be added to the notebook, containing this information as a dict : d = nbp . nb . frontmatter_ d {'execute': {'echo': False}, 'title': 'a title', 'description': 'A description', 'key1': 'value1', 'key2': 'value2', 'categories': ['c1', 'c2'], 'output-file': 'docs_test.html'}","title":"FrontmatterProc"},{"location":"api/maker/","text":"maker \u00a4 Helpers \u00a4 Variable helpers \u00a4 These functions let us find and modify the definitions of variables in Python modules. source find_var \u00a4 find_var (lines, varname) Find the line numbers where varname is defined in lines t = '''a_=(1, 2, 3) b_=3''' test_eq ( find_var ( t . splitlines (), 'a_' ), ( 0 , 3 )) test_eq ( find_var ( t . splitlines (), 'b_' ), ( 4 , 5 )) source read_var \u00a4 read_var (code, varname) Eval and return the value of varname defined in code test_eq ( read_var ( t , 'a_' ), ( 1 , 2 , 3 )) test_eq ( read_var ( t , 'b_' ), 3 ) source update_var \u00a4 update_var (varname, func, fn=None, code=None) Update the definition of varname in file fn , by calling func with the current definition g = exec_new ( t ) test_eq (( g [ 'a_' ], g [ 'b_' ]), (( 1 , 2 , 3 ), 3 )) t2 = update_var ( 'a_' , lambda o : 0 , code = t ) exec ( t2 , g ) test_eq (( g [ 'a_' ], g [ 'b_' ]), ( 0 , 3 )) t3 = update_var ( 'b_' , lambda o : 0 , code = t ) exec ( t3 , g ) test_eq (( g [ 'a_' ], g [ 'b_' ]), (( 1 , 2 , 3 ), 0 )) source ModuleMaker \u00a4 ModuleMaker (dest, name, nb_path, is_new=True, parse=True) Helper class to create exported library from notebook source cells In order to export a notebook, we need an way to create a Python file. ModuleMaker fills that role. Pass in the directory where you want to module created, the name of the module, the path of the notebook source, and set is_new to True if this is a new file being created (rather than an existing file being added to). The location of the saved module will be in fname . Finally, if the source in the notebooks should not be parsed by Python (such as partial class declarations in cells), parse should be set to False . Note: If doing so, then the __all__ generation will be turned off as well. mm = ModuleMaker ( dest = 'tmp' , name = 'test.testing' , nb_path = Path . cwd () / '01_export.ipynb' , is_new = True ) mm . fname Path('tmp/test/testing.py') source decor_id \u00a4 decor_id (d) id attr of decorator, regardless of whether called as function or bare source ModuleMaker.make_all \u00a4 ModuleMaker.make_all (cells) Create __all__ with all exports in cells source make_code_cells \u00a4 make_code_cells (*ss) We want to add an __all__ to the top of the exported module. This methods autogenerates it from all code in cells . nb = make_code_cells ( \"from __future__ import print_function\" , \"def a():...\" , \"def b():...\" , \"c=d=1\" , \"_f=1\" , \"_g=1\" , \"_h=1\" , \"_all_=['_g', _h]\" , \"@patch \\n def h(self:ca):...\" ) test_eq ( set ( mm . make_all ( nb )), set ([ 'a' , 'b' , 'c' , 'd' , '_g' , '_h' ])) source relative_import \u00a4 relative_import (name, fname, level=0) Convert a module name to a name relative to fname test_eq ( relative_import ( 'nbdev.core' , \"xyz\" ), 'nbdev.core' ) test_eq ( relative_import ( 'nbdev.core' , 'nbdev' ), '.core' ) _p = Path ( 'fastai' ) test_eq ( relative_import ( 'fastai.core' , _p / 'vision' ), '..core' ) test_eq ( relative_import ( 'fastai.core' , _p / 'vision/transform' ), '...core' ) test_eq ( relative_import ( 'fastai.vision.transform' , _p / 'vision' ), '.transform' ) test_eq ( relative_import ( 'fastai.notebook.core' , _p / 'data' ), '..notebook.core' ) test_eq ( relative_import ( 'fastai.vision' , _p / 'vision' ), '.' ) test_eq ( relative_import ( 'fastai' , _p ), '.' ) test_eq ( relative_import ( 'fastai' , _p / 'vision' ), '..' ) test_eq ( relative_import ( 'fastai' , _p / 'vision/transform' ), '...' ) source NbCell.import2relative \u00a4 NbCell.import2relative (cell:execnb.nbio.NbCell, libname) source update_import \u00a4 update_import (source, tree, libname, f=<function relative_import>) ss = \"from nbdev.export import * \\n from nbdev.a.b import *\" cell = make_code_cells ([ ss ])[ 0 ] cell . import2relative ( 'nbdev' ) test_eq ( cell . source , 'from .export import * \\n from .a.b import *' ) cell = make_code_cells ([ ss ])[ 0 ] cell . import2relative ( 'nbdev/a' ) test_eq ( cell . source , 'from ..export import * \\n from .b import *' ) source ModuleMaker.make \u00a4 ModuleMaker.make (cells, all_cells=None, lib_path=None) Write module containing cells with __all__ generated from all_cells cells = make_code_cells ( \"from __future__ import print_function\" , \"_doc_ = 'module docstring here'\" , \"#|export \\n def a(): ...\" , \"def b(): ...\" ) mm . make ( cells , L ([ cells [ 2 ]])) show_src ( Path ( 'tmp/test/testing.py' ) . read_text ()) \"\"\"module docstring here\"\"\" # AUTOGENERATED! DO NOT EDIT! File to edit: ../../01_export.ipynb. # %% ../../01_export.ipynb 0 from __future__ import print_function # %% auto 0 __all__ = [ 'a' ] # %% ../../01_export.ipynb 1 _doc_ = 'module docstring here' # %% ../../01_export.ipynb 2 #|export def a (): ... # %% ../../01_export.ipynb 3 def b (): ... Pass all_cells=[] or parse=False if you don\u2019t want any __all__ added. Passing parse=False is also handy for when writing broken up functions or classes that ast.parse might not like but still want it to be exported, such as having a cell with: #|export class A : Note that by doing so we cannot properly generate a __all__ , so we assume that it is unwanted. am = ModuleMaker ( dest = 'tmp' , name = 'test.testing_noall' , nb_path = Path . cwd () / '01_export.ipynb' , is_new = True , parse = False ) am . fname Path('tmp/test/testing_noall.py') cells = make_code_cells ( \"from __future__ import print_function\" , \"#|export \\n def a(): ...\" , \"#|export \\n class A:\" ) am . make ( cells ) show_src ( Path ( 'tmp/test/testing_noall.py' ) . read_text ()) # AUTOGENERATED! DO NOT EDIT! File to edit: ../../01_export.ipynb. # %% ../../01_export.ipynb 0 from __future__ import print_function # %% ../../01_export.ipynb 1 #|export def a (): ... # %% ../../01_export.ipynb 2 #|export class A : If is_new=False then the additional definitions are added to the bottom, and any existing __all__ is updated with the newly-added symbols. c2 = make_code_cells ( \"def c(): ...\" , \"def d(): ...\" ) mm = ModuleMaker ( dest = 'tmp' , name = 'test.testing' , nb_path = Path . cwd () / '01_export.ipynb' , is_new = False ) mm . make ( c2 , c2 ) show_src ( Path ( 'tmp/test/testing.py' ) . read_text ()) \"\"\"module docstring here\"\"\" # AUTOGENERATED! DO NOT EDIT! File to edit: ../../01_export.ipynb. # %% ../../01_export.ipynb 0 from __future__ import print_function # %% auto 0 __all__ = [ 'a' , 'c' , 'd' ] # %% ../../01_export.ipynb 1 _doc_ = 'module docstring here' # %% ../../01_export.ipynb 2 #|export def a (): ... # %% ../../01_export.ipynb 3 def b (): ... # %% ../../01_export.ipynb 0 def c (): ... # %% ../../01_export.ipynb 1 def d (): ... try : g = exec_import ( 'tmp.test.testing' , '*' ) for s in \"a c d\" . split (): assert s in g , s assert 'b' not in g assert g [ 'a' ]() is None finally : shutil . rmtree ( 'tmp' )","title":"maker"},{"location":"api/maker/#maker","text":"","title":"maker"},{"location":"api/maker/#helpers","text":"","title":"Helpers"},{"location":"api/maker/#variable-helpers","text":"These functions let us find and modify the definitions of variables in Python modules. source","title":"Variable helpers"},{"location":"api/maker/#find_var","text":"find_var (lines, varname) Find the line numbers where varname is defined in lines t = '''a_=(1, 2, 3) b_=3''' test_eq ( find_var ( t . splitlines (), 'a_' ), ( 0 , 3 )) test_eq ( find_var ( t . splitlines (), 'b_' ), ( 4 , 5 )) source","title":"find_var"},{"location":"api/maker/#read_var","text":"read_var (code, varname) Eval and return the value of varname defined in code test_eq ( read_var ( t , 'a_' ), ( 1 , 2 , 3 )) test_eq ( read_var ( t , 'b_' ), 3 ) source","title":"read_var"},{"location":"api/maker/#update_var","text":"update_var (varname, func, fn=None, code=None) Update the definition of varname in file fn , by calling func with the current definition g = exec_new ( t ) test_eq (( g [ 'a_' ], g [ 'b_' ]), (( 1 , 2 , 3 ), 3 )) t2 = update_var ( 'a_' , lambda o : 0 , code = t ) exec ( t2 , g ) test_eq (( g [ 'a_' ], g [ 'b_' ]), ( 0 , 3 )) t3 = update_var ( 'b_' , lambda o : 0 , code = t ) exec ( t3 , g ) test_eq (( g [ 'a_' ], g [ 'b_' ]), (( 1 , 2 , 3 ), 0 )) source","title":"update_var"},{"location":"api/maker/#modulemaker","text":"ModuleMaker (dest, name, nb_path, is_new=True, parse=True) Helper class to create exported library from notebook source cells In order to export a notebook, we need an way to create a Python file. ModuleMaker fills that role. Pass in the directory where you want to module created, the name of the module, the path of the notebook source, and set is_new to True if this is a new file being created (rather than an existing file being added to). The location of the saved module will be in fname . Finally, if the source in the notebooks should not be parsed by Python (such as partial class declarations in cells), parse should be set to False . Note: If doing so, then the __all__ generation will be turned off as well. mm = ModuleMaker ( dest = 'tmp' , name = 'test.testing' , nb_path = Path . cwd () / '01_export.ipynb' , is_new = True ) mm . fname Path('tmp/test/testing.py') source","title":"ModuleMaker"},{"location":"api/maker/#decor_id","text":"decor_id (d) id attr of decorator, regardless of whether called as function or bare source","title":"decor_id"},{"location":"api/maker/#modulemakermake_all","text":"ModuleMaker.make_all (cells) Create __all__ with all exports in cells source","title":"ModuleMaker.make_all"},{"location":"api/maker/#make_code_cells","text":"make_code_cells (*ss) We want to add an __all__ to the top of the exported module. This methods autogenerates it from all code in cells . nb = make_code_cells ( \"from __future__ import print_function\" , \"def a():...\" , \"def b():...\" , \"c=d=1\" , \"_f=1\" , \"_g=1\" , \"_h=1\" , \"_all_=['_g', _h]\" , \"@patch \\n def h(self:ca):...\" ) test_eq ( set ( mm . make_all ( nb )), set ([ 'a' , 'b' , 'c' , 'd' , '_g' , '_h' ])) source","title":"make_code_cells"},{"location":"api/maker/#relative_import","text":"relative_import (name, fname, level=0) Convert a module name to a name relative to fname test_eq ( relative_import ( 'nbdev.core' , \"xyz\" ), 'nbdev.core' ) test_eq ( relative_import ( 'nbdev.core' , 'nbdev' ), '.core' ) _p = Path ( 'fastai' ) test_eq ( relative_import ( 'fastai.core' , _p / 'vision' ), '..core' ) test_eq ( relative_import ( 'fastai.core' , _p / 'vision/transform' ), '...core' ) test_eq ( relative_import ( 'fastai.vision.transform' , _p / 'vision' ), '.transform' ) test_eq ( relative_import ( 'fastai.notebook.core' , _p / 'data' ), '..notebook.core' ) test_eq ( relative_import ( 'fastai.vision' , _p / 'vision' ), '.' ) test_eq ( relative_import ( 'fastai' , _p ), '.' ) test_eq ( relative_import ( 'fastai' , _p / 'vision' ), '..' ) test_eq ( relative_import ( 'fastai' , _p / 'vision/transform' ), '...' ) source","title":"relative_import"},{"location":"api/maker/#nbcellimport2relative","text":"NbCell.import2relative (cell:execnb.nbio.NbCell, libname) source","title":"NbCell.import2relative"},{"location":"api/maker/#update_import","text":"update_import (source, tree, libname, f=<function relative_import>) ss = \"from nbdev.export import * \\n from nbdev.a.b import *\" cell = make_code_cells ([ ss ])[ 0 ] cell . import2relative ( 'nbdev' ) test_eq ( cell . source , 'from .export import * \\n from .a.b import *' ) cell = make_code_cells ([ ss ])[ 0 ] cell . import2relative ( 'nbdev/a' ) test_eq ( cell . source , 'from ..export import * \\n from .b import *' ) source","title":"update_import"},{"location":"api/maker/#modulemakermake","text":"ModuleMaker.make (cells, all_cells=None, lib_path=None) Write module containing cells with __all__ generated from all_cells cells = make_code_cells ( \"from __future__ import print_function\" , \"_doc_ = 'module docstring here'\" , \"#|export \\n def a(): ...\" , \"def b(): ...\" ) mm . make ( cells , L ([ cells [ 2 ]])) show_src ( Path ( 'tmp/test/testing.py' ) . read_text ()) \"\"\"module docstring here\"\"\" # AUTOGENERATED! DO NOT EDIT! File to edit: ../../01_export.ipynb. # %% ../../01_export.ipynb 0 from __future__ import print_function # %% auto 0 __all__ = [ 'a' ] # %% ../../01_export.ipynb 1 _doc_ = 'module docstring here' # %% ../../01_export.ipynb 2 #|export def a (): ... # %% ../../01_export.ipynb 3 def b (): ... Pass all_cells=[] or parse=False if you don\u2019t want any __all__ added. Passing parse=False is also handy for when writing broken up functions or classes that ast.parse might not like but still want it to be exported, such as having a cell with: #|export class A : Note that by doing so we cannot properly generate a __all__ , so we assume that it is unwanted. am = ModuleMaker ( dest = 'tmp' , name = 'test.testing_noall' , nb_path = Path . cwd () / '01_export.ipynb' , is_new = True , parse = False ) am . fname Path('tmp/test/testing_noall.py') cells = make_code_cells ( \"from __future__ import print_function\" , \"#|export \\n def a(): ...\" , \"#|export \\n class A:\" ) am . make ( cells ) show_src ( Path ( 'tmp/test/testing_noall.py' ) . read_text ()) # AUTOGENERATED! DO NOT EDIT! File to edit: ../../01_export.ipynb. # %% ../../01_export.ipynb 0 from __future__ import print_function # %% ../../01_export.ipynb 1 #|export def a (): ... # %% ../../01_export.ipynb 2 #|export class A : If is_new=False then the additional definitions are added to the bottom, and any existing __all__ is updated with the newly-added symbols. c2 = make_code_cells ( \"def c(): ...\" , \"def d(): ...\" ) mm = ModuleMaker ( dest = 'tmp' , name = 'test.testing' , nb_path = Path . cwd () / '01_export.ipynb' , is_new = False ) mm . make ( c2 , c2 ) show_src ( Path ( 'tmp/test/testing.py' ) . read_text ()) \"\"\"module docstring here\"\"\" # AUTOGENERATED! DO NOT EDIT! File to edit: ../../01_export.ipynb. # %% ../../01_export.ipynb 0 from __future__ import print_function # %% auto 0 __all__ = [ 'a' , 'c' , 'd' ] # %% ../../01_export.ipynb 1 _doc_ = 'module docstring here' # %% ../../01_export.ipynb 2 #|export def a (): ... # %% ../../01_export.ipynb 3 def b (): ... # %% ../../01_export.ipynb 0 def c (): ... # %% ../../01_export.ipynb 1 def d (): ... try : g = exec_import ( 'tmp.test.testing' , '*' ) for s in \"a c d\" . split (): assert s in g , s assert 'b' not in g assert g [ 'a' ]() is None finally : shutil . rmtree ( 'tmp' )","title":"ModuleMaker.make"},{"location":"api/merge/","text":"merge \u00a4 Introduction \u00a4 When working with jupyter notebooks (which are json files behind the scenes) and GitHub, it is very common that a merge conflict (that will add new lines in the notebook source file) will break some notebooks you are working on. This module defines the function nbdev_fix to fix those notebooks for you, and attempt to automatically merge standard conflicts. The remaining ones will be delimited by markdown cells like this: <<<<<< HEAD # local code here ====== # remote code here >>>>>> a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35 Below is an example of broken notebook. The json format is broken by the lines automatically added by git. Such a file can\u2019t be opened in jupyter notebook. broken = Path ( '../../tests/example.ipynb.broken' ) tst_nb = broken . read_text () print ( tst_nb ) { \"cells\": [ { \"cell_type\": \"code\", \"execution_count\": 6, \"metadata\": {}, \"outputs\": [ { \"data\": { \"text/plain\": [ \"3\" ] }, \"execution_count\": 6, \"metadata\": {}, \"output_type\": \"execute_result\" } ], \"source\": [ <<<<<<< HEAD \"z=3\\n\", ======= \"z=2\\n\", >>>>>>> a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35 \"z\" ] }, { \"cell_type\": \"code\", \"execution_count\": 7, \"execution_count\": 5, \"metadata\": {}, \"outputs\": [ { \"data\": { \"text/plain\": [ \"6\" ] }, <<<<<<< HEAD \"execution_count\": 7, ======= \"execution_count\": 5, >>>>>>> a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35 \"metadata\": {}, \"output_type\": \"execute_result\" } ], \"source\": [ \"x=3\\n\", \"y=3\\n\", \"x+y\" ] }, { \"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [] } ], \"metadata\": { \"kernelspec\": { \"display_name\": \"Python 3\", \"language\": \"python\", \"name\": \"python3\" } }, \"nbformat\": 4, \"nbformat_minor\": 2 } Note that in this example, the second conflict is easily solved: it just concerns the execution count of the second cell and can be solved by choosing either option without really impacting your notebook. This is the kind of conflict we will fix automatically. The first conflict is more complicated as it spans across two cells and there is a cell present in one version, not the other. Such a conflict (and generally the ones where the inputs of the cells change form one version to the other) aren\u2019t automatically fixed, but we will return a proper json file where the annotations introduced by git will be placed in markdown cells. Creating a merged notebook \u00a4 The approach we use is to first \u201cunpatch\u201d the conflicted file, regenerating the two files it was originally created from. Then we redo the diff process, but using cells instead of text lines. source unpatch \u00a4 unpatch (s:str) Takes a string with conflict markers and returns the two original files, and their branch names The result of \u201cunpatching\u201d our conflicted test notebook is the two original notebooks it would have been created from. Each of these original notebooks will contain valid JSON: a , b , branch1 , branch2 = unpatch ( tst_nb ) dict2nb ( loads ( a )) { 'cells' : [ { 'cell_ t ype' : 'code' , 'execu t io n _cou nt ' : 6 , 'idx_' : 0 , 'me ta da ta ' : {}, 'ou t pu ts ' : [ { 'da ta ' : { ' te x t /plai n ' : [ ' 3 ' ]}, 'execu t io n _cou nt ' : 6 , 'me ta da ta ' : {}, 'ou t pu t _ t ype' : 'execu te _resul t ' }], 'source' : 'z= 3 \\ n z' }, { 'cell_ t ype' : 'code' , 'execu t io n _cou nt ' : 5 , 'idx_' : 1 , 'me ta da ta ' : {}, 'ou t pu ts ' : [ { 'da ta ' : { ' te x t /plai n ' : [ ' 6 ' ]}, 'execu t io n _cou nt ' : 7 , 'me ta da ta ' : {}, 'ou t pu t _ t ype' : 'execu te _resul t ' }], 'source' : 'x= 3 \\ n y= 3 \\ n x+y' }, { 'cell_ t ype' : 'code' , 'execu t io n _cou nt ' : No ne , 'idx_' : 2 , 'me ta da ta ' : {}, 'ou t pu ts ' : [], 'source' : '' }], 'me ta da ta ' : { 'ker nels pec' : { 'display_ na me' : 'Py t ho n 3 ' , 'la n guage' : 'py t ho n ' , ' na me' : 'py t ho n 3 ' }}, ' n b f orma t ' : 4 , ' n b f orma t _mi n or' : 2 } dict2nb ( loads ( b )) { 'cells' : [ { 'cell_ t ype' : 'code' , 'execu t io n _cou nt ' : 6 , 'idx_' : 0 , 'me ta da ta ' : {}, 'ou t pu ts ' : [ { 'da ta ' : { ' te x t /plai n ' : [ ' 3 ' ]}, 'execu t io n _cou nt ' : 6 , 'me ta da ta ' : {}, 'ou t pu t _ t ype' : 'execu te _resul t ' }], 'source' : 'z= 2 \\ n z' }, { 'cell_ t ype' : 'code' , 'execu t io n _cou nt ' : 5 , 'idx_' : 1 , 'me ta da ta ' : {}, 'ou t pu ts ' : [ { 'da ta ' : { ' te x t /plai n ' : [ ' 6 ' ]}, 'execu t io n _cou nt ' : 5 , 'me ta da ta ' : {}, 'ou t pu t _ t ype' : 'execu te _resul t ' }], 'source' : 'x= 3 \\ n y= 3 \\ n x+y' }, { 'cell_ t ype' : 'code' , 'execu t io n _cou nt ' : No ne , 'idx_' : 2 , 'me ta da ta ' : {}, 'ou t pu ts ' : [], 'source' : '' }], 'me ta da ta ' : { 'ker nels pec' : { 'display_ na me' : 'Py t ho n 3 ' , 'la n guage' : 'py t ho n ' , ' na me' : 'py t ho n 3 ' }}, ' n b f orma t ' : 4 , ' n b f orma t _mi n or' : 2 } branch1 , branch2 ('HEAD', 'a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35') source nbdev_fix \u00a4 nbdev_fix (nbname:str, outname:str=None, nobackup:<function bool_arg>=True, theirs:bool=False, noprint:bool=False) Create working notebook from conflicted notebook nbname Type Default Details nbname str Notebook filename to fix outname str None Filename of output notebook (defaults to nbname ) nobackup bool_arg True Do not backup nbname to nbname .bak if outname not provided theirs bool False Use their outputs and metadata instead of ours noprint bool False Do not print info about whether conflicts are found This begins by optionally backing the notebook fname to fname.bak in case something goes wrong. Then it parses the broken json, solving conflicts in cells. Every conflict that only involves metadata or outputs of cells will be solved automatically by using the local ( theirs==False ) or the remote ( theirs==True ) branch. Otherwise, or for conflicts involving the inputs of cells, the json will be repaired by including the two version of the conflicted cell(s) with markdown cells indicating the conflicts. You will be able to open the notebook again and search for the conflicts (look for <<<<<<< ) then fix them as you wish. A message will be printed indicating whether the notebook was fully merged or if conflicts remain. nbdev_fix ( broken , outname = 'tmp.ipynb' ) chk = read_nb ( 'tmp.ipynb' ) test_eq ( len ( chk . cells ), 7 ) os . unlink ( 'tmp.ipynb' ) One or more conflict remains in the notebook, please inspect manually. Git merge driver \u00a4 source nbdev_merge \u00a4 nbdev_merge (base:str, ours:str, theirs:str, path:str) Git merge driver for notebooks This implements a git merge driver for notebooks that automatically resolves conflicting metadata and outputs, and splits remaining conflicts as separate cells so that the notebook can be viewed and fixed in Jupyter. The easiest way to install it is by running nbdev_install_hooks . This works by first running Git\u2019s default merge driver, and then nbdev_fix if there are still conflicts. You can set nbdev_fix \u2019s theirs argument using the THEIRS environment variable, for example: THEIRS=True git merge branch","title":"merge"},{"location":"api/merge/#merge","text":"","title":"merge"},{"location":"api/merge/#introduction","text":"When working with jupyter notebooks (which are json files behind the scenes) and GitHub, it is very common that a merge conflict (that will add new lines in the notebook source file) will break some notebooks you are working on. This module defines the function nbdev_fix to fix those notebooks for you, and attempt to automatically merge standard conflicts. The remaining ones will be delimited by markdown cells like this: <<<<<< HEAD # local code here ====== # remote code here >>>>>> a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35 Below is an example of broken notebook. The json format is broken by the lines automatically added by git. Such a file can\u2019t be opened in jupyter notebook. broken = Path ( '../../tests/example.ipynb.broken' ) tst_nb = broken . read_text () print ( tst_nb ) { \"cells\": [ { \"cell_type\": \"code\", \"execution_count\": 6, \"metadata\": {}, \"outputs\": [ { \"data\": { \"text/plain\": [ \"3\" ] }, \"execution_count\": 6, \"metadata\": {}, \"output_type\": \"execute_result\" } ], \"source\": [ <<<<<<< HEAD \"z=3\\n\", ======= \"z=2\\n\", >>>>>>> a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35 \"z\" ] }, { \"cell_type\": \"code\", \"execution_count\": 7, \"execution_count\": 5, \"metadata\": {}, \"outputs\": [ { \"data\": { \"text/plain\": [ \"6\" ] }, <<<<<<< HEAD \"execution_count\": 7, ======= \"execution_count\": 5, >>>>>>> a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35 \"metadata\": {}, \"output_type\": \"execute_result\" } ], \"source\": [ \"x=3\\n\", \"y=3\\n\", \"x+y\" ] }, { \"cell_type\": \"code\", \"execution_count\": null, \"metadata\": {}, \"outputs\": [], \"source\": [] } ], \"metadata\": { \"kernelspec\": { \"display_name\": \"Python 3\", \"language\": \"python\", \"name\": \"python3\" } }, \"nbformat\": 4, \"nbformat_minor\": 2 } Note that in this example, the second conflict is easily solved: it just concerns the execution count of the second cell and can be solved by choosing either option without really impacting your notebook. This is the kind of conflict we will fix automatically. The first conflict is more complicated as it spans across two cells and there is a cell present in one version, not the other. Such a conflict (and generally the ones where the inputs of the cells change form one version to the other) aren\u2019t automatically fixed, but we will return a proper json file where the annotations introduced by git will be placed in markdown cells.","title":"Introduction"},{"location":"api/merge/#creating-a-merged-notebook","text":"The approach we use is to first \u201cunpatch\u201d the conflicted file, regenerating the two files it was originally created from. Then we redo the diff process, but using cells instead of text lines. source","title":"Creating a merged notebook"},{"location":"api/merge/#unpatch","text":"unpatch (s:str) Takes a string with conflict markers and returns the two original files, and their branch names The result of \u201cunpatching\u201d our conflicted test notebook is the two original notebooks it would have been created from. Each of these original notebooks will contain valid JSON: a , b , branch1 , branch2 = unpatch ( tst_nb ) dict2nb ( loads ( a )) { 'cells' : [ { 'cell_ t ype' : 'code' , 'execu t io n _cou nt ' : 6 , 'idx_' : 0 , 'me ta da ta ' : {}, 'ou t pu ts ' : [ { 'da ta ' : { ' te x t /plai n ' : [ ' 3 ' ]}, 'execu t io n _cou nt ' : 6 , 'me ta da ta ' : {}, 'ou t pu t _ t ype' : 'execu te _resul t ' }], 'source' : 'z= 3 \\ n z' }, { 'cell_ t ype' : 'code' , 'execu t io n _cou nt ' : 5 , 'idx_' : 1 , 'me ta da ta ' : {}, 'ou t pu ts ' : [ { 'da ta ' : { ' te x t /plai n ' : [ ' 6 ' ]}, 'execu t io n _cou nt ' : 7 , 'me ta da ta ' : {}, 'ou t pu t _ t ype' : 'execu te _resul t ' }], 'source' : 'x= 3 \\ n y= 3 \\ n x+y' }, { 'cell_ t ype' : 'code' , 'execu t io n _cou nt ' : No ne , 'idx_' : 2 , 'me ta da ta ' : {}, 'ou t pu ts ' : [], 'source' : '' }], 'me ta da ta ' : { 'ker nels pec' : { 'display_ na me' : 'Py t ho n 3 ' , 'la n guage' : 'py t ho n ' , ' na me' : 'py t ho n 3 ' }}, ' n b f orma t ' : 4 , ' n b f orma t _mi n or' : 2 } dict2nb ( loads ( b )) { 'cells' : [ { 'cell_ t ype' : 'code' , 'execu t io n _cou nt ' : 6 , 'idx_' : 0 , 'me ta da ta ' : {}, 'ou t pu ts ' : [ { 'da ta ' : { ' te x t /plai n ' : [ ' 3 ' ]}, 'execu t io n _cou nt ' : 6 , 'me ta da ta ' : {}, 'ou t pu t _ t ype' : 'execu te _resul t ' }], 'source' : 'z= 2 \\ n z' }, { 'cell_ t ype' : 'code' , 'execu t io n _cou nt ' : 5 , 'idx_' : 1 , 'me ta da ta ' : {}, 'ou t pu ts ' : [ { 'da ta ' : { ' te x t /plai n ' : [ ' 6 ' ]}, 'execu t io n _cou nt ' : 5 , 'me ta da ta ' : {}, 'ou t pu t _ t ype' : 'execu te _resul t ' }], 'source' : 'x= 3 \\ n y= 3 \\ n x+y' }, { 'cell_ t ype' : 'code' , 'execu t io n _cou nt ' : No ne , 'idx_' : 2 , 'me ta da ta ' : {}, 'ou t pu ts ' : [], 'source' : '' }], 'me ta da ta ' : { 'ker nels pec' : { 'display_ na me' : 'Py t ho n 3 ' , 'la n guage' : 'py t ho n ' , ' na me' : 'py t ho n 3 ' }}, ' n b f orma t ' : 4 , ' n b f orma t _mi n or' : 2 } branch1 , branch2 ('HEAD', 'a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35') source","title":"unpatch"},{"location":"api/merge/#nbdev_fix","text":"nbdev_fix (nbname:str, outname:str=None, nobackup:<function bool_arg>=True, theirs:bool=False, noprint:bool=False) Create working notebook from conflicted notebook nbname Type Default Details nbname str Notebook filename to fix outname str None Filename of output notebook (defaults to nbname ) nobackup bool_arg True Do not backup nbname to nbname .bak if outname not provided theirs bool False Use their outputs and metadata instead of ours noprint bool False Do not print info about whether conflicts are found This begins by optionally backing the notebook fname to fname.bak in case something goes wrong. Then it parses the broken json, solving conflicts in cells. Every conflict that only involves metadata or outputs of cells will be solved automatically by using the local ( theirs==False ) or the remote ( theirs==True ) branch. Otherwise, or for conflicts involving the inputs of cells, the json will be repaired by including the two version of the conflicted cell(s) with markdown cells indicating the conflicts. You will be able to open the notebook again and search for the conflicts (look for <<<<<<< ) then fix them as you wish. A message will be printed indicating whether the notebook was fully merged or if conflicts remain. nbdev_fix ( broken , outname = 'tmp.ipynb' ) chk = read_nb ( 'tmp.ipynb' ) test_eq ( len ( chk . cells ), 7 ) os . unlink ( 'tmp.ipynb' ) One or more conflict remains in the notebook, please inspect manually.","title":"nbdev_fix"},{"location":"api/merge/#git-merge-driver","text":"source","title":"Git merge driver"},{"location":"api/merge/#nbdev_merge","text":"nbdev_merge (base:str, ours:str, theirs:str, path:str) Git merge driver for notebooks This implements a git merge driver for notebooks that automatically resolves conflicting metadata and outputs, and splits remaining conflicts as separate cells so that the notebook can be viewed and fixed in Jupyter. The easiest way to install it is by running nbdev_install_hooks . This works by first running Git\u2019s default merge driver, and then nbdev_fix if there are still conflicts. You can set nbdev_fix \u2019s theirs argument using the THEIRS environment variable, for example: THEIRS=True git merge branch","title":"nbdev_merge"},{"location":"api/migrate/","text":"migrate \u00a4 Migrate notebooks \u00a4 source MigrateProc \u00a4 MigrateProc (nb) Migrate fastpages front matter in notebooks to a raw cell. Before you migrate the fastpages notebook, the front matter is specified in Markdown like this: _tst_nb = '../../tests/2020-09-01-fastcore.ipynb' print ( read_nb ( _tst_nb ) . cells [ 0 ] . source ) # \"fastcore: An Underrated Python Library\" > A unique python library that extends the python programming language and provides utilities that enhance productivity. - author: \"<a href='https://twitter.com/HamelHusain'>Hamel Husain</a>\" - toc: false - image: images/copied_from_nb/fastcore_imgs/td.png - comments: true - search_exclude: true - hide: true - categories: [fastcore, fastai] - permalink: /fastcore/ - badges: true After migrating the notebook, the front matter is moved to a raw cell, and some of the fields are converted to be compliant with Quarto. Furthermore, aliases may be added in order to prevent broken links: nbp = NBProcessor ( '../../tests/2020-09-01-fastcore.ipynb' , procs = [ FrontmatterProc , MigrateProc ]) nbp . process () _fm1 = _get_raw_fm ( nbp . nb ) print ( _fm1 ) --- aliases: - /fastcore/ author: <a href='https://twitter.com/HamelHusain'>Hamel Husain</a> badges: true categories: - fastcore - fastai date: '2020-09-01' description: A unique python library that extends the python programming language and provides utilities that enhance productivity. draft: 'true' image: fastcore_imgs/td.png output-file: 2020-09-01-fastcore.html permalink: /fastcore/ search: 'false' title: 'fastcore: An Underrated Python Library' toc: false --- Migrate Fastpages Markdown Front Matter \u00a4 source fp_md_fm \u00a4 fp_md_fm (path) Make fastpages front matter in markdown files quarto compliant. Here is what the front matter of a fastpages markdown post looks like before migration: print ( run ( 'head -n13 ../../tests/2020-01-14-test-markdown-post.md' )) --- toc: true layout: post description: A minimal example of using markdown with fastpages. categories: [markdown] title: An Example Markdown Post --- # Example Markdown Post And this is what it looks like after migration: _res = fp_md_fm ( '../../tests/2020-01-14-test-markdown-post.md' ) print ( _res [: 300 ]) --- aliases: - /markdown/2020/01/14/test-markdown-post categories: - markdown date: '2020-01-14' description: A minimal example of using markdown with fastpages. layout: post title: An Example Markdown Post toc: true --- # Example Markdown Post ## Basic setup Jekyll requires blog post files to b #hide _res = fp_md_fm ( '../../tests/2022-09-06-homeschooling.md' ) test_eq ( _res , \"\"\"--- aliases: - /2022/09/06/homeschooling author: Rachel Thomas categories: - advice - health date: '2022-09-06' description: You can permanently damage your back, neck, and wrists from working without an ergonomic setup. Learn how to create one for less at home. image: /images/ergonomic1-short.jpg summary: You can permanently damage your back, neck, and wrists from working without an ergonomic setup. Learn how to create one for less at home. tags: advice health title: 'Essential Work-From-Home Advice: Cheap and Easy Ergonomic Setups' --- Lorem ipsum \"\"\" ) Convert nbdev v1 projects to nbdev v2 \u00a4 Directives \u00a4 nbdev v2 directives start with a #| whereas v1 directives were comments without a pipe | . _test_dir = \"\"\" #default_exp #export # collapse-show #collapse-hide #collapse # collapse_output not_dir='#export' # hide_input foo # hide \"\"\" test_eq ( _repl_directives ( _test_dir ), \"\"\" #| default_exp #| export #| code-fold: show #| code-fold: true #| code-fold: true # collapse_output not_dir='#export' #| echo: false foo #| include: false \"\"\" ) source _repl_v1dir \u00a4 _repl_v1dir (cell) Replace nbdev v1 with v2 directives. for example, if any of the lines below are valid nbdev v1 directives, they replaced with a #| , but only before the first line of code: Callouts \u00a4 In fastpages, there was a markdown shortuct for callouts for Note , Tip , Important and Warning with block quotes (these only worked in notebooks). Since Quarto has its own callout blocks with markdown syntax, we do not implement these shortcuts in nbdev. Instead, we offer a manual conversion utility for these callouts so that you can migrate from fastpages to Quarto. source _convert_callout \u00a4 _convert_callout (s) Convert nbdev v1 to v2 callouts. For example, the below markdown: _callouts = \"\"\" ## Boxes / Callouts > Warning: There will be no second warning! Other text > Important: Pay attention! It's important. > Tip: This is my tip. > Note: Take note of `this.` \"\"\" Gets converted to: ## Boxes / Callouts :::{.callout-warning} There will be no second warning! ::: Other text :::{.callout-important} Pay attention! It's important. ::: Video Embeds \u00a4 In fastpages, you could embed videos with a simple markdown shortcut involving a block quote with the prefix youtube: , that looked like this > youtube: https://youtu.be/XfoYk_Z5AkI However, in Quarto you can use the video extension to embed videos. source _convert_video \u00a4 _convert_video (s) Replace nbdev v1 with v2 video embeds. _videos = \"\"\" ## Videos > youtube: https://youtu.be/XfoYk_Z5AkI \"\"\" print ( _convert_video ( _videos )) ## Videos https://youtu.be/XfoYk_Z5AkI source migrate_nb \u00a4 migrate_nb (path, overwrite=True) Migrate Notebooks from nbdev v1 and fastpages. source migrate_md \u00a4 migrate_md (path, overwrite=True) Migrate Markdown Files from fastpages. source nbdev_migrate \u00a4 nbdev_migrate (path:str=None, no_skip:bool=False) Convert all markdown and notebook files in path from v1 to v2 Type Default Details path str None A path or glob containing notebooks and markdown files to migrate no_skip bool False Do not skip directories beginning with an underscore","title":"migrate"},{"location":"api/migrate/#migrate","text":"","title":"migrate"},{"location":"api/migrate/#migrate-notebooks","text":"source","title":"Migrate notebooks"},{"location":"api/migrate/#migrateproc","text":"MigrateProc (nb) Migrate fastpages front matter in notebooks to a raw cell. Before you migrate the fastpages notebook, the front matter is specified in Markdown like this: _tst_nb = '../../tests/2020-09-01-fastcore.ipynb' print ( read_nb ( _tst_nb ) . cells [ 0 ] . source ) # \"fastcore: An Underrated Python Library\" > A unique python library that extends the python programming language and provides utilities that enhance productivity. - author: \"<a href='https://twitter.com/HamelHusain'>Hamel Husain</a>\" - toc: false - image: images/copied_from_nb/fastcore_imgs/td.png - comments: true - search_exclude: true - hide: true - categories: [fastcore, fastai] - permalink: /fastcore/ - badges: true After migrating the notebook, the front matter is moved to a raw cell, and some of the fields are converted to be compliant with Quarto. Furthermore, aliases may be added in order to prevent broken links: nbp = NBProcessor ( '../../tests/2020-09-01-fastcore.ipynb' , procs = [ FrontmatterProc , MigrateProc ]) nbp . process () _fm1 = _get_raw_fm ( nbp . nb ) print ( _fm1 ) --- aliases: - /fastcore/ author: <a href='https://twitter.com/HamelHusain'>Hamel Husain</a> badges: true categories: - fastcore - fastai date: '2020-09-01' description: A unique python library that extends the python programming language and provides utilities that enhance productivity. draft: 'true' image: fastcore_imgs/td.png output-file: 2020-09-01-fastcore.html permalink: /fastcore/ search: 'false' title: 'fastcore: An Underrated Python Library' toc: false ---","title":"MigrateProc"},{"location":"api/migrate/#migrate-fastpages-markdown-front-matter","text":"source","title":"Migrate Fastpages Markdown Front Matter"},{"location":"api/migrate/#fp_md_fm","text":"fp_md_fm (path) Make fastpages front matter in markdown files quarto compliant. Here is what the front matter of a fastpages markdown post looks like before migration: print ( run ( 'head -n13 ../../tests/2020-01-14-test-markdown-post.md' )) --- toc: true layout: post description: A minimal example of using markdown with fastpages. categories: [markdown] title: An Example Markdown Post --- # Example Markdown Post And this is what it looks like after migration: _res = fp_md_fm ( '../../tests/2020-01-14-test-markdown-post.md' ) print ( _res [: 300 ]) --- aliases: - /markdown/2020/01/14/test-markdown-post categories: - markdown date: '2020-01-14' description: A minimal example of using markdown with fastpages. layout: post title: An Example Markdown Post toc: true --- # Example Markdown Post ## Basic setup Jekyll requires blog post files to b #hide _res = fp_md_fm ( '../../tests/2022-09-06-homeschooling.md' ) test_eq ( _res , \"\"\"--- aliases: - /2022/09/06/homeschooling author: Rachel Thomas categories: - advice - health date: '2022-09-06' description: You can permanently damage your back, neck, and wrists from working without an ergonomic setup. Learn how to create one for less at home. image: /images/ergonomic1-short.jpg summary: You can permanently damage your back, neck, and wrists from working without an ergonomic setup. Learn how to create one for less at home. tags: advice health title: 'Essential Work-From-Home Advice: Cheap and Easy Ergonomic Setups' --- Lorem ipsum \"\"\" )","title":"fp_md_fm"},{"location":"api/migrate/#convert-nbdev-v1-projects-to-nbdev-v2","text":"","title":"Convert nbdev v1 projects to nbdev v2"},{"location":"api/migrate/#directives","text":"nbdev v2 directives start with a #| whereas v1 directives were comments without a pipe | . _test_dir = \"\"\" #default_exp #export # collapse-show #collapse-hide #collapse # collapse_output not_dir='#export' # hide_input foo # hide \"\"\" test_eq ( _repl_directives ( _test_dir ), \"\"\" #| default_exp #| export #| code-fold: show #| code-fold: true #| code-fold: true # collapse_output not_dir='#export' #| echo: false foo #| include: false \"\"\" ) source","title":"Directives"},{"location":"api/migrate/#_repl_v1dir","text":"_repl_v1dir (cell) Replace nbdev v1 with v2 directives. for example, if any of the lines below are valid nbdev v1 directives, they replaced with a #| , but only before the first line of code:","title":"_repl_v1dir"},{"location":"api/migrate/#callouts","text":"In fastpages, there was a markdown shortuct for callouts for Note , Tip , Important and Warning with block quotes (these only worked in notebooks). Since Quarto has its own callout blocks with markdown syntax, we do not implement these shortcuts in nbdev. Instead, we offer a manual conversion utility for these callouts so that you can migrate from fastpages to Quarto. source","title":"Callouts"},{"location":"api/migrate/#_convert_callout","text":"_convert_callout (s) Convert nbdev v1 to v2 callouts. For example, the below markdown: _callouts = \"\"\" ## Boxes / Callouts > Warning: There will be no second warning! Other text > Important: Pay attention! It's important. > Tip: This is my tip. > Note: Take note of `this.` \"\"\" Gets converted to: ## Boxes / Callouts :::{.callout-warning} There will be no second warning! ::: Other text :::{.callout-important} Pay attention! It's important. :::","title":"_convert_callout"},{"location":"api/migrate/#video-embeds","text":"In fastpages, you could embed videos with a simple markdown shortcut involving a block quote with the prefix youtube: , that looked like this > youtube: https://youtu.be/XfoYk_Z5AkI However, in Quarto you can use the video extension to embed videos. source","title":"Video Embeds"},{"location":"api/migrate/#_convert_video","text":"_convert_video (s) Replace nbdev v1 with v2 video embeds. _videos = \"\"\" ## Videos > youtube: https://youtu.be/XfoYk_Z5AkI \"\"\" print ( _convert_video ( _videos )) ## Videos https://youtu.be/XfoYk_Z5AkI source","title":"_convert_video"},{"location":"api/migrate/#migrate_nb","text":"migrate_nb (path, overwrite=True) Migrate Notebooks from nbdev v1 and fastpages. source","title":"migrate_nb"},{"location":"api/migrate/#migrate_md","text":"migrate_md (path, overwrite=True) Migrate Markdown Files from fastpages. source","title":"migrate_md"},{"location":"api/migrate/#nbdev_migrate","text":"nbdev_migrate (path:str=None, no_skip:bool=False) Convert all markdown and notebook files in path from v1 to v2 Type Default Details path str None A path or glob containing notebooks and markdown files to migrate no_skip bool False Do not skip directories beginning with an underscore","title":"nbdev_migrate"},{"location":"api/process/","text":"process \u00a4 Special comments at the start of a cell can be used to provide information to nbdev about how to process a cell, so we need to be able to find the location of these comments. minimal = read_nb ( '../../tests/minimal.ipynb' ) source nb_lang \u00a4 nb_lang (nb) source first_code_ln \u00a4 first_code_ln (code_list, re_pattern=None, lang='python') get first line number where code occurs, where code_list is a list of code _tst = \"\"\" #|default_exp #|export #|hide_input foo \"\"\" test_eq ( first_code_ln ( _tst . splitlines ( True )), 4 ) source extract_directives \u00a4 extract_directives (cell, remove=True, lang='python') Take leading comment directives from lines of code in ss , remove #| , and split Comment directives start with #| , followed by whitespace delimited tokens, which extract_directives extracts from the start of a cell, up until a blank line or a line containing something other than comments. The extracted lines are removed from the source. exp = AttrDict ( source = \"\"\"#|export module #|eval:false #| hide # | foo bar # |woo: baz 1+2 #bar\"\"\" ) test_eq ( extract_directives ( exp ), { 'export' :[ 'module' ], 'hide' :[], 'eval:' : [ 'false' ], 'foo' : [ 'bar' ], 'woo:' : [ 'baz' ]}) test_eq ( exp . source , '#|eval: false \\n # |woo: baz \\n 1+2 \\n #bar' ) source opt_set \u00a4 opt_set (var, newval) newval if newval else var source instantiate \u00a4 instantiate (x, **kwargs) Instantiate x if it\u2019s a type source NBProcessor \u00a4 NBProcessor (path=None, procs=None, nb=None, debug=False, rm_directives=True, process=False) Process cells and nbdev comments in a notebook Cell processors can be callables (e.g regular functions), in which case they are called for every cell (set a cell\u2019s source to None to remove the cell): everything_fn = '../../tests/01_everything.ipynb' def print_execs ( cell ): if 'exec' in cell . source : print ( cell . source ) NBProcessor ( everything_fn , print_execs ) . process () --- title: Foo execute: echo: false --- exec(\"o_y=1\") exec(\"p_y=1\") _all_ = [o_y, 'p_y'] Comment directives are put in a cell attribute directive_ as a dictionary keyed by directive name: def printme_func ( cell ): if cell . directives_ and 'printme' in cell . directives_ : print ( cell . directives_ [ 'printme' ]) NBProcessor ( everything_fn , printme_func ) . process () ['testing'] However, a more convenient way to handle comment directives is to use a class as a processor, and include a method in your class with the same name as your directive, surrounded by underscores: class _PrintExample : def _printme_ ( self , cell , to_print ): print ( to_print ) NBProcessor ( everything_fn , _PrintExample ()) . process () testing In the case that your processor supports just one comment directive, you can just use a regular function, with the same name as your directive, but with an underscore appended \u2013 here printme_ is identical to _PrintExample above: def printme_ ( cell , to_print ): print ( to_print ) NBProcessor ( everything_fn , printme_ ) . process () testing NBProcessor ( everything_fn , _PrintExample ()) . process () testing source Processor \u00a4 Processor (nb) Base class for processors For more complex behavior, inherit from Processor , and override one of more of begin() (called before any cells are processed), cell() (called for each cell), and end() (called after all cells are processed). You can also include comment directives (such as the _printme example above) in these subclasses. Subclasses will automatically have access to self.nb , containing the processed notebook. class CountCellProcessor ( Processor ): def begin ( self ): print ( f \"First cell: \\n { self . nb . cells [ 0 ] . source } \" ) self . count = 0 def cell ( self , cell ): if cell . cell_type == 'code' : self . count += 1 def end ( self ): print ( f \"* There were { self . count } code cells\" ) NBProcessor ( everything_fn , CountCellProcessor ) . process () First cell: --- title: Foo execute: echo: false --- * There were 26 code cells","title":"process"},{"location":"api/process/#process","text":"Special comments at the start of a cell can be used to provide information to nbdev about how to process a cell, so we need to be able to find the location of these comments. minimal = read_nb ( '../../tests/minimal.ipynb' ) source","title":"process"},{"location":"api/process/#nb_lang","text":"nb_lang (nb) source","title":"nb_lang"},{"location":"api/process/#first_code_ln","text":"first_code_ln (code_list, re_pattern=None, lang='python') get first line number where code occurs, where code_list is a list of code _tst = \"\"\" #|default_exp #|export #|hide_input foo \"\"\" test_eq ( first_code_ln ( _tst . splitlines ( True )), 4 ) source","title":"first_code_ln"},{"location":"api/process/#extract_directives","text":"extract_directives (cell, remove=True, lang='python') Take leading comment directives from lines of code in ss , remove #| , and split Comment directives start with #| , followed by whitespace delimited tokens, which extract_directives extracts from the start of a cell, up until a blank line or a line containing something other than comments. The extracted lines are removed from the source. exp = AttrDict ( source = \"\"\"#|export module #|eval:false #| hide # | foo bar # |woo: baz 1+2 #bar\"\"\" ) test_eq ( extract_directives ( exp ), { 'export' :[ 'module' ], 'hide' :[], 'eval:' : [ 'false' ], 'foo' : [ 'bar' ], 'woo:' : [ 'baz' ]}) test_eq ( exp . source , '#|eval: false \\n # |woo: baz \\n 1+2 \\n #bar' ) source","title":"extract_directives"},{"location":"api/process/#opt_set","text":"opt_set (var, newval) newval if newval else var source","title":"opt_set"},{"location":"api/process/#instantiate","text":"instantiate (x, **kwargs) Instantiate x if it\u2019s a type source","title":"instantiate"},{"location":"api/process/#nbprocessor","text":"NBProcessor (path=None, procs=None, nb=None, debug=False, rm_directives=True, process=False) Process cells and nbdev comments in a notebook Cell processors can be callables (e.g regular functions), in which case they are called for every cell (set a cell\u2019s source to None to remove the cell): everything_fn = '../../tests/01_everything.ipynb' def print_execs ( cell ): if 'exec' in cell . source : print ( cell . source ) NBProcessor ( everything_fn , print_execs ) . process () --- title: Foo execute: echo: false --- exec(\"o_y=1\") exec(\"p_y=1\") _all_ = [o_y, 'p_y'] Comment directives are put in a cell attribute directive_ as a dictionary keyed by directive name: def printme_func ( cell ): if cell . directives_ and 'printme' in cell . directives_ : print ( cell . directives_ [ 'printme' ]) NBProcessor ( everything_fn , printme_func ) . process () ['testing'] However, a more convenient way to handle comment directives is to use a class as a processor, and include a method in your class with the same name as your directive, surrounded by underscores: class _PrintExample : def _printme_ ( self , cell , to_print ): print ( to_print ) NBProcessor ( everything_fn , _PrintExample ()) . process () testing In the case that your processor supports just one comment directive, you can just use a regular function, with the same name as your directive, but with an underscore appended \u2013 here printme_ is identical to _PrintExample above: def printme_ ( cell , to_print ): print ( to_print ) NBProcessor ( everything_fn , printme_ ) . process () testing NBProcessor ( everything_fn , _PrintExample ()) . process () testing source","title":"NBProcessor"},{"location":"api/process/#processor","text":"Processor (nb) Base class for processors For more complex behavior, inherit from Processor , and override one of more of begin() (called before any cells are processed), cell() (called for each cell), and end() (called after all cells are processed). You can also include comment directives (such as the _printme example above) in these subclasses. Subclasses will automatically have access to self.nb , containing the processed notebook. class CountCellProcessor ( Processor ): def begin ( self ): print ( f \"First cell: \\n { self . nb . cells [ 0 ] . source } \" ) self . count = 0 def cell ( self , cell ): if cell . cell_type == 'code' : self . count += 1 def end ( self ): print ( f \"* There were { self . count } code cells\" ) NBProcessor ( everything_fn , CountCellProcessor ) . process () First cell: --- title: Foo execute: echo: false --- * There were 26 code cells","title":"Processor"},{"location":"api/processors/","text":"processors \u00a4 On this page we\u2019ll be using this private helper to process a notebook and return the results, to simplify testing: def _run_procs ( procs = None , return_nb = False , path = _test_file ): nbp = NBProcessor ( path , procs ) nbp . process () if return_nb : return nbp . nb return ' \\n ' . join ([ str ( cell ) for cell in nbp . nb . cells ]) source populate_language \u00a4 populate_language (nb) Set cell language based on NB metadata and magics source insert_warning \u00a4 insert_warning (nb) Insert Autogenerated Warning Into Notebook after the first cell. This preprocessor inserts a warning in the markdown destination that the file is autogenerated. This warning is inserted in the second cell so we do not interfere with front matter. res = _run_procs ( insert_warning ) assert \"<!-- WARNING: THIS FILE WAS AUTOGENERATED!\" in res L ( 'foo' , None , 'a' ) . filter ( lambda x : x == 1 ) _tstre = re . compile ( 'a' ) source add_show_docs \u00a4 add_show_docs (nb) Add show_doc cells after exported cells, unless they are already documented source cell_lang \u00a4 cell_lang (cell) res = _run_procs ([ populate_language , add_show_docs ]) assert \"show_doc(some_func)'\" in res assert \"show_doc(and_another)'\" in res assert \"show_doc(another_func)'\" not in res source add_links \u00a4 add_links (cell) Add links to markdown cells res = _run_procs ( add_links ) assert \"[`numpy.array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array)\" in res assert \"[`ModuleMaker`](https://nbdev.fast.ai/api/maker.html#modulemaker) but not a link to `foobar`.\" in res assert \"A link in a docstring: [`ModuleMaker`](https://nbdev.fast.ai/api/maker.html#modulemaker).\" in res assert \"And not a link to <code>dict2nb</code>.\" in res Gets rid of colors that are streamed from standard out, which can interfere with static site generators: source strip_ansi \u00a4 strip_ansi (cell) Strip Ansi Characters. res = _run_procs ( strip_ansi ) assert not _re_ansi_escape . findall ( res ) source strip_hidden_metadata \u00a4 strip_hidden_metadata (cell) Strips \u201chidden\u201d metadata property from code cells so it doesn\u2019t interfere with docs rendering source hide_ \u00a4 hide_ (cell) Hide cell from output res = _run_procs ( hide_ ) assert 'you will not be able to see this cell at all either' not in res source hide_line \u00a4 hide_line (cell) Hide lines of code in code cells with the directive hide_line at the end of a line of code res = _run_procs ( hide_line ) assert r \"def show():\\n a = 2\\n b = 3\" not in res assert r \"def show():\\n a = 2\" in res source filter_stream_ \u00a4 filter_stream_ (cell, *words) Remove output lines containing any of words in cell stream output res = _run_procs ( filter_stream_ ) exp = r \"'A line\\n', 'Another line.\\n'\" assert exp in res source clean_magics \u00a4 clean_magics (cell) A preprocessor to remove cell magic commands res = _run_procs ( clean_magics ) assert \" %% \" not in res source rm_header_dash \u00a4 rm_header_dash (cell) Remove headings that end with a dash - res = _run_procs ( rm_header_dash ) assert 'some words' in res assert 'A heading to Hide' not in res assert 'Yet another heading to hide' not in res source rm_export \u00a4 rm_export (cell) Remove cells that are exported or hidden res = _run_procs ( rm_export ) assert 'dontshow' not in res source clean_show_doc \u00a4 clean_show_doc (cell) Remove ShowDoc input cells source exec_show_docs \u00a4 exec_show_docs (nb) Execute cells needed for show_docs output, including exported cells and imports res = _run_procs ([ add_show_docs , exec_show_docs ]) assert res source FilterDefaults \u00a4 FilterDefaults () Override FilterDefaults to change which notebook processors are used","title":"processors"},{"location":"api/processors/#processors","text":"On this page we\u2019ll be using this private helper to process a notebook and return the results, to simplify testing: def _run_procs ( procs = None , return_nb = False , path = _test_file ): nbp = NBProcessor ( path , procs ) nbp . process () if return_nb : return nbp . nb return ' \\n ' . join ([ str ( cell ) for cell in nbp . nb . cells ]) source","title":"processors"},{"location":"api/processors/#populate_language","text":"populate_language (nb) Set cell language based on NB metadata and magics source","title":"populate_language"},{"location":"api/processors/#insert_warning","text":"insert_warning (nb) Insert Autogenerated Warning Into Notebook after the first cell. This preprocessor inserts a warning in the markdown destination that the file is autogenerated. This warning is inserted in the second cell so we do not interfere with front matter. res = _run_procs ( insert_warning ) assert \"<!-- WARNING: THIS FILE WAS AUTOGENERATED!\" in res L ( 'foo' , None , 'a' ) . filter ( lambda x : x == 1 ) _tstre = re . compile ( 'a' ) source","title":"insert_warning"},{"location":"api/processors/#add_show_docs","text":"add_show_docs (nb) Add show_doc cells after exported cells, unless they are already documented source","title":"add_show_docs"},{"location":"api/processors/#cell_lang","text":"cell_lang (cell) res = _run_procs ([ populate_language , add_show_docs ]) assert \"show_doc(some_func)'\" in res assert \"show_doc(and_another)'\" in res assert \"show_doc(another_func)'\" not in res source","title":"cell_lang"},{"location":"api/processors/#add_links","text":"add_links (cell) Add links to markdown cells res = _run_procs ( add_links ) assert \"[`numpy.array`](https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array)\" in res assert \"[`ModuleMaker`](https://nbdev.fast.ai/api/maker.html#modulemaker) but not a link to `foobar`.\" in res assert \"A link in a docstring: [`ModuleMaker`](https://nbdev.fast.ai/api/maker.html#modulemaker).\" in res assert \"And not a link to <code>dict2nb</code>.\" in res Gets rid of colors that are streamed from standard out, which can interfere with static site generators: source","title":"add_links"},{"location":"api/processors/#strip_ansi","text":"strip_ansi (cell) Strip Ansi Characters. res = _run_procs ( strip_ansi ) assert not _re_ansi_escape . findall ( res ) source","title":"strip_ansi"},{"location":"api/processors/#strip_hidden_metadata","text":"strip_hidden_metadata (cell) Strips \u201chidden\u201d metadata property from code cells so it doesn\u2019t interfere with docs rendering source","title":"strip_hidden_metadata"},{"location":"api/processors/#hide_","text":"hide_ (cell) Hide cell from output res = _run_procs ( hide_ ) assert 'you will not be able to see this cell at all either' not in res source","title":"hide_"},{"location":"api/processors/#hide_line","text":"hide_line (cell) Hide lines of code in code cells with the directive hide_line at the end of a line of code res = _run_procs ( hide_line ) assert r \"def show():\\n a = 2\\n b = 3\" not in res assert r \"def show():\\n a = 2\" in res source","title":"hide_line"},{"location":"api/processors/#filter_stream_","text":"filter_stream_ (cell, *words) Remove output lines containing any of words in cell stream output res = _run_procs ( filter_stream_ ) exp = r \"'A line\\n', 'Another line.\\n'\" assert exp in res source","title":"filter_stream_"},{"location":"api/processors/#clean_magics","text":"clean_magics (cell) A preprocessor to remove cell magic commands res = _run_procs ( clean_magics ) assert \" %% \" not in res source","title":"clean_magics"},{"location":"api/processors/#rm_header_dash","text":"rm_header_dash (cell) Remove headings that end with a dash - res = _run_procs ( rm_header_dash ) assert 'some words' in res assert 'A heading to Hide' not in res assert 'Yet another heading to hide' not in res source","title":"rm_header_dash"},{"location":"api/processors/#rm_export","text":"rm_export (cell) Remove cells that are exported or hidden res = _run_procs ( rm_export ) assert 'dontshow' not in res source","title":"rm_export"},{"location":"api/processors/#clean_show_doc","text":"clean_show_doc (cell) Remove ShowDoc input cells source","title":"clean_show_doc"},{"location":"api/processors/#exec_show_docs","text":"exec_show_docs (nb) Execute cells needed for show_docs output, including exported cells and imports res = _run_procs ([ add_show_docs , exec_show_docs ]) assert res source","title":"exec_show_docs"},{"location":"api/processors/#filterdefaults","text":"FilterDefaults () Override FilterDefaults to change which notebook processors are used","title":"FilterDefaults"},{"location":"api/qmd/","text":"qmd \u00a4 source meta \u00a4 meta (md, classes=None, style=None, **kwargs) A metadata section for qmd div in {} Type Default Details md Markdown to add meta to classes NoneType None List of CSS classes to add style NoneType None Dict of CSS styles to add kwargs source div \u00a4 div (txt, classes=None, style=None, **kwargs) A qmd div with optional metadata section Type Default Details txt Markdown to add meta to classes NoneType None List of CSS classes to add style NoneType None Dict of CSS styles to add kwargs source img \u00a4 img (fname, classes=None, style=None, height=None, relative=None, link=False, **kwargs) A qmd image Type Default Details fname Image to link to classes NoneType None List of CSS classes to add style NoneType None Dict of CSS styles to add height NoneType None Height attribute relative NoneType None Tuple of (position,px) link bool False Hyperlink to this image kwargs source btn \u00a4 btn (txt, link, classes=None, style=None, **kwargs) A qmd button Type Default Details txt Button text link Button link URL classes NoneType None List of CSS classes to add style NoneType None Dict of CSS styles to add kwargs source tbl_row \u00a4 tbl_row (cols:list) Create a markdown table row from cols Type Details cols list Auto-stringified columns to show in the row source tbl_sep \u00a4 tbl_sep (sizes:Union[int,list]=3) Create a markdown table separator with relative column size sizes Type Default Details sizes int | list 3 List of column sizes, or single int if all sizes the same","title":"qmd"},{"location":"api/qmd/#qmd","text":"source","title":"qmd"},{"location":"api/qmd/#meta","text":"meta (md, classes=None, style=None, **kwargs) A metadata section for qmd div in {} Type Default Details md Markdown to add meta to classes NoneType None List of CSS classes to add style NoneType None Dict of CSS styles to add kwargs source","title":"meta"},{"location":"api/qmd/#div","text":"div (txt, classes=None, style=None, **kwargs) A qmd div with optional metadata section Type Default Details txt Markdown to add meta to classes NoneType None List of CSS classes to add style NoneType None Dict of CSS styles to add kwargs source","title":"div"},{"location":"api/qmd/#img","text":"img (fname, classes=None, style=None, height=None, relative=None, link=False, **kwargs) A qmd image Type Default Details fname Image to link to classes NoneType None List of CSS classes to add style NoneType None Dict of CSS styles to add height NoneType None Height attribute relative NoneType None Tuple of (position,px) link bool False Hyperlink to this image kwargs source","title":"img"},{"location":"api/qmd/#btn","text":"btn (txt, link, classes=None, style=None, **kwargs) A qmd button Type Default Details txt Button text link Button link URL classes NoneType None List of CSS classes to add style NoneType None Dict of CSS styles to add kwargs source","title":"btn"},{"location":"api/qmd/#tbl_row","text":"tbl_row (cols:list) Create a markdown table row from cols Type Details cols list Auto-stringified columns to show in the row source","title":"tbl_row"},{"location":"api/qmd/#tbl_sep","text":"tbl_sep (sizes:Union[int,list]=3) Create a markdown table separator with relative column size sizes Type Default Details sizes int | list 3 List of column sizes, or single int if all sizes the same","title":"tbl_sep"},{"location":"api/quarto/","text":"quarto \u00a4 Install \u00a4 source install_quarto \u00a4 install_quarto () Install latest Quarto on macOS or Linux, prints instructions for Windows source install \u00a4 install () Install Quarto and the current library Sidebar \u00a4 source nbdev_sidebar \u00a4 nbdev_sidebar (path:str=None, printit:bool=False, force:bool=False, skip_folder_re:str='(?:^[_.]|^www\\\\$)', file_glob:str=None, file_re:str='\\\\.(?:ipynb|qmd|html)$', symlinks:bool=False, folder_re:str=None, skip_file_glob:str=None, skip_file_re:str='^[_.]') Create sidebar.yml Type Default Details path str None Path to notebooks printit bool False Print YAML for debugging force bool False Create sidebar even if settings.ini custom_sidebar=False skip_folder_re str (?:^[_.]|^www$) Skip folders matching regex file_glob str None Only include files matching glob file_re str .(?:ipynb|qmd|html)$ Only include files matching regex symlinks bool False Follow symlinks? folder_re str None Only enter folders matching regex skip_file_glob str None Skip files matching glob skip_file_re str ^[_.] Skip files matching regex # nbdev_sidebar(printit=True, force=True) Render docs \u00a4 source refresh_quarto_yml \u00a4 refresh_quarto_yml () Generate _quarto.yml from settings.ini . source nbdev_proc_nbs \u00a4 nbdev_proc_nbs (path:str='', n_workers:int=2, force:bool=False, file_glob:str='', file_re:str='', symlinks:bool=False, folder_re:str=None, skip_file_glob:str=None, skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]') Process notebooks in path for docs rendering Type Default Details path str Path to notebooks n_workers int 2 Number of workers force bool False Ignore cache and build all file_glob str Only include files matching glob file_re str Only include files matching glob symlinks bool False Follow symlinks? folder_re str None Only enter folders matching regex skip_file_glob str None Skip files matching glob skip_file_re str ^[_.] Skip files matching regex skip_folder_re str ^[_.] Skip folders matching regex # nbdev_proc_nbs.__wrapped__() source nbdev_readme \u00a4 nbdev_readme (path:str=None, chk_time:bool=False) Type Default Details path str None Path to notebooks chk_time bool False Only build if out of date source nbdev_docs \u00a4 nbdev_docs (path:str=None, n_workers:int=2, file_glob:str=None, file_re:str='\\\\.(?:ipynb|qmd|html)$', symlinks:bool=False, folder_re:str=None, skip_file_glob:str=None, skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]') Create Quarto docs and README.md Type Default Details path str None Path to notebooks n_workers int 2 Number of workers file_glob str None Only include files matching glob file_re str .(?:ipynb|qmd|html)$ Only include files matching regex symlinks bool False Follow symlinks? folder_re str None Only enter folders matching regex skip_file_glob str None Skip files matching glob skip_file_re str ^[_.] Skip files matching regex skip_folder_re str ^[_.] Skip folders matching regex source prepare \u00a4 prepare () Export, test, and clean notebooks, and render README if needed Preview \u00a4 source fs_watchdog \u00a4 fs_watchdog (func, path, recursive:bool=True) File system watchdog dispatching to func source nbdev_preview \u00a4 nbdev_preview (path:str=None, port:int=None, host:str=None, n_workers:int=2, file_glob:str=None, file_re:str='\\\\.(?:ipynb|qmd|html)$', symlinks:bool=False, folder_re:str=None, skip_file_glob:str=None, skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]') Preview docs locally Type Default Details path str None Path to notebooks port int None The port on which to run preview host str None The host on which to run preview n_workers int 2 Number of workers file_glob str None Only include files matching glob file_re str .(?:ipynb|qmd|html)$ Only include files matching regex symlinks bool False Follow symlinks? folder_re str None Only enter folders matching regex skip_file_glob str None Skip files matching glob skip_file_re str ^[_.] Skip files matching regex skip_folder_re str ^[_.] Skip folders matching regex","title":"quarto"},{"location":"api/quarto/#quarto","text":"","title":"quarto"},{"location":"api/quarto/#install","text":"source","title":"Install"},{"location":"api/quarto/#install_quarto","text":"install_quarto () Install latest Quarto on macOS or Linux, prints instructions for Windows source","title":"install_quarto"},{"location":"api/quarto/#install_1","text":"install () Install Quarto and the current library","title":"install"},{"location":"api/quarto/#sidebar","text":"source","title":"Sidebar"},{"location":"api/quarto/#nbdev_sidebar","text":"nbdev_sidebar (path:str=None, printit:bool=False, force:bool=False, skip_folder_re:str='(?:^[_.]|^www\\\\$)', file_glob:str=None, file_re:str='\\\\.(?:ipynb|qmd|html)$', symlinks:bool=False, folder_re:str=None, skip_file_glob:str=None, skip_file_re:str='^[_.]') Create sidebar.yml Type Default Details path str None Path to notebooks printit bool False Print YAML for debugging force bool False Create sidebar even if settings.ini custom_sidebar=False skip_folder_re str (?:^[_.]|^www$) Skip folders matching regex file_glob str None Only include files matching glob file_re str .(?:ipynb|qmd|html)$ Only include files matching regex symlinks bool False Follow symlinks? folder_re str None Only enter folders matching regex skip_file_glob str None Skip files matching glob skip_file_re str ^[_.] Skip files matching regex # nbdev_sidebar(printit=True, force=True)","title":"nbdev_sidebar"},{"location":"api/quarto/#render-docs","text":"source","title":"Render docs"},{"location":"api/quarto/#refresh_quarto_yml","text":"refresh_quarto_yml () Generate _quarto.yml from settings.ini . source","title":"refresh_quarto_yml"},{"location":"api/quarto/#nbdev_proc_nbs","text":"nbdev_proc_nbs (path:str='', n_workers:int=2, force:bool=False, file_glob:str='', file_re:str='', symlinks:bool=False, folder_re:str=None, skip_file_glob:str=None, skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]') Process notebooks in path for docs rendering Type Default Details path str Path to notebooks n_workers int 2 Number of workers force bool False Ignore cache and build all file_glob str Only include files matching glob file_re str Only include files matching glob symlinks bool False Follow symlinks? folder_re str None Only enter folders matching regex skip_file_glob str None Skip files matching glob skip_file_re str ^[_.] Skip files matching regex skip_folder_re str ^[_.] Skip folders matching regex # nbdev_proc_nbs.__wrapped__() source","title":"nbdev_proc_nbs"},{"location":"api/quarto/#nbdev_readme","text":"nbdev_readme (path:str=None, chk_time:bool=False) Type Default Details path str None Path to notebooks chk_time bool False Only build if out of date source","title":"nbdev_readme"},{"location":"api/quarto/#nbdev_docs","text":"nbdev_docs (path:str=None, n_workers:int=2, file_glob:str=None, file_re:str='\\\\.(?:ipynb|qmd|html)$', symlinks:bool=False, folder_re:str=None, skip_file_glob:str=None, skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]') Create Quarto docs and README.md Type Default Details path str None Path to notebooks n_workers int 2 Number of workers file_glob str None Only include files matching glob file_re str .(?:ipynb|qmd|html)$ Only include files matching regex symlinks bool False Follow symlinks? folder_re str None Only enter folders matching regex skip_file_glob str None Skip files matching glob skip_file_re str ^[_.] Skip files matching regex skip_folder_re str ^[_.] Skip folders matching regex source","title":"nbdev_docs"},{"location":"api/quarto/#prepare","text":"prepare () Export, test, and clean notebooks, and render README if needed","title":"prepare"},{"location":"api/quarto/#preview","text":"source","title":"Preview"},{"location":"api/quarto/#fs_watchdog","text":"fs_watchdog (func, path, recursive:bool=True) File system watchdog dispatching to func source","title":"fs_watchdog"},{"location":"api/quarto/#nbdev_preview","text":"nbdev_preview (path:str=None, port:int=None, host:str=None, n_workers:int=2, file_glob:str=None, file_re:str='\\\\.(?:ipynb|qmd|html)$', symlinks:bool=False, folder_re:str=None, skip_file_glob:str=None, skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]') Preview docs locally Type Default Details path str None Path to notebooks port int None The port on which to run preview host str None The host on which to run preview n_workers int 2 Number of workers file_glob str None Only include files matching glob file_re str .(?:ipynb|qmd|html)$ Only include files matching regex symlinks bool False Follow symlinks? folder_re str None Only enter folders matching regex skip_file_glob str None Skip files matching glob skip_file_re str ^[_.] Skip files matching regex skip_folder_re str ^[_.] Skip folders matching regex","title":"nbdev_preview"},{"location":"api/release/","text":"release \u00a4 Overview \u00a4 nbdev.release provides 3 commands that you can run from your shell to manage your changelog file and git releases: nbdev_changelog : creates a CHANGELOG.md file from closed and labeled GitHub issues nbdev_release_git : tags and creates a release in GitHub for the current version nbdev_release_gh : calls nbdev_changelog , lets you edit the result, then pushes to git and calls nbdev_release_git It provides 3 futher commands for releasing packages on pypi or conda: nbdev_pypi : Create and upload a pypi installer nbdev_conda : Create and upload a conda installer nbdev_release_both : Create and upload both pypi and conda installers Here\u2019s a brief demonstration of how to use the changelog and git release tools in nbdev.release . This demo first creates an issue using the gh command line tool, and then closes it using git ; you can also use GitHub\u2019s web interface for both of these tasks. (Note that this functionality used to be in a project called fastrelease , so in the video the command line tools have different names, starting with fastrelease_ instead of nbdev_ ). [ ](images/release.svg) Setup \u00a4 You\u2019ll need to get a GitHub personal access token if you haven\u2019t already. To do so, click here and enter \u201cnbdev\u201d in the \u201cNote\u201d section, and click the repo checkbox. Then click \u201cGenerate Token\u201d at the bottom of the screen, and copy the token (the long string of letters and numbers shown). You can easily do that by clicking the little clipboard icon next to the token. Paste that token into a file called token into the root of your repo. You can run the following in your terminal ( cd to the root of your repo first) to create that file: echo XXX > token Replace XXX above with the token you copied. Also, ensure that this file isn\u2019t added to git, by running this in your terminal: echo token >> .gitignore Creating release notes \u00a4 Now you\u2019re ready to create your release notes. These are created in a file called CHANGELOG.md . Here\u2019s an example of what it creates: nbdev CHANGELOG . All issues with the label bug , enhancement , or breaking that have been closed in your repo since your last release will be added to the top of this file. If you haven\u2019t made any releases before, then all issues with those labels will be included. Therefore, before you create or update CHANGELOG.md , go to your GitHub issues page, remove is:open from the filter, and label any issues you want included with one of the labels above. When you\u2019ve done that, you can create or update your release notes by running in your terminal: nbdev_changelog The titles and bodies of each issue will be added. Open CHANGELOG.md in your editor and make any edits that you want, and then commit the file to your repo (remember to git add it!) Tagging a release \u00a4 You should now tag a release. This will create a tag in GitHub with your current version number in settings.ini , and will then make it into a release, using your latest release notes as the description of the release: nbdev_release_git After you run this, be sure to increment your version number in settings.ini . You can either edit it manually, or if you use nbdev it can be done for you by running: nbdev_bump_version Doing both (creating release notes, and tagging a release) \u00a4 To complete both of the steps above, run: nbdev_release_gh See the screencast above for a demonstration of this. Python API \u00a4 source Release \u00a4 Release (owner=None, repo=None, token=None, **groups) Create CHANGELOG.md from GitHub issues To create a markdown changelog, first create a Release object, optionally passing a mapping from GitHub labels to markdown titles. Put your github token in a file named token at the root of your repo. Release attempts to fetch values for arguments from the following locations if not supplied: owner: fetched from the field user in settings.ini . This is the owner name of the repository on GitHub. For example for the repo fastai/fastcore the owner would be fastai . repo: fetched from the field lib_name in settings.ini . This is the name of the repository on GitHub. For example for the repo fastai/fastcore the owner would be fastcore . token: fetched from a file named token at the root of your repo. Creating a token is discussed in the setup section. groups: (optional) fetched from the field label_groups in settings.ini , which is a JSON string. This is a mapping from label names to titles in your release notes. If not specified, this defaults to: { \"breaking\" : \"Breaking Changes\" , \"enhancement\" : \"New Features\" , \"bug\" : \"Bugs Squashed\" } source Release.changelog \u00a4 Release.changelog (debug=False) Create the CHANGELOG.md file, or return the proposed text if debug is True Type Default Details debug bool False Just print the latest changes, instead of updating file rel = Release () # print(rel.changelog(debug=True)) source Release.release \u00a4 Release.release () Tag and create a release in GitHub for the current version This uses the version information from your settings.ini . source Release.latest_notes \u00a4 Release.latest_notes () Latest CHANGELOG entry All relevant pull requests and issues are fetched from the GitHub API, and are categorized according to a user-supplied mapping from labels to markdown headings. CLI functions \u00a4 source changelog \u00a4 changelog (debug:<function store_true>=False, repo:str=None) Create a CHANGELOG.md file from closed and labeled GitHub issues Type Default Details debug store_true False Print info to be added to CHANGELOG, instead of updating file repo str None repo to use instead of lib_name from settings.ini source release_git \u00a4 release_git (token:str=None) Tag and create a release in GitHub for the current version Type Default Details token str None Optional GitHub token (otherwise token file is used) source release_gh \u00a4 release_gh (token:str=None) Calls nbdev_changelog , lets you edit the result, then pushes to git and calls nbdev_release_git Type Default Details token str None Optional GitHub token (otherwise token file is used) Publish Packages \u00a4 source pypi_json \u00a4 pypi_json (s) Dictionary decoded JSON for PYPI path s source latest_pypi \u00a4 latest_pypi (name) Latest version of name on pypi source pypi_details \u00a4 pypi_details (name) Version, URL, and SHA256 for name from pypi source conda_output_path \u00a4 conda_output_path (name, build='build') Output path for conda build source write_conda_meta \u00a4 write_conda_meta (path='conda') Writes a meta.yaml file to the conda directory of the current directory This function is used in the conda_package CLI command. NB : you need to first of all upload your package to PyPi, before creating the conda package. source write_requirements \u00a4 write_requirements (directory=None) Writes a requirements.txt file to directory based on settings.ini. This function can be used in situations where you need to generate a requirements.txt file for a project. source anaconda_upload \u00a4 anaconda_upload (name, loc=None, user=None, token=None, env_token=None) Upload name to anaconda from fastcore.xtras import globtastic source release_conda \u00a4 release_conda (path:str='conda', do_build:<function bool_arg>=True, build_args:str='', skip_upload:<function store_true>=False, mambabuild:<function store_true>=False, upload_user:str=None) Create a meta.yaml file ready to be built into a package, and optionally build and upload it Type Default Details path str conda Path where package will be created do_build bool_arg True Run conda build step build_args str Additional args (as str) to send to conda build skip_upload store_true False Skip anaconda upload step mambabuild store_true False Use mambabuild (requires boa ) upload_user str None Optional user to upload package to source chk_conda_rel \u00a4 chk_conda_rel (nm:str, apkg:str=None, channel:str='fastai', force:<function store_true>=False) Prints GitHub tag only if a newer release exists on Pypi compared to an Anaconda Repo. Type Default Details nm str Package name on pypi apkg str None Anaconda Package (defaults to {nm}) channel str fastai Anaconda Channel force store_true False Always return github tag To build and upload a conda package, cd to the root of your repo, and then: nbdev_conda_package Or to do things more manually: nbdev_conda_package --do_build false cd conda conda build --no-anaconda-upload --output-folder build {name} anaconda upload build/noarch/{name}-{ver}-*.tar.bz2 Add --debug to the conda build command to debug any problems that occur. Note that the build step takes a few minutes. Add -u {org_name} to the anaconda upload command if you wish to upload to an organization, or pass upload_user to nbdev_conda_package . NB : you need to first of all upload your package to PyPi, before creating the conda package. source release_pypi \u00a4 release_pypi (repository:str='pypi') Create and upload Python package to PyPI Type Default Details repository str pypi Respository to upload to (defined in \\~/.pypirc) source release_both \u00a4 release_both (path:str='conda', do_build:<function bool_arg>=True, build_args:str='', skip_upload:<function store_true>=False, mambabuild:<function store_true>=False, upload_user:str=None, repository:str='pypi') Release both conda and PyPI packages Type Default Details path str conda Path where package will be created do_build bool_arg True Run conda build step build_args str Additional args (as str) to send to conda build skip_upload store_true False Skip anaconda upload step mambabuild store_true False Use mambabuild (requires boa ) upload_user str None Optional user to upload package to repository str pypi Pypi respository to upload to (defined in \\~/.pypirc) Bump Version \u00a4 source bump_version \u00a4 bump_version (version, part=2, unbump=False) source nbdev_bump_version \u00a4 nbdev_bump_version (part:int=2, unbump:bool=False) Increment version in settings.ini by one Type Default Details part int 2 Part of version to bump unbump bool False Reduce version instead of increasing it","title":"release"},{"location":"api/release/#release","text":"","title":"release"},{"location":"api/release/#overview","text":"nbdev.release provides 3 commands that you can run from your shell to manage your changelog file and git releases: nbdev_changelog : creates a CHANGELOG.md file from closed and labeled GitHub issues nbdev_release_git : tags and creates a release in GitHub for the current version nbdev_release_gh : calls nbdev_changelog , lets you edit the result, then pushes to git and calls nbdev_release_git It provides 3 futher commands for releasing packages on pypi or conda: nbdev_pypi : Create and upload a pypi installer nbdev_conda : Create and upload a conda installer nbdev_release_both : Create and upload both pypi and conda installers Here\u2019s a brief demonstration of how to use the changelog and git release tools in nbdev.release . This demo first creates an issue using the gh command line tool, and then closes it using git ; you can also use GitHub\u2019s web interface for both of these tasks. (Note that this functionality used to be in a project called fastrelease , so in the video the command line tools have different names, starting with fastrelease_ instead of nbdev_ ). [ ](images/release.svg)","title":"Overview"},{"location":"api/release/#setup","text":"You\u2019ll need to get a GitHub personal access token if you haven\u2019t already. To do so, click here and enter \u201cnbdev\u201d in the \u201cNote\u201d section, and click the repo checkbox. Then click \u201cGenerate Token\u201d at the bottom of the screen, and copy the token (the long string of letters and numbers shown). You can easily do that by clicking the little clipboard icon next to the token. Paste that token into a file called token into the root of your repo. You can run the following in your terminal ( cd to the root of your repo first) to create that file: echo XXX > token Replace XXX above with the token you copied. Also, ensure that this file isn\u2019t added to git, by running this in your terminal: echo token >> .gitignore","title":"Setup"},{"location":"api/release/#creating-release-notes","text":"Now you\u2019re ready to create your release notes. These are created in a file called CHANGELOG.md . Here\u2019s an example of what it creates: nbdev CHANGELOG . All issues with the label bug , enhancement , or breaking that have been closed in your repo since your last release will be added to the top of this file. If you haven\u2019t made any releases before, then all issues with those labels will be included. Therefore, before you create or update CHANGELOG.md , go to your GitHub issues page, remove is:open from the filter, and label any issues you want included with one of the labels above. When you\u2019ve done that, you can create or update your release notes by running in your terminal: nbdev_changelog The titles and bodies of each issue will be added. Open CHANGELOG.md in your editor and make any edits that you want, and then commit the file to your repo (remember to git add it!)","title":"Creating release notes"},{"location":"api/release/#tagging-a-release","text":"You should now tag a release. This will create a tag in GitHub with your current version number in settings.ini , and will then make it into a release, using your latest release notes as the description of the release: nbdev_release_git After you run this, be sure to increment your version number in settings.ini . You can either edit it manually, or if you use nbdev it can be done for you by running: nbdev_bump_version","title":"Tagging a release"},{"location":"api/release/#doing-both-creating-release-notes-and-tagging-a-release","text":"To complete both of the steps above, run: nbdev_release_gh See the screencast above for a demonstration of this.","title":"Doing both (creating release notes, and tagging a release)"},{"location":"api/release/#python-api","text":"source","title":"Python API"},{"location":"api/release/#release_1","text":"Release (owner=None, repo=None, token=None, **groups) Create CHANGELOG.md from GitHub issues To create a markdown changelog, first create a Release object, optionally passing a mapping from GitHub labels to markdown titles. Put your github token in a file named token at the root of your repo. Release attempts to fetch values for arguments from the following locations if not supplied: owner: fetched from the field user in settings.ini . This is the owner name of the repository on GitHub. For example for the repo fastai/fastcore the owner would be fastai . repo: fetched from the field lib_name in settings.ini . This is the name of the repository on GitHub. For example for the repo fastai/fastcore the owner would be fastcore . token: fetched from a file named token at the root of your repo. Creating a token is discussed in the setup section. groups: (optional) fetched from the field label_groups in settings.ini , which is a JSON string. This is a mapping from label names to titles in your release notes. If not specified, this defaults to: { \"breaking\" : \"Breaking Changes\" , \"enhancement\" : \"New Features\" , \"bug\" : \"Bugs Squashed\" } source","title":"Release"},{"location":"api/release/#releasechangelog","text":"Release.changelog (debug=False) Create the CHANGELOG.md file, or return the proposed text if debug is True Type Default Details debug bool False Just print the latest changes, instead of updating file rel = Release () # print(rel.changelog(debug=True)) source","title":"Release.changelog"},{"location":"api/release/#releaserelease","text":"Release.release () Tag and create a release in GitHub for the current version This uses the version information from your settings.ini . source","title":"Release.release"},{"location":"api/release/#releaselatest_notes","text":"Release.latest_notes () Latest CHANGELOG entry All relevant pull requests and issues are fetched from the GitHub API, and are categorized according to a user-supplied mapping from labels to markdown headings.","title":"Release.latest_notes"},{"location":"api/release/#cli-functions","text":"source","title":"CLI functions"},{"location":"api/release/#changelog","text":"changelog (debug:<function store_true>=False, repo:str=None) Create a CHANGELOG.md file from closed and labeled GitHub issues Type Default Details debug store_true False Print info to be added to CHANGELOG, instead of updating file repo str None repo to use instead of lib_name from settings.ini source","title":"changelog"},{"location":"api/release/#release_git","text":"release_git (token:str=None) Tag and create a release in GitHub for the current version Type Default Details token str None Optional GitHub token (otherwise token file is used) source","title":"release_git"},{"location":"api/release/#release_gh","text":"release_gh (token:str=None) Calls nbdev_changelog , lets you edit the result, then pushes to git and calls nbdev_release_git Type Default Details token str None Optional GitHub token (otherwise token file is used)","title":"release_gh"},{"location":"api/release/#publish-packages","text":"source","title":"Publish Packages"},{"location":"api/release/#pypi_json","text":"pypi_json (s) Dictionary decoded JSON for PYPI path s source","title":"pypi_json"},{"location":"api/release/#latest_pypi","text":"latest_pypi (name) Latest version of name on pypi source","title":"latest_pypi"},{"location":"api/release/#pypi_details","text":"pypi_details (name) Version, URL, and SHA256 for name from pypi source","title":"pypi_details"},{"location":"api/release/#conda_output_path","text":"conda_output_path (name, build='build') Output path for conda build source","title":"conda_output_path"},{"location":"api/release/#write_conda_meta","text":"write_conda_meta (path='conda') Writes a meta.yaml file to the conda directory of the current directory This function is used in the conda_package CLI command. NB : you need to first of all upload your package to PyPi, before creating the conda package. source","title":"write_conda_meta"},{"location":"api/release/#write_requirements","text":"write_requirements (directory=None) Writes a requirements.txt file to directory based on settings.ini. This function can be used in situations where you need to generate a requirements.txt file for a project. source","title":"write_requirements"},{"location":"api/release/#anaconda_upload","text":"anaconda_upload (name, loc=None, user=None, token=None, env_token=None) Upload name to anaconda from fastcore.xtras import globtastic source","title":"anaconda_upload"},{"location":"api/release/#release_conda","text":"release_conda (path:str='conda', do_build:<function bool_arg>=True, build_args:str='', skip_upload:<function store_true>=False, mambabuild:<function store_true>=False, upload_user:str=None) Create a meta.yaml file ready to be built into a package, and optionally build and upload it Type Default Details path str conda Path where package will be created do_build bool_arg True Run conda build step build_args str Additional args (as str) to send to conda build skip_upload store_true False Skip anaconda upload step mambabuild store_true False Use mambabuild (requires boa ) upload_user str None Optional user to upload package to source","title":"release_conda"},{"location":"api/release/#chk_conda_rel","text":"chk_conda_rel (nm:str, apkg:str=None, channel:str='fastai', force:<function store_true>=False) Prints GitHub tag only if a newer release exists on Pypi compared to an Anaconda Repo. Type Default Details nm str Package name on pypi apkg str None Anaconda Package (defaults to {nm}) channel str fastai Anaconda Channel force store_true False Always return github tag To build and upload a conda package, cd to the root of your repo, and then: nbdev_conda_package Or to do things more manually: nbdev_conda_package --do_build false cd conda conda build --no-anaconda-upload --output-folder build {name} anaconda upload build/noarch/{name}-{ver}-*.tar.bz2 Add --debug to the conda build command to debug any problems that occur. Note that the build step takes a few minutes. Add -u {org_name} to the anaconda upload command if you wish to upload to an organization, or pass upload_user to nbdev_conda_package . NB : you need to first of all upload your package to PyPi, before creating the conda package. source","title":"chk_conda_rel"},{"location":"api/release/#release_pypi","text":"release_pypi (repository:str='pypi') Create and upload Python package to PyPI Type Default Details repository str pypi Respository to upload to (defined in \\~/.pypirc) source","title":"release_pypi"},{"location":"api/release/#release_both","text":"release_both (path:str='conda', do_build:<function bool_arg>=True, build_args:str='', skip_upload:<function store_true>=False, mambabuild:<function store_true>=False, upload_user:str=None, repository:str='pypi') Release both conda and PyPI packages Type Default Details path str conda Path where package will be created do_build bool_arg True Run conda build step build_args str Additional args (as str) to send to conda build skip_upload store_true False Skip anaconda upload step mambabuild store_true False Use mambabuild (requires boa ) upload_user str None Optional user to upload package to repository str pypi Pypi respository to upload to (defined in \\~/.pypirc)","title":"release_both"},{"location":"api/release/#bump-version","text":"source","title":"Bump Version"},{"location":"api/release/#bump_version","text":"bump_version (version, part=2, unbump=False) source","title":"bump_version"},{"location":"api/release/#nbdev_bump_version","text":"nbdev_bump_version (part:int=2, unbump:bool=False) Increment version in settings.ini by one Type Default Details part int 2 Part of version to bump unbump bool False Reduce version instead of increasing it","title":"nbdev_bump_version"},{"location":"api/serve/","text":"serve \u00a4 source proc_nbs \u00a4 proc_nbs (path:str='', n_workers:int=2, force:bool=False, file_glob:str='', file_re:str='', symlinks:bool=False, folder_re:str=None, skip_file_glob:str=None, skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]') Process notebooks in path for docs rendering Type Default Details path str Path to notebooks n_workers int 2 Number of workers force bool False Ignore cache and build all file_glob str Only include files matching glob file_re str Only include files matching glob symlinks bool False Follow symlinks? folder_re str None Only enter folders matching regex skip_file_glob str None Skip files matching glob skip_file_re str ^[_.] Skip files matching regex skip_folder_re str ^[_.] Skip folders matching regex","title":"serve"},{"location":"api/serve/#serve","text":"source","title":"serve"},{"location":"api/serve/#proc_nbs","text":"proc_nbs (path:str='', n_workers:int=2, force:bool=False, file_glob:str='', file_re:str='', symlinks:bool=False, folder_re:str=None, skip_file_glob:str=None, skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]') Process notebooks in path for docs rendering Type Default Details path str Path to notebooks n_workers int 2 Number of workers force bool False Ignore cache and build all file_glob str Only include files matching glob file_re str Only include files matching glob symlinks bool False Follow symlinks? folder_re str None Only enter folders matching regex skip_file_glob str None Skip files matching glob skip_file_re str ^[_.] Skip files matching regex skip_folder_re str ^[_.] Skip folders matching regex","title":"proc_nbs"},{"location":"api/showdoc/","text":"showdoc \u00a4 Rendering docment Tables \u00a4 Render nicely formatted tables that shows docments for any function or method. source DocmentTbl \u00a4 DocmentTbl (obj, verbose=True, returns=True) Compute the docment table string DocmentTbl can render a markdown table showing docments if appropriate. This is an example of how a docments table will render for a function: def _f ( a , # description of param a b = True , # description of param b c : str = None ) -> int : ... _dm = DocmentTbl ( _f ) _dm Type Default Details a description of param a b bool True description of param b c str None Returns int If one column in the table has no information, for example because there are no default values, that column will not be shown. In the below example, the Default column, will not be shown. Additionally, if the return of the function is not annotated the Returns row will not be rendered: def _f ( a , b , #param b c #param c ): ... _dm2 = DocmentTbl ( _f ) _dm2 Details a b param b c param c DocmentTbl also works on classes. By default, the __init__ will be rendered: class _Test : def __init__ ( self , a , # description of param a b = True , # description of param b c : str = None ): ... def foo ( self , c : int , # description of param c d = True , # description of param d ): ... DocmentTbl ( _Test ) Type Default Details a description of param a b bool True description of param b c str None You can also pass a method to be rendered as well: DocmentTbl ( _Test . foo ) Type Default Details c int description of param c d bool True description of param d Documentation For An Object \u00a4 Render the signature as well as the docments to show complete documentation for an object. source ShowDocRenderer \u00a4 ShowDocRenderer (sym, name:str|None=None, title_level:int=3) Show documentation for sym source BasicMarkdownRenderer \u00a4 BasicMarkdownRenderer (sym, name:str|None=None, title_level:int=3) Markdown renderer for show_doc source show_doc \u00a4 show_doc (sym, renderer=None, name:Optional[str]=None, title_level:int=3) Show signature and docstring for sym Type Default Details sym Symbol to document renderer NoneType None Optional renderer (defaults to markdown) name str | None None Optionally override displayed name of sym title_level int 3 Heading level to use for symbol name You can use show_doc to document apis of functions, classes or methods. Numpy Docstrings \u00a4 if you have numpy docstrings instead of docments , show_doc will attempt to parse and render those just like docments . > **Warning** > > Numpy docstring formatting is very strict. If your docstrings do not > strictly adhere to the numpy format, it will not be parsed properly > and information about parameters and return values may not properly be > rendered in the table below the signature. Where possible, we > recommend using `docments` to annonate your function instead. show_doc on Classes \u00a4 show_doc works on Classes, too, including when you use @patch . You can define methods for the class Foo with @patch which is convenient in allowing you to break up code for documentation in notebooks. Class properties also work with showdoc. Pluggable renderers \u00a4 You can replace the default markdown show_doc renderer with custom renderers. For instance, nbdev comes with a simple example for rendering with raw HTML. source BasicHtmlRenderer \u00a4 BasicHtmlRenderer (sym, name:str|None=None, title_level:int=3) Simple HTML renderer for show_doc source doc \u00a4 doc (elt) Show show_doc info along with link to docs source showdoc_nm \u00a4 showdoc_nm (tree) Get the fully qualified name for showdoc. Other helpers \u00a4 source colab_link \u00a4 colab_link (path) Get a link to the notebook at path on Colab colab_link ( 'index' ) Open index in Colab","title":"showdoc"},{"location":"api/showdoc/#showdoc","text":"","title":"showdoc"},{"location":"api/showdoc/#rendering-docment-tables","text":"Render nicely formatted tables that shows docments for any function or method. source","title":"Rendering docment Tables"},{"location":"api/showdoc/#docmenttbl","text":"DocmentTbl (obj, verbose=True, returns=True) Compute the docment table string DocmentTbl can render a markdown table showing docments if appropriate. This is an example of how a docments table will render for a function: def _f ( a , # description of param a b = True , # description of param b c : str = None ) -> int : ... _dm = DocmentTbl ( _f ) _dm Type Default Details a description of param a b bool True description of param b c str None Returns int If one column in the table has no information, for example because there are no default values, that column will not be shown. In the below example, the Default column, will not be shown. Additionally, if the return of the function is not annotated the Returns row will not be rendered: def _f ( a , b , #param b c #param c ): ... _dm2 = DocmentTbl ( _f ) _dm2 Details a b param b c param c DocmentTbl also works on classes. By default, the __init__ will be rendered: class _Test : def __init__ ( self , a , # description of param a b = True , # description of param b c : str = None ): ... def foo ( self , c : int , # description of param c d = True , # description of param d ): ... DocmentTbl ( _Test ) Type Default Details a description of param a b bool True description of param b c str None You can also pass a method to be rendered as well: DocmentTbl ( _Test . foo ) Type Default Details c int description of param c d bool True description of param d","title":"DocmentTbl"},{"location":"api/showdoc/#documentation-for-an-object","text":"Render the signature as well as the docments to show complete documentation for an object. source","title":"Documentation For An Object"},{"location":"api/showdoc/#showdocrenderer","text":"ShowDocRenderer (sym, name:str|None=None, title_level:int=3) Show documentation for sym source","title":"ShowDocRenderer"},{"location":"api/showdoc/#basicmarkdownrenderer","text":"BasicMarkdownRenderer (sym, name:str|None=None, title_level:int=3) Markdown renderer for show_doc source","title":"BasicMarkdownRenderer"},{"location":"api/showdoc/#show_doc","text":"show_doc (sym, renderer=None, name:Optional[str]=None, title_level:int=3) Show signature and docstring for sym Type Default Details sym Symbol to document renderer NoneType None Optional renderer (defaults to markdown) name str | None None Optionally override displayed name of sym title_level int 3 Heading level to use for symbol name You can use show_doc to document apis of functions, classes or methods.","title":"show_doc"},{"location":"api/showdoc/#numpy-docstrings","text":"if you have numpy docstrings instead of docments , show_doc will attempt to parse and render those just like docments . > **Warning** > > Numpy docstring formatting is very strict. If your docstrings do not > strictly adhere to the numpy format, it will not be parsed properly > and information about parameters and return values may not properly be > rendered in the table below the signature. Where possible, we > recommend using `docments` to annonate your function instead.","title":"Numpy Docstrings"},{"location":"api/showdoc/#show_doc-on-classes","text":"show_doc works on Classes, too, including when you use @patch . You can define methods for the class Foo with @patch which is convenient in allowing you to break up code for documentation in notebooks. Class properties also work with showdoc.","title":"show_doc on Classes"},{"location":"api/showdoc/#pluggable-renderers","text":"You can replace the default markdown show_doc renderer with custom renderers. For instance, nbdev comes with a simple example for rendering with raw HTML. source","title":"Pluggable renderers"},{"location":"api/showdoc/#basichtmlrenderer","text":"BasicHtmlRenderer (sym, name:str|None=None, title_level:int=3) Simple HTML renderer for show_doc source","title":"BasicHtmlRenderer"},{"location":"api/showdoc/#doc","text":"doc (elt) Show show_doc info along with link to docs source","title":"doc"},{"location":"api/showdoc/#showdoc_nm","text":"showdoc_nm (tree) Get the fully qualified name for showdoc.","title":"showdoc_nm"},{"location":"api/showdoc/#other-helpers","text":"source","title":"Other helpers"},{"location":"api/showdoc/#colab_link","text":"colab_link (path) Get a link to the notebook at path on Colab colab_link ( 'index' ) Open index in Colab","title":"colab_link"},{"location":"api/sync/","text":"sync \u00a4 The library is primarily developed in notebooks so any big changes should be made there. But sometimes, it\u2019s easier to fix small bugs or typos in the modules directly. nbdev_update is the function that will propagate those changes back to the corresponding notebooks. Note that you can\u2019t create new cells or reorder cells with that functionality, so your corrections should remain limited. source absolute_import \u00a4 absolute_import (name, fname, level) Unwarps a relative import in name according to fname test_eq ( absolute_import ( 'xyz' , 'nbdev' , 0 ), 'xyz' ) test_eq ( absolute_import ( '' , 'nbdev' , 1 ), 'nbdev' ) test_eq ( absolute_import ( None , 'nbdev' , 1 ), 'nbdev' ) test_eq ( absolute_import ( 'core' , 'nbdev' , 1 ), 'nbdev.core' ) test_eq ( absolute_import ( 'core' , 'nbdev/vision' , 2 ), 'nbdev.core' ) # from ..core import * test_eq ( absolute_import ( 'transform' , 'nbdev/vision' , 1 ), 'nbdev.vision.transform' ) # from .transform import * test_eq ( absolute_import ( 'notebook.core' , 'nbdev/data' , 2 ), 'nbdev.notebook.core' ) # from ..notebook.core import * source nbdev_update \u00a4 nbdev_update (fname:str=None) Propagate change in modules matching fname to notebooks that created them Type Default Details fname str None A Python file name to update","title":"sync"},{"location":"api/sync/#sync","text":"The library is primarily developed in notebooks so any big changes should be made there. But sometimes, it\u2019s easier to fix small bugs or typos in the modules directly. nbdev_update is the function that will propagate those changes back to the corresponding notebooks. Note that you can\u2019t create new cells or reorder cells with that functionality, so your corrections should remain limited. source","title":"sync"},{"location":"api/sync/#absolute_import","text":"absolute_import (name, fname, level) Unwarps a relative import in name according to fname test_eq ( absolute_import ( 'xyz' , 'nbdev' , 0 ), 'xyz' ) test_eq ( absolute_import ( '' , 'nbdev' , 1 ), 'nbdev' ) test_eq ( absolute_import ( None , 'nbdev' , 1 ), 'nbdev' ) test_eq ( absolute_import ( 'core' , 'nbdev' , 1 ), 'nbdev.core' ) test_eq ( absolute_import ( 'core' , 'nbdev/vision' , 2 ), 'nbdev.core' ) # from ..core import * test_eq ( absolute_import ( 'transform' , 'nbdev/vision' , 1 ), 'nbdev.vision.transform' ) # from .transform import * test_eq ( absolute_import ( 'notebook.core' , 'nbdev/data' , 2 ), 'nbdev.notebook.core' ) # from ..notebook.core import * source","title":"absolute_import"},{"location":"api/sync/#nbdev_update","text":"nbdev_update (fname:str=None) Propagate change in modules matching fname to notebooks that created them Type Default Details fname str None A Python file name to update","title":"nbdev_update"},{"location":"api/test/","text":"test \u00a4 source test_nb \u00a4 test_nb (fn, skip_flags=None, force_flags=None, do_print=False, showerr=True, basepath=None) Execute tests in notebook in fn except those with skip_flags Type Default Details fn file name of notebook to test skip_flags NoneType None list of flags marking cells to skip force_flags NoneType None list of flags marking cells to always run do_print bool False print completion? showerr bool True print errors to stderr? basepath NoneType None path to add to sys.path test_nb can test a notebook, and skip over certain flags: _nb = Path ( '../../tests/directives.ipynb' ) success , duration = test_nb ( _nb , skip_flags = [ 'notest' ]) assert success In that notebook the cell flagged notest raises an exception, which will be returned as a bool : _nb = Path ( '../../tests/directives.ipynb' ) success , duration = test_nb ( _nb , showerr = False ) assert not success Sometimes you may wish to override one or more of the skip_flags, in which case you can use the argument force_flags which will remove the appropriate tag(s) from skip_flags . This is useful because skip_flags are meant to be set in the tst_flags field of settings.ini , whereas force_flags are usually passed in by the user. source nbdev_test \u00a4 nbdev_test (path:str=None, flags:str='', n_workers:int=None, timing:bool=False, do_print:bool=False, pause:float=0.01, ignore_fname:str='.notest', symlinks:bool=False, file_glob:str='*.ipynb', file_re:str=None, folder_re:str=None, skip_file_glob:str=None, skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]') Test in parallel notebooks matching path , passing along flags Type Default Details path str None A notebook name or glob to test flags str Space separated list of test flags to run that are normally ignored n_workers int None Number of workers timing bool False Time each notebook to see which are slow do_print bool False Print start and end of each notebook pause float 0.01 Pause time (in seconds) between notebooks to avoid race conditions ignore_fname str .notest Filename that will result in siblings being ignored symlinks bool False Follow symlinks? file_glob str *.ipynb Only include files matching glob file_re str None Only include files matching regex folder_re str None Only enter folders matching regex skip_file_glob str None Skip files matching glob skip_file_re str ^[_.] Skip files matching regex skip_folder_re str ^[_.] Skip folders matching regex nbdev_test ( n_workers = 0 ) Success. You can even run nbdev_test in non nbdev projects, for example, you can test an individual notebook like so: nbdev_test --path ../../tests/minimal.ipynb --do_print Or you can test an entire directory of notebooks filtered for only those that match a regular expression: nbdev_test --path ../../tests --file_re '.*test.ipynb' --do_print","title":"test"},{"location":"api/test/#test","text":"source","title":"test"},{"location":"api/test/#test_nb","text":"test_nb (fn, skip_flags=None, force_flags=None, do_print=False, showerr=True, basepath=None) Execute tests in notebook in fn except those with skip_flags Type Default Details fn file name of notebook to test skip_flags NoneType None list of flags marking cells to skip force_flags NoneType None list of flags marking cells to always run do_print bool False print completion? showerr bool True print errors to stderr? basepath NoneType None path to add to sys.path test_nb can test a notebook, and skip over certain flags: _nb = Path ( '../../tests/directives.ipynb' ) success , duration = test_nb ( _nb , skip_flags = [ 'notest' ]) assert success In that notebook the cell flagged notest raises an exception, which will be returned as a bool : _nb = Path ( '../../tests/directives.ipynb' ) success , duration = test_nb ( _nb , showerr = False ) assert not success Sometimes you may wish to override one or more of the skip_flags, in which case you can use the argument force_flags which will remove the appropriate tag(s) from skip_flags . This is useful because skip_flags are meant to be set in the tst_flags field of settings.ini , whereas force_flags are usually passed in by the user. source","title":"test_nb"},{"location":"api/test/#nbdev_test","text":"nbdev_test (path:str=None, flags:str='', n_workers:int=None, timing:bool=False, do_print:bool=False, pause:float=0.01, ignore_fname:str='.notest', symlinks:bool=False, file_glob:str='*.ipynb', file_re:str=None, folder_re:str=None, skip_file_glob:str=None, skip_file_re:str='^[_.]', skip_folder_re:str='^[_.]') Test in parallel notebooks matching path , passing along flags Type Default Details path str None A notebook name or glob to test flags str Space separated list of test flags to run that are normally ignored n_workers int None Number of workers timing bool False Time each notebook to see which are slow do_print bool False Print start and end of each notebook pause float 0.01 Pause time (in seconds) between notebooks to avoid race conditions ignore_fname str .notest Filename that will result in siblings being ignored symlinks bool False Follow symlinks? file_glob str *.ipynb Only include files matching glob file_re str None Only include files matching regex folder_re str None Only enter folders matching regex skip_file_glob str None Skip files matching glob skip_file_re str ^[_.] Skip files matching regex skip_folder_re str ^[_.] Skip folders matching regex nbdev_test ( n_workers = 0 ) Success. You can even run nbdev_test in non nbdev projects, for example, you can test an individual notebook like so: nbdev_test --path ../../tests/minimal.ipynb --do_print Or you can test an entire directory of notebooks filtered for only those that match a regular expression: nbdev_test --path ../../tests --file_re '.*test.ipynb' --do_print","title":"nbdev_test"},{"location":"blog/","text":"nbdev Blog \u00a4","title":"Index"},{"location":"blog/#nbdev-blog","text":"","title":"nbdev Blog"},{"location":"blog/posts/2022-07-28-nbdev2/","text":"nbdev+Quarto: A new secret weapon for productivity \u00a4 Hamel HusainJeremy Howard 7/28/22 Originally posted on the fast.ai blog Our new secret weapon for productivity \u00a4 Today we\u2019re excited to announce that we\u2019ve teamed up with Quarto to give nbdev superpowers. nbdev offers Python programmers a common set of tools for using Jupyter notebooks to: Write & distribute software packages Test code, and Author documentation and technical articles Although notebooks are already widely used for once-off exploratory work, it\u2019s less well-known that they are perfectly capable of writing quality software. In fact, we\u2019ve used nbdev for a wide range of software projects over the last three years, including deep learning libraries, API clients , Python language extensions , terminal user interfaces , and more. We discovered that it is not only capable of writing great software but that it has also increased our productivity by 300% or more . With nbdev, developers simply write notebooks with lightweight markup and get high-quality documentation, tests, continuous integration, and packaging for free! Nbdev has allowed us to maintain and scale many open source projects . Pull requests are often accompanied by detailed documentation and tests\u2013contributors simply write notebooks. This is why we\u2019re excited to share nbdev v2. It\u2019s rewritten from the ground up, with much-anticipated features including: Interoperation with non-nbdev codebases for tasks like documentation Support for any static site generator Wide variety of output mediums such as blogs, papers, slides, and websites A faster Jupyter kernel, which also means faster tests Cleaner and more extensible API, which supports custom directives, custom module exporters, and more nbdev in industry \u00a4 We have piloted nbdev at several companies. We were delighted to receive the following feedback, which fits our own experience using and developing nbdev: David Berg , on using nbdev for internal documentation at Netflix: \u201cPrior to using nbdev, documentation was the most cumbersome aspect of our software development process\u2026 Using nbdev allows us to spend more time creating rich prose around the many code snippets guaranteeing the whole experience is robust. nbdev has turned what was once a chore into a natural extension of the notebook-based testing we were already doing.\u201d Erik Gaasedelen , on using nbdev in production at Lyft: \u201cI use this in production at my company. It\u2019s an awesome tool\u2026 nbdev streamlines everything so I can write docs, tests, and code all in one place\u2026 The packaging is also really well thought out. From my point of view it is close to a Pareto improvement over traditional Python library development.\u201d Hugo Bowne-Anderson , on using nbdev for Outerbounds : \u201cnbdev has transformed the way we write documentation. Gone are the days of worrying about broken code examples when our API changes or [due to] human errors associated with copying & pasting code into markdown files. The authoring experience of nbdev\u2026 [allows] us to write prose and live code in a unified interface, which allows more experimentation\u2026 On top of this, nbdev allows us to include unit tests in our documentation which mitigates the burden of maintaining the docs over time.\u201d Roxanna Pourzand , on using nbdev for Transform : \u201cWe\u2019re so excited about using nbdev. Our product is technical so our resulting documentation includes a lot of code-based examples. Before nbdev, we had no way of maintaining our code examples and ensuring that it was up-to-date for both command inputs and outputs. It was all manual. With nbdev, we now have this under control in a sustainable way. Since we\u2019ve deployed these docs, we also had a situation where we were able to identify a bug in one of our interfaces, which we found by seeing the error that was output in the documentation.\u201d What\u2019s nbdev? \u00a4 Nbdev embraces the dynamic nature of python and REPL-driven development in ways that traditional IDEs and software development workflows cannot. We thoroughly discussed the motivation, history, and goals of nbdev in this initial launch post three years ago. The creator of Jupyter, Fernando P\u00e9rez, told us: [Nbdev] should be celebrated and used a lot more - I have kept a tab with your original nbdev blog post open for months in Chrome because of how often I refer to it and point others to this work In short, nbdev embraces ideas from literate programming and exploratory programming . These paradigms have been revisited in platforms like XCode Playgrounds and languages like Smalltalk, LISP, and Mathematica. With nbdev, we sought to push these paradigms even further by enabling it for one of the most popular dynamic programming languages in the world: Python. Even though nbdev is most widely used in scientific computing communities due to its integration with Jupyter Notebooks, we\u2019ve found that nbdev is well suited for a much wider range of software. We have used nbdev to write deep learning libraries, API clients , python language extensions , terminal user interfaces , and more! Hamel: When I use nbdev, my colleagues are often astounded by how quickly I can create and distribute high-quality python packages. I consider nbdev to be a superpower that allows me to create tests and documentation without any additional friction, which makes all of my projects more maintainable. I also find writing software with nbdev to be more fun and productive as I can iterate very fast on ideas relative to more traditional software engineering workflows. Lastly, with nbdev I can also use traditional text-based IDEs if I want to, so I get the best of both worlds. What we learned after three years of using nbdev \u00a4 While nbdev was originally developed to simplify the software development workflow for various fast.ai projects , we found that users wanted to extend nbdev to: Write and publish blog posts, books, papers, and other types of documents with Jupyter Notebooks Document existing codebases not written in nbdev Accommodate traditional Python conventions\u2013for those constrained in how their code is organized and formatted Publish content using any static site generator While we created projects such as fastpages and fastdoc to accomplish some of these tasks, we realized that it would be better to have a single set of flexible tools to accomplish all of them. To this end, we were extremely excited to discover Quarto , an open-source technical publishing system built on pandoc. Hamel: The more I used nbdev for creating Python modules, the more I wanted to use it for writing blogs and documenting existing codebases. The ability to customize the way notebooks are rendered (hiding vs. showing cells, stripping output, etc.), along with the facilities for including unit tests, made it my go-to authoring tool for all technical content. I\u2019m excited that nbdev2 unlocks all of these possibilities for everyone! Enter Quarto: A pandoc super-processor \u00a4 Quarto is a project that enables technical publishing with support for Jupyter Notebook, VSCode, Observable, and plaintext editors. Furthermore, Quarto enables the publishing of high-quality articles, reports, websites, and blogs in HTML, PDF, ePub, PowerPoint slides, and more. Quarto is maintained by RStudio , a company with a long history of products supporting literate programming, such as RMarkdown and RStudio. Quarto is built on top of Pandoc , a universal document converter that supports nearly any format you can think of. Pandoc achieves this seemingly magical feat by representing documents in a common abstract syntax tree (AST) that serves as the medium through which different formats can be translated. By extension, Quarto allows you to generate content in almost any format you wish! You can use pandoc filters to modify the AST and the output format, which allows you to use any static site generator you want, and programmatically modify and generate content. Quarto allows you to compose pandoc filters in a processing pipeline and apply them to specific documents or entire projects. You can also distribute filters as Quarto extensions , which makes Quarto extremely customizable. We also find Quarto compelling because user interfaces such as comment directives (comments that start with #| ) correlate with nbdev. In fact, we even learned that nbdev inspired Quarto in this regard! In general, Quarto and nbdev share many goals, and the Quarto team has been incredibly responsive to our suggestions. For example, the ability to create notebook filters to modify notebooks before rendering. Below is a screenshot of a Jupyter notebook rendered with Quarto and nbdev. ![Quarto rendering a Jupyter notebook written with nbdev](../images/nbs/blog/posts/2022-07-28-nbdev2/nb_quarto.png) Finally, Quarto supports more programming languages than just Python and has been adding new features and fixing bugs at an impressive speed. This gives us confidence that we will be able to expand nbdev to support more use cases in the future. We discuss some of these future directions in the closing section. A blazing fast notebook kernel: execnb \u00a4 A core component of nbdev is executing and testing notebooks programmatically. It is important that this notebook runner executes with minimal overhead to maintain our goal of providing a delightful developer experience. This is why we built execnb , a lightweight notebook runner for Python kernels, which executes notebooks blazingly fast. Furthermore, execnb allows parameterized execution of notebooks. Hamel: I have been an enthusiastic user of tools like papermill that programmatically run notebooks for use-cases like creating dashboards or enabling new kinds of machine learning workflows . I believe execnb unlocks even more possibilities with its ability to inject arbitrary code at any place in a notebook, as well as the ability to pass callbacks that run before and/or after cells are executed. This opens up possibilities to create new types of workflows with notebooks that I am excited about exploring in the near future. Towards a dialect of python that embraces its dynamic nature \u00a4 One way to understand nbdev is part of an ecosystem that is designed to embrace Python\u2019s dynamic properties for REPL-driven software engineering. Similar to Clojure , our goal is to provide tools that remove all friction from using the REPL in your programming workflow. We believe that the REPL enhances developer workflows thanks to context-sensitive auto-completion, signature inspection, and documentation\u2013all based on the actual state of your code, and none of which are available in IDEs that depend solely on static analysis. We have found that for this reason, nbdev, with its Jupyter notebook foundation, makes programming significantly more productive and enjoyable. Our efforts to support REPL-driven development and literate programming are not limited to nbdev. We maintain a number of libraries that extend python to bolster this programming experience. The most notable of these libraries is fastcore , which extends Python in terms of testing , documenting code , metaprogramming , attribute helpers , enhanced representations of objects , and notebook-friendly patching . This blog post offers a gentle introduction to fastcore. In addition to literate programming, fastcore encourages conventions such as brevity and efficient use of vertical space so you can accomplish more with significantly less code. For example, below is a simple decorator that enables notebook-friendly patching : @patch decorator from fastcore We believe that this combination of a new developer workflow (nbdev), Python extensions (fastcore), and associated norms form a new dialect of Python that is centered on leveraging its dynamic nature\u2013in contrast to an ever-growing trend toward static analysis . We suspect that this dialect of Python will be more productive for programmers in many scenarios. We are framing this ecosystem as a \u201cdialect\u201d as it is still very much Python and is approachable by anyone who is familiar with the language. Furthermore, despite nbdev\u2019s notebook workflow, our tools generate plaintext modules that can be navigated and edited with text-based IDEs, allowing programmers to experience the best of both worlds, if they desire. Hamel: I believe this framing of a Python dialect is key to properly understanding what nbdev is. While it may be tempting to get stuck on specific features or technical details of nbdev, it is useful to zoom out to understand the overall intent of creating a better workflow rather than conforming too rigidly to existing ones. A good analogy is TypeScript\u2019s relationship with JavaScript: it is an extension of an existing programming language that supports a new way of programming. I encourage you to treat nbdev in a similar fashion: be willing to try new ways of programming and observe which tradeoffs resonate with you. At the very least, I believe nbdev is a fun way to experience a different way of writing software, which will broaden your horizons about programming in general, all without having to learn an entirely new programming language! The future of nbdev \u00a4 While we are excited about nbdev2, we believe we have only scratched the surface of what\u2019s possible. We are considering the following features: Supporting more languages beyond Python, such as Julia, R and JavaScript Offering interfaces for executing parameterized notebooks that mimic Python scripts Extensions for more static site generators and filters Supporting alternate testing backends, such as pytest Supporting a greater number of docstring formats, such as Google-style docstrings More options to use plain-text or human readable notebook backends other than JSON If you have interesting ideas about how nbdev can be extended, please drop and chat with us on discord or post a message in the forums . How you can get started with nbdev \u00a4 Our project\u2019s website is at nbdev.fast.ai , where we will be posting tutorials, examples, and more documentation in the coming days. Thank You \u00a4 This new version of nbdev was a team effort by many wonderful people. We want to highlight two people who have made outstanding contributions: Wasim Lorgat was instrumental across different areas, including significant contributions to fastcore, execnb, and nbdev, as well as the implementation of the new nbdev home page . With Wasim\u2019s help, we were able to push nbdev to a new level of functionality and quality. JJ Allaire is not only the CEO of RStudio but also the steward of Quarto. JJ was incredibly responsive and eager to work with us on nbdev and added many features to Quarto specifically with nbdev in mind, such as notebook filters . We were also astounded by the attention to detail and the pace at which bugs are addressed. This new version of nbdev would not have been possible without JJ\u2019s help, and we are excited to continue to work with him. We also want to thank the amazing fastai community, notably Isaac Flath , Benjamin Warner and Zach Mueller for their tireless work on this project. A conversation with JJ Allaire \u00a4 To celebrate the launch of nbdev v2 and Quarto, Jeremy sat down with the CEO of Posit (previously known as RStudio, the company behind Quarto), JJ Allaire, to talk about software development, scientific publishing, R, Python, literate programming, and much more.","title":"Index"},{"location":"blog/posts/2022-07-28-nbdev2/#nbdevquarto-a-new-secret-weapon-for-productivity","text":"Hamel HusainJeremy Howard 7/28/22 Originally posted on the fast.ai blog","title":"nbdev+Quarto: A new secret weapon for productivity"},{"location":"blog/posts/2022-07-28-nbdev2/#our-new-secret-weapon-for-productivity","text":"Today we\u2019re excited to announce that we\u2019ve teamed up with Quarto to give nbdev superpowers. nbdev offers Python programmers a common set of tools for using Jupyter notebooks to: Write & distribute software packages Test code, and Author documentation and technical articles Although notebooks are already widely used for once-off exploratory work, it\u2019s less well-known that they are perfectly capable of writing quality software. In fact, we\u2019ve used nbdev for a wide range of software projects over the last three years, including deep learning libraries, API clients , Python language extensions , terminal user interfaces , and more. We discovered that it is not only capable of writing great software but that it has also increased our productivity by 300% or more . With nbdev, developers simply write notebooks with lightweight markup and get high-quality documentation, tests, continuous integration, and packaging for free! Nbdev has allowed us to maintain and scale many open source projects . Pull requests are often accompanied by detailed documentation and tests\u2013contributors simply write notebooks. This is why we\u2019re excited to share nbdev v2. It\u2019s rewritten from the ground up, with much-anticipated features including: Interoperation with non-nbdev codebases for tasks like documentation Support for any static site generator Wide variety of output mediums such as blogs, papers, slides, and websites A faster Jupyter kernel, which also means faster tests Cleaner and more extensible API, which supports custom directives, custom module exporters, and more","title":"Our new secret weapon for productivity"},{"location":"blog/posts/2022-07-28-nbdev2/#nbdev-in-industry","text":"We have piloted nbdev at several companies. We were delighted to receive the following feedback, which fits our own experience using and developing nbdev: David Berg , on using nbdev for internal documentation at Netflix: \u201cPrior to using nbdev, documentation was the most cumbersome aspect of our software development process\u2026 Using nbdev allows us to spend more time creating rich prose around the many code snippets guaranteeing the whole experience is robust. nbdev has turned what was once a chore into a natural extension of the notebook-based testing we were already doing.\u201d Erik Gaasedelen , on using nbdev in production at Lyft: \u201cI use this in production at my company. It\u2019s an awesome tool\u2026 nbdev streamlines everything so I can write docs, tests, and code all in one place\u2026 The packaging is also really well thought out. From my point of view it is close to a Pareto improvement over traditional Python library development.\u201d Hugo Bowne-Anderson , on using nbdev for Outerbounds : \u201cnbdev has transformed the way we write documentation. Gone are the days of worrying about broken code examples when our API changes or [due to] human errors associated with copying & pasting code into markdown files. The authoring experience of nbdev\u2026 [allows] us to write prose and live code in a unified interface, which allows more experimentation\u2026 On top of this, nbdev allows us to include unit tests in our documentation which mitigates the burden of maintaining the docs over time.\u201d Roxanna Pourzand , on using nbdev for Transform : \u201cWe\u2019re so excited about using nbdev. Our product is technical so our resulting documentation includes a lot of code-based examples. Before nbdev, we had no way of maintaining our code examples and ensuring that it was up-to-date for both command inputs and outputs. It was all manual. With nbdev, we now have this under control in a sustainable way. Since we\u2019ve deployed these docs, we also had a situation where we were able to identify a bug in one of our interfaces, which we found by seeing the error that was output in the documentation.\u201d","title":"nbdev in industry"},{"location":"blog/posts/2022-07-28-nbdev2/#whats-nbdev","text":"Nbdev embraces the dynamic nature of python and REPL-driven development in ways that traditional IDEs and software development workflows cannot. We thoroughly discussed the motivation, history, and goals of nbdev in this initial launch post three years ago. The creator of Jupyter, Fernando P\u00e9rez, told us: [Nbdev] should be celebrated and used a lot more - I have kept a tab with your original nbdev blog post open for months in Chrome because of how often I refer to it and point others to this work In short, nbdev embraces ideas from literate programming and exploratory programming . These paradigms have been revisited in platforms like XCode Playgrounds and languages like Smalltalk, LISP, and Mathematica. With nbdev, we sought to push these paradigms even further by enabling it for one of the most popular dynamic programming languages in the world: Python. Even though nbdev is most widely used in scientific computing communities due to its integration with Jupyter Notebooks, we\u2019ve found that nbdev is well suited for a much wider range of software. We have used nbdev to write deep learning libraries, API clients , python language extensions , terminal user interfaces , and more! Hamel: When I use nbdev, my colleagues are often astounded by how quickly I can create and distribute high-quality python packages. I consider nbdev to be a superpower that allows me to create tests and documentation without any additional friction, which makes all of my projects more maintainable. I also find writing software with nbdev to be more fun and productive as I can iterate very fast on ideas relative to more traditional software engineering workflows. Lastly, with nbdev I can also use traditional text-based IDEs if I want to, so I get the best of both worlds.","title":"What\u2019s nbdev?"},{"location":"blog/posts/2022-07-28-nbdev2/#what-we-learned-after-three-years-of-using-nbdev","text":"While nbdev was originally developed to simplify the software development workflow for various fast.ai projects , we found that users wanted to extend nbdev to: Write and publish blog posts, books, papers, and other types of documents with Jupyter Notebooks Document existing codebases not written in nbdev Accommodate traditional Python conventions\u2013for those constrained in how their code is organized and formatted Publish content using any static site generator While we created projects such as fastpages and fastdoc to accomplish some of these tasks, we realized that it would be better to have a single set of flexible tools to accomplish all of them. To this end, we were extremely excited to discover Quarto , an open-source technical publishing system built on pandoc. Hamel: The more I used nbdev for creating Python modules, the more I wanted to use it for writing blogs and documenting existing codebases. The ability to customize the way notebooks are rendered (hiding vs. showing cells, stripping output, etc.), along with the facilities for including unit tests, made it my go-to authoring tool for all technical content. I\u2019m excited that nbdev2 unlocks all of these possibilities for everyone!","title":"What we learned after three years of using nbdev"},{"location":"blog/posts/2022-07-28-nbdev2/#enter-quarto-a-pandoc-super-processor","text":"Quarto is a project that enables technical publishing with support for Jupyter Notebook, VSCode, Observable, and plaintext editors. Furthermore, Quarto enables the publishing of high-quality articles, reports, websites, and blogs in HTML, PDF, ePub, PowerPoint slides, and more. Quarto is maintained by RStudio , a company with a long history of products supporting literate programming, such as RMarkdown and RStudio. Quarto is built on top of Pandoc , a universal document converter that supports nearly any format you can think of. Pandoc achieves this seemingly magical feat by representing documents in a common abstract syntax tree (AST) that serves as the medium through which different formats can be translated. By extension, Quarto allows you to generate content in almost any format you wish! You can use pandoc filters to modify the AST and the output format, which allows you to use any static site generator you want, and programmatically modify and generate content. Quarto allows you to compose pandoc filters in a processing pipeline and apply them to specific documents or entire projects. You can also distribute filters as Quarto extensions , which makes Quarto extremely customizable. We also find Quarto compelling because user interfaces such as comment directives (comments that start with #| ) correlate with nbdev. In fact, we even learned that nbdev inspired Quarto in this regard! In general, Quarto and nbdev share many goals, and the Quarto team has been incredibly responsive to our suggestions. For example, the ability to create notebook filters to modify notebooks before rendering. Below is a screenshot of a Jupyter notebook rendered with Quarto and nbdev. ![Quarto rendering a Jupyter notebook written with nbdev](../images/nbs/blog/posts/2022-07-28-nbdev2/nb_quarto.png) Finally, Quarto supports more programming languages than just Python and has been adding new features and fixing bugs at an impressive speed. This gives us confidence that we will be able to expand nbdev to support more use cases in the future. We discuss some of these future directions in the closing section.","title":"Enter Quarto: A pandoc super-processor"},{"location":"blog/posts/2022-07-28-nbdev2/#a-blazing-fast-notebook-kernel-execnb","text":"A core component of nbdev is executing and testing notebooks programmatically. It is important that this notebook runner executes with minimal overhead to maintain our goal of providing a delightful developer experience. This is why we built execnb , a lightweight notebook runner for Python kernels, which executes notebooks blazingly fast. Furthermore, execnb allows parameterized execution of notebooks. Hamel: I have been an enthusiastic user of tools like papermill that programmatically run notebooks for use-cases like creating dashboards or enabling new kinds of machine learning workflows . I believe execnb unlocks even more possibilities with its ability to inject arbitrary code at any place in a notebook, as well as the ability to pass callbacks that run before and/or after cells are executed. This opens up possibilities to create new types of workflows with notebooks that I am excited about exploring in the near future.","title":"A blazing fast notebook kernel: execnb"},{"location":"blog/posts/2022-07-28-nbdev2/#towards-a-dialect-of-python-that-embraces-its-dynamic-nature","text":"One way to understand nbdev is part of an ecosystem that is designed to embrace Python\u2019s dynamic properties for REPL-driven software engineering. Similar to Clojure , our goal is to provide tools that remove all friction from using the REPL in your programming workflow. We believe that the REPL enhances developer workflows thanks to context-sensitive auto-completion, signature inspection, and documentation\u2013all based on the actual state of your code, and none of which are available in IDEs that depend solely on static analysis. We have found that for this reason, nbdev, with its Jupyter notebook foundation, makes programming significantly more productive and enjoyable. Our efforts to support REPL-driven development and literate programming are not limited to nbdev. We maintain a number of libraries that extend python to bolster this programming experience. The most notable of these libraries is fastcore , which extends Python in terms of testing , documenting code , metaprogramming , attribute helpers , enhanced representations of objects , and notebook-friendly patching . This blog post offers a gentle introduction to fastcore. In addition to literate programming, fastcore encourages conventions such as brevity and efficient use of vertical space so you can accomplish more with significantly less code. For example, below is a simple decorator that enables notebook-friendly patching : @patch decorator from fastcore We believe that this combination of a new developer workflow (nbdev), Python extensions (fastcore), and associated norms form a new dialect of Python that is centered on leveraging its dynamic nature\u2013in contrast to an ever-growing trend toward static analysis . We suspect that this dialect of Python will be more productive for programmers in many scenarios. We are framing this ecosystem as a \u201cdialect\u201d as it is still very much Python and is approachable by anyone who is familiar with the language. Furthermore, despite nbdev\u2019s notebook workflow, our tools generate plaintext modules that can be navigated and edited with text-based IDEs, allowing programmers to experience the best of both worlds, if they desire. Hamel: I believe this framing of a Python dialect is key to properly understanding what nbdev is. While it may be tempting to get stuck on specific features or technical details of nbdev, it is useful to zoom out to understand the overall intent of creating a better workflow rather than conforming too rigidly to existing ones. A good analogy is TypeScript\u2019s relationship with JavaScript: it is an extension of an existing programming language that supports a new way of programming. I encourage you to treat nbdev in a similar fashion: be willing to try new ways of programming and observe which tradeoffs resonate with you. At the very least, I believe nbdev is a fun way to experience a different way of writing software, which will broaden your horizons about programming in general, all without having to learn an entirely new programming language!","title":"Towards a dialect of python that embraces its dynamic nature"},{"location":"blog/posts/2022-07-28-nbdev2/#the-future-of-nbdev","text":"While we are excited about nbdev2, we believe we have only scratched the surface of what\u2019s possible. We are considering the following features: Supporting more languages beyond Python, such as Julia, R and JavaScript Offering interfaces for executing parameterized notebooks that mimic Python scripts Extensions for more static site generators and filters Supporting alternate testing backends, such as pytest Supporting a greater number of docstring formats, such as Google-style docstrings More options to use plain-text or human readable notebook backends other than JSON If you have interesting ideas about how nbdev can be extended, please drop and chat with us on discord or post a message in the forums .","title":"The future of nbdev"},{"location":"blog/posts/2022-07-28-nbdev2/#how-you-can-get-started-with-nbdev","text":"Our project\u2019s website is at nbdev.fast.ai , where we will be posting tutorials, examples, and more documentation in the coming days.","title":"How you can get started with nbdev"},{"location":"blog/posts/2022-07-28-nbdev2/#thank-you","text":"This new version of nbdev was a team effort by many wonderful people. We want to highlight two people who have made outstanding contributions: Wasim Lorgat was instrumental across different areas, including significant contributions to fastcore, execnb, and nbdev, as well as the implementation of the new nbdev home page . With Wasim\u2019s help, we were able to push nbdev to a new level of functionality and quality. JJ Allaire is not only the CEO of RStudio but also the steward of Quarto. JJ was incredibly responsive and eager to work with us on nbdev and added many features to Quarto specifically with nbdev in mind, such as notebook filters . We were also astounded by the attention to detail and the pace at which bugs are addressed. This new version of nbdev would not have been possible without JJ\u2019s help, and we are excited to continue to work with him. We also want to thank the amazing fastai community, notably Isaac Flath , Benjamin Warner and Zach Mueller for their tireless work on this project.","title":"Thank You"},{"location":"blog/posts/2022-07-28-nbdev2/#a-conversation-with-jj-allaire","text":"To celebrate the launch of nbdev v2 and Quarto, Jeremy sat down with the CEO of Posit (previously known as RStudio, the company behind Quarto), JJ Allaire, to talk about software development, scientific publishing, R, Python, literate programming, and much more.","title":"A conversation with JJ Allaire"},{"location":"blog/posts/2022-08-25-jupyter-git/","text":"The Jupyter+git problem is now solved \u00a4 Jeremy Howard 8/25/22 Originally posted on the fast.ai blog Jupyter notebooks don\u2019t work with git by default. With nbdev2 , the Jupyter+git problem has been totally solved. It provides a set of hooks which provide clean git diffs, solve most git conflicts automatically, and ensure that any remaining conflicts can be resolved entirely within the standard Jupyter notebook environment. To get started, follow the directions on Git-friendly Jupyter . The Jupyter+git problem \u00a4 Jupyter notebooks are a powerful tool for scientists, engineers, technical writers, students, teachers, and more. They provide an ideal notebook environment for interactively exploring data and code, writing programs, and documenting the results as dashboards, books, or blogs. But when collaborating with others, this ideal environment goes up in smoke. That\u2019s because tools such as git, which are the most popular approaches for asynchronous collaboration, makes notebooks unusable. Literally. Here\u2019s what it looks like if you and a colleague both modify a notebook cell (including, in many cases, simply executing a cell withuout changing it), and then try to open that notebook later: The reason for this stems from a fundamental incompatibility between the format Jupyter notebooks use (JSON) and the format that git conflict markers assume by default (plain lines of text). This is what it looks like when git adds its conflict markers to a notebook: \"source\": [ < < < < < < HEAD \"z=3\\n\", ====== \"z=2\\n\", >>>>>> a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35 \"z\" ] That\u2019s not valid JSON, and therefore Jupyter can\u2019t open it. Conflicts are particularly common in notebooks, because Jupyter changes the following every time you run a notebook: Every cell includes a number indicating what order it was run in. If you and a colleague run the cells in different orders, you\u2019ll have a conflict in every single cell! This would take a very long time to fix manually For every figure, such as a plot, Jupyter includes not only the image itself in the notebook, but also a plain text description that includes the id (like a memory address) of the object, such as <matplotlib.axes._subplots.AxesSubplot at 0x7fbc113dbe90> . This changes every time you execute a notebook, and therefore will create a conflict every time two people execute this cell Some outputs may be non-deterministic, such as a notebook that uses random numbers, or that interacts with a service that provides different outputs over time (such as a weather service) Jupyter adds metadata to the notebook describing the environment it was last run in, such as the name of the kernel. This often varies across installations, and therefore two people saving a notebook (even without and other changes) will often end up with a conflict in the metadata. All these changes to notebook files also make git diffs of notebooks very verbose. This can make code reviews a challenge, and make git repos more bulky than necessary. The result of these problems is that many Jupyter users feel that collaborating with notebooks is a clunky, error-prone, and frustrating experience. (We\u2019ve even seen people on social media describe Jupyter\u2019s notebook format as \u201cstupid\u201d or \u201cterrible\u201d, despite otherwise professing their love for the software!) It turns out, however, that Jupyter and git can work together extremely well, with none of the above problems at all. All that\u2019s needed is a bit of special software\u2026 The solution \u00a4 Jupyter and git are both well-designed software systems that provide many powerful extensibility mechanisms. It turns out that we can use these to fully and automatically solve the Jupyter+git problem. We identified two categories of problems in the previous section: git conflicts lead to broken notebooks Unnecessary conflicts due to metadata and outputs. In our newly released nbdev2 , an open source Jupyter-based development platform, we\u2019ve solve each of the problems: A new merge driver for git provides \u201cnotebook-native\u201d conflict markers, resulting in notebooks that can be opened directly in Jupyter, even when there are git conflicts A new save hook for Jupyter automatically removes all unnecessary metadata and non-deterministic cell output. Here\u2019s what a conflict looks like in Jupyter with nbdev\u2019s merge driver: ![](../images/nbs/blog/posts/2022-08-25-jupyter-git/friendly-conflict.png) As you see, the local and remote change are each clearly displayed as separate cells in the notebook, allowing you to simply delete the version you don\u2019t want to keep, or combine the two cells as needed. The techniques used to make the merge driver work are quite fascinating \u2013 let\u2019s dive into the details! The nbdev2 git merge driver \u00a4 We provide here a summary of the git merge driver \u2013 for full details and source code see the nbdev.merge docs . Amazingly enough, the entire implementation is just 58 lines of code! The basic idea is to first \u201cundo\u201d the original git merge which created the conflict, and then \u201credo\u201d it at a cell level (instead of a line level) and looking only at cell source (not outputs or metadata). The \u201cundoing\u201d is straightforward: just create two copies of the conflicted file (representing the local and remove versions of the file), go through each git conflict marker, and replace the conflict section with either the local or remote version of the code. Now that we\u2019ve got the original local and remote notebooks, we can load the json using execnb.nbio , which will then give us an array of cells for each notebook. Now we\u2019re up to the interesting bit \u2013 creating cell-level diffs based only on the cell source. The Python standard library contains a very flexible and effective implementation of a diff algorithm in the difflib module. In particular, the SequenceMatcher class provides the fundamental building blocks for implementing your own conflict resolution system. We pass the two sets of cells (remote and local) to SequenceMatcher(...).get_matching_blocks() , and it returns a list of each section of cells that match (i.e. have no conflicts/differences). We can then go through each matching section and copy them into the final notebook, and through each non-matching section and copy in each of the remote and local cells (add cells between them to mark the conflicts). Making SequenceMatcher work with notebook cells (represented in nbdev by the NbCell class) requires only adding __hash__ and __eq__ methods to NbCell . In each case, these methods are defined to look only at the actual source code, and not at any metadata or outputs. As a result, SequenceMatcher will only show differences in source code, and will ignore differences in everything else. With a single line of configuration, we can ask git to call our python script, instead of its default line-based implementation, any time it is merging changes. nbdev_install_hooks sets up this configuration automatically, so after running it, git conflicts become much less common, and never result in broken notebooks. The nbdev2 Jupyter save hook \u00a4 Solving git merges locally is extremely helpful, but we need to solve them remotely as well. For instance, if a contributor submits a pull request (PR), and then someone else commits to the same notebook before the PR is merged, the PR might now have a conflict like this: \"outputs\": [ { < < < < < < HEAD \"execution_count\": 7, ====== \"execution_count\": 5, >>>>>> a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35 \"metadata\": {}, This conflict shows that the two contributors have run cells in different orders (or perhaps one added a couple of cells above in the notebook), so their commits have conflicting execution counts. GitHub will refuse to allow this PR to be merged until this conflict is fixed. But of course we don\u2019t really care about the conflict at all \u2013 it doesn\u2019t matter what, if any, execution count is stored in the notebook. So we\u2019d really prefer to ignore this difference entirely! Thankfully, Jupyter provides a \u201cpre-save\u201d hook which allows code to be run every time a notebook is saved. nbdev uses this to set up a hook which removes all unnecessary metadata (including execution_count ) on saving. That means there\u2019s no pointless conflicts like the one above, because no commits will have this information stored in the first place. Background \u00a4 Here at fast.ai we use Jupyter for everything. All our tests, documentation, and module source code for all of our many libraries is entirely developed in notebooks (using nbdev, of course!) And we use git for all our libraries too. Some of our repositories have many hundreds of contributors. Therefore solving the Jupyter+git problem has been critical for us. The solution presented here is the result of years of work by many people. Our first approach, developed by Stas Bekman and me, was to use git \u201csmudge\u201d and \u201cclean\u201d filters that automatically rewrote all notebook json to remove unneeded metadata when committing. This helped a bit, but git quite often ended up in an odd state where it was impossible to merge. In nbdev v1 Sylvain Gugger created an amazing tool called nbdev_fix_merge which used very clever custom logic to manually fix merge conflicts in notebooks, to ensure that they could opened in Jupyter. For nbdev v2 I did a from-scratch rewrite of every part of the library, and I realised that we could replace the custom logic with the SequenceMatcher approach described above. None of these steps fully resolved the Jupyter+git problem, since we were getting frequent merge errors caused by the smudge/clean git filters, and conflicts required manually running nbdev_fix_merge . Wasim Lorgat realised that we could resolve the smudge/clean issue by moving that logic into an nbdev save hook, and avoid the manual fix step by moving that logic into a git merge driver. This resolved the final remaining issues! (I was actually quite stunned that Wasim went from our first discussion of the outstanding problems, to figuring out how to solve all of them, in the space of about two days\u2026) The result \u00a4 The new tools in nbdev2, which we\u2019ve been using internally for the last few months, have been transformational to our workflow. The Jupyter+git problem has been totally solved. I\u2019ve seen no unnecessary conflicts, cell-level merges have worked like magic, and on the few occassions where I\u2019ve changed the source in the same cell as a collaborator, fixing the conflict in Jupyter has been straightforward and convenient. Postscript: other Jupyter+git tools \u00a4 ReviewNB \u00a4 There is one other tool which we\u2019ve found very helpful in using Jupyter with git, which is ReviewNB . ReviewNB solves the problem of doing pull requests with notebooks. GitHub\u2019s code review GUI only works well for line-based file formats, such as plain python scripts. This works fine with the Python modules that nbdev exports, and I often do reviews directly on the Python files, instead of the source notebooks. However, much of the time I\u2019d rather do reviews on the source notebooks, because: I want to review the documentation and tests, not just the implementation I want to see the changes to cell outputs, such as charts and tables, not just the code. For this purpose, ReviewNB is perfect. Just like nbdev makes git merges and commits Jupyter-friendly, ReviewNB makes code reviews Jupyter-friendly. A picture is worth a thousand words, so rather than trying to explain, I\u2019ll just show this picture from the ReviewNB website of what PRs look like in their interface: An alternative solution: Jupytext \u00a4 Another potential solution to the Jupyter+git problem might be to use Jupytext . Jupytext saves notebooks in a line-based format, instead of in JSON. This means that all the usual git machinery, such as merges and PRs, works fine. Jupytext can even use Quarto\u2019s format, qmd , as a format for saving notebooks, which then can be used to generate a website. Jupytext can be a bit tricky to manage when you want to save your cell outputs (which I generally want to do, since many of my notebooks take a long time to run \u2013 e.g training deep learning models.) Whilst Jupytext can save outputs in a linked ipynb file, managing this linkage gets complex, and ends up with the Jupyter+git problem all over again! If you don\u2019t need to save outputs, then you might find Jupytext sufficient \u2013 although of course you\u2019ll miss out on the cell-based code reviews of ReviewNB and your users won\u2019t be able to read your notebooks properly when they\u2019re browsing GitHub. nbdime \u00a4 There\u2019s also an interesting project called nbdime which has its own git drivers and filters. Since they\u2019re not really compatible with nbdev (partly because they tackle some of the same problems in different ways) I haven\u2019t used them much, so haven\u2019t got an informed opinion about them. However I do use nbdime\u2019s Jupyter extension sometimes, which provides a view similar to ReviewNB, but for local changes instead of PRs. If you want to try to yourself, follow the directions on Git-friendly Jupyter to get started.","title":"Index"},{"location":"blog/posts/2022-08-25-jupyter-git/#the-jupytergit-problem-is-now-solved","text":"Jeremy Howard 8/25/22 Originally posted on the fast.ai blog Jupyter notebooks don\u2019t work with git by default. With nbdev2 , the Jupyter+git problem has been totally solved. It provides a set of hooks which provide clean git diffs, solve most git conflicts automatically, and ensure that any remaining conflicts can be resolved entirely within the standard Jupyter notebook environment. To get started, follow the directions on Git-friendly Jupyter .","title":"The Jupyter+git problem is now solved"},{"location":"blog/posts/2022-08-25-jupyter-git/#the-jupytergit-problem","text":"Jupyter notebooks are a powerful tool for scientists, engineers, technical writers, students, teachers, and more. They provide an ideal notebook environment for interactively exploring data and code, writing programs, and documenting the results as dashboards, books, or blogs. But when collaborating with others, this ideal environment goes up in smoke. That\u2019s because tools such as git, which are the most popular approaches for asynchronous collaboration, makes notebooks unusable. Literally. Here\u2019s what it looks like if you and a colleague both modify a notebook cell (including, in many cases, simply executing a cell withuout changing it), and then try to open that notebook later: The reason for this stems from a fundamental incompatibility between the format Jupyter notebooks use (JSON) and the format that git conflict markers assume by default (plain lines of text). This is what it looks like when git adds its conflict markers to a notebook: \"source\": [ < < < < < < HEAD \"z=3\\n\", ====== \"z=2\\n\", >>>>>> a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35 \"z\" ] That\u2019s not valid JSON, and therefore Jupyter can\u2019t open it. Conflicts are particularly common in notebooks, because Jupyter changes the following every time you run a notebook: Every cell includes a number indicating what order it was run in. If you and a colleague run the cells in different orders, you\u2019ll have a conflict in every single cell! This would take a very long time to fix manually For every figure, such as a plot, Jupyter includes not only the image itself in the notebook, but also a plain text description that includes the id (like a memory address) of the object, such as <matplotlib.axes._subplots.AxesSubplot at 0x7fbc113dbe90> . This changes every time you execute a notebook, and therefore will create a conflict every time two people execute this cell Some outputs may be non-deterministic, such as a notebook that uses random numbers, or that interacts with a service that provides different outputs over time (such as a weather service) Jupyter adds metadata to the notebook describing the environment it was last run in, such as the name of the kernel. This often varies across installations, and therefore two people saving a notebook (even without and other changes) will often end up with a conflict in the metadata. All these changes to notebook files also make git diffs of notebooks very verbose. This can make code reviews a challenge, and make git repos more bulky than necessary. The result of these problems is that many Jupyter users feel that collaborating with notebooks is a clunky, error-prone, and frustrating experience. (We\u2019ve even seen people on social media describe Jupyter\u2019s notebook format as \u201cstupid\u201d or \u201cterrible\u201d, despite otherwise professing their love for the software!) It turns out, however, that Jupyter and git can work together extremely well, with none of the above problems at all. All that\u2019s needed is a bit of special software\u2026","title":"The Jupyter+git problem"},{"location":"blog/posts/2022-08-25-jupyter-git/#the-solution","text":"Jupyter and git are both well-designed software systems that provide many powerful extensibility mechanisms. It turns out that we can use these to fully and automatically solve the Jupyter+git problem. We identified two categories of problems in the previous section: git conflicts lead to broken notebooks Unnecessary conflicts due to metadata and outputs. In our newly released nbdev2 , an open source Jupyter-based development platform, we\u2019ve solve each of the problems: A new merge driver for git provides \u201cnotebook-native\u201d conflict markers, resulting in notebooks that can be opened directly in Jupyter, even when there are git conflicts A new save hook for Jupyter automatically removes all unnecessary metadata and non-deterministic cell output. Here\u2019s what a conflict looks like in Jupyter with nbdev\u2019s merge driver: ![](../images/nbs/blog/posts/2022-08-25-jupyter-git/friendly-conflict.png) As you see, the local and remote change are each clearly displayed as separate cells in the notebook, allowing you to simply delete the version you don\u2019t want to keep, or combine the two cells as needed. The techniques used to make the merge driver work are quite fascinating \u2013 let\u2019s dive into the details!","title":"The solution"},{"location":"blog/posts/2022-08-25-jupyter-git/#the-nbdev2-git-merge-driver","text":"We provide here a summary of the git merge driver \u2013 for full details and source code see the nbdev.merge docs . Amazingly enough, the entire implementation is just 58 lines of code! The basic idea is to first \u201cundo\u201d the original git merge which created the conflict, and then \u201credo\u201d it at a cell level (instead of a line level) and looking only at cell source (not outputs or metadata). The \u201cundoing\u201d is straightforward: just create two copies of the conflicted file (representing the local and remove versions of the file), go through each git conflict marker, and replace the conflict section with either the local or remote version of the code. Now that we\u2019ve got the original local and remote notebooks, we can load the json using execnb.nbio , which will then give us an array of cells for each notebook. Now we\u2019re up to the interesting bit \u2013 creating cell-level diffs based only on the cell source. The Python standard library contains a very flexible and effective implementation of a diff algorithm in the difflib module. In particular, the SequenceMatcher class provides the fundamental building blocks for implementing your own conflict resolution system. We pass the two sets of cells (remote and local) to SequenceMatcher(...).get_matching_blocks() , and it returns a list of each section of cells that match (i.e. have no conflicts/differences). We can then go through each matching section and copy them into the final notebook, and through each non-matching section and copy in each of the remote and local cells (add cells between them to mark the conflicts). Making SequenceMatcher work with notebook cells (represented in nbdev by the NbCell class) requires only adding __hash__ and __eq__ methods to NbCell . In each case, these methods are defined to look only at the actual source code, and not at any metadata or outputs. As a result, SequenceMatcher will only show differences in source code, and will ignore differences in everything else. With a single line of configuration, we can ask git to call our python script, instead of its default line-based implementation, any time it is merging changes. nbdev_install_hooks sets up this configuration automatically, so after running it, git conflicts become much less common, and never result in broken notebooks.","title":"The nbdev2 git merge driver"},{"location":"blog/posts/2022-08-25-jupyter-git/#the-nbdev2-jupyter-save-hook","text":"Solving git merges locally is extremely helpful, but we need to solve them remotely as well. For instance, if a contributor submits a pull request (PR), and then someone else commits to the same notebook before the PR is merged, the PR might now have a conflict like this: \"outputs\": [ { < < < < < < HEAD \"execution_count\": 7, ====== \"execution_count\": 5, >>>>>> a7ec1b0bfb8e23b05fd0a2e6cafcb41cd0fb1c35 \"metadata\": {}, This conflict shows that the two contributors have run cells in different orders (or perhaps one added a couple of cells above in the notebook), so their commits have conflicting execution counts. GitHub will refuse to allow this PR to be merged until this conflict is fixed. But of course we don\u2019t really care about the conflict at all \u2013 it doesn\u2019t matter what, if any, execution count is stored in the notebook. So we\u2019d really prefer to ignore this difference entirely! Thankfully, Jupyter provides a \u201cpre-save\u201d hook which allows code to be run every time a notebook is saved. nbdev uses this to set up a hook which removes all unnecessary metadata (including execution_count ) on saving. That means there\u2019s no pointless conflicts like the one above, because no commits will have this information stored in the first place.","title":"The nbdev2 Jupyter save hook"},{"location":"blog/posts/2022-08-25-jupyter-git/#background","text":"Here at fast.ai we use Jupyter for everything. All our tests, documentation, and module source code for all of our many libraries is entirely developed in notebooks (using nbdev, of course!) And we use git for all our libraries too. Some of our repositories have many hundreds of contributors. Therefore solving the Jupyter+git problem has been critical for us. The solution presented here is the result of years of work by many people. Our first approach, developed by Stas Bekman and me, was to use git \u201csmudge\u201d and \u201cclean\u201d filters that automatically rewrote all notebook json to remove unneeded metadata when committing. This helped a bit, but git quite often ended up in an odd state where it was impossible to merge. In nbdev v1 Sylvain Gugger created an amazing tool called nbdev_fix_merge which used very clever custom logic to manually fix merge conflicts in notebooks, to ensure that they could opened in Jupyter. For nbdev v2 I did a from-scratch rewrite of every part of the library, and I realised that we could replace the custom logic with the SequenceMatcher approach described above. None of these steps fully resolved the Jupyter+git problem, since we were getting frequent merge errors caused by the smudge/clean git filters, and conflicts required manually running nbdev_fix_merge . Wasim Lorgat realised that we could resolve the smudge/clean issue by moving that logic into an nbdev save hook, and avoid the manual fix step by moving that logic into a git merge driver. This resolved the final remaining issues! (I was actually quite stunned that Wasim went from our first discussion of the outstanding problems, to figuring out how to solve all of them, in the space of about two days\u2026)","title":"Background"},{"location":"blog/posts/2022-08-25-jupyter-git/#the-result","text":"The new tools in nbdev2, which we\u2019ve been using internally for the last few months, have been transformational to our workflow. The Jupyter+git problem has been totally solved. I\u2019ve seen no unnecessary conflicts, cell-level merges have worked like magic, and on the few occassions where I\u2019ve changed the source in the same cell as a collaborator, fixing the conflict in Jupyter has been straightforward and convenient.","title":"The result"},{"location":"blog/posts/2022-08-25-jupyter-git/#postscript-other-jupytergit-tools","text":"","title":"Postscript: other Jupyter+git tools"},{"location":"blog/posts/2022-08-25-jupyter-git/#reviewnb","text":"There is one other tool which we\u2019ve found very helpful in using Jupyter with git, which is ReviewNB . ReviewNB solves the problem of doing pull requests with notebooks. GitHub\u2019s code review GUI only works well for line-based file formats, such as plain python scripts. This works fine with the Python modules that nbdev exports, and I often do reviews directly on the Python files, instead of the source notebooks. However, much of the time I\u2019d rather do reviews on the source notebooks, because: I want to review the documentation and tests, not just the implementation I want to see the changes to cell outputs, such as charts and tables, not just the code. For this purpose, ReviewNB is perfect. Just like nbdev makes git merges and commits Jupyter-friendly, ReviewNB makes code reviews Jupyter-friendly. A picture is worth a thousand words, so rather than trying to explain, I\u2019ll just show this picture from the ReviewNB website of what PRs look like in their interface:","title":"ReviewNB"},{"location":"blog/posts/2022-08-25-jupyter-git/#an-alternative-solution-jupytext","text":"Another potential solution to the Jupyter+git problem might be to use Jupytext . Jupytext saves notebooks in a line-based format, instead of in JSON. This means that all the usual git machinery, such as merges and PRs, works fine. Jupytext can even use Quarto\u2019s format, qmd , as a format for saving notebooks, which then can be used to generate a website. Jupytext can be a bit tricky to manage when you want to save your cell outputs (which I generally want to do, since many of my notebooks take a long time to run \u2013 e.g training deep learning models.) Whilst Jupytext can save outputs in a linked ipynb file, managing this linkage gets complex, and ends up with the Jupyter+git problem all over again! If you don\u2019t need to save outputs, then you might find Jupytext sufficient \u2013 although of course you\u2019ll miss out on the cell-based code reviews of ReviewNB and your users won\u2019t be able to read your notebooks properly when they\u2019re browsing GitHub.","title":"An alternative solution: Jupytext"},{"location":"blog/posts/2022-08-25-jupyter-git/#nbdime","text":"There\u2019s also an interesting project called nbdime which has its own git drivers and filters. Since they\u2019re not really compatible with nbdev (partly because they tackle some of the same problems in different ways) I haven\u2019t used them much, so haven\u2019t got an informed opinion about them. However I do use nbdime\u2019s Jupyter extension sometimes, which provides a view similar to ReviewNB, but for local changes instead of PRs. If you want to try to yourself, follow the directions on Git-friendly Jupyter to get started.","title":"nbdime"},{"location":"blog/posts/2022-11-07-spaces/","text":"Create A \ud83e\udd17 Space From A Notebook \u00a4 Hamel Husain 11/7/22 Hugging Face Spaces provides an easy ways to deploy a web app with python. Gradio is one of my favorite tools for building these web apps. For example, the cover-image for this blog post was generated with a Gradio App ![^1] Gradio also allows you to prototype your web apps in notebooks which allows you to iterate fast. Unfortunately, Hugging Face Spaces requires you to package your web application code as a python script named app.py . However, thanks to nbdev , you can deploy a Gradio app to Spaces from a notebook without having to refactor your code into a script! When you finish this tutorial, you will have an app that looks like this: [![](../images/nbs/blog/posts/2022-11-07-spaces/final_app.png)](https://huggingface.co/spaces/hamel/hfspace_demo) A Gradio app that shows the size of a HF Dataset. The above app allows you to lookup the size of any Hugging Face Dataset , using the Hugging Face Datasets Server API . Authoring your spaces in notebooks offers a number of benefits such as the ability to: Document your code (with quarto or nbdev ) Prototype and author your code (with nbdev.export.export_nb ) Test your code (with nbdev_test ) \u2026 All from the same environment! 1. Create a Gradio-enabled Space on Hugging Face \u00a4 The first step is to create a space and select the appropriate sdk (which is Gradio in this example), according to these instructions : After you are done creating the space, clone the repo locally. In this example, I ran the command git clone https://huggingface.co/spaces/hamel/hfspace_demo . 2. Create A Notebook \u00a4 Before getting started you will want to install the dependencies for this tutorial: ! pip install git + https : // github . com / fastai / nbdev . git gradio fastcore Create a notebook called app.ipynb in the root of your newly cloned repo. Alternatively, download the notebook and follow along. > **Download the notebook and follow along** > > This blog post is a verbose version of the \u201cnotebook\u201d you can use to > create a Gradio app. However, it can be useful to see just the code > without any of the prose. A [concise version of this notebook is > here](https://gist.github.com/hamelsmu/35be07d242f3f19063c3a3839127dc67). > I recommend taking a look at this notebook during or after you read > this blog post. 3. Make an app with Gradio \u00a4 Below, I will create a gradio app in a notebook and show you how to deploy it to Hugging Face Spaces . First, lets import the libraries we need, which in this case are gradio and fastcore : #|export import gradio as gr from fastcore.net import urljson , HTTPError Next, write the functions your gradio app will use. Because of nbdev , you can prototype and package your code all in one place. The special comment #|export marks which cells will be sent to a python script (more on this later). Note that there are only three cells in this notebook with the #|export directive. #|export def size ( repo : str ): \"Returns the size in GB of a HuggingFace Dataset.\" url = f 'https://huggingface.co/api/datasets/ { repo } ' try : resp = urljson ( f ' { url } /treesize/main' ) except HTTPError : return f 'Did not find repo: { url } ' gb = resp [ 'size' ] / 1e9 return f ' { gb : .2f } GB' size takes as an input a Hugging Face Dataset repo and returns the total size in GB of the data. For example, I can check the size of tglcourse/CelebA-faces-cropped-128 like so: size ( \"tglcourse/CelebA-faces-cropped-128\" ) '5.49 GB' You can construct a simple UI with the gradio.interface and then call the launch method of that interface to display a preview in a notebook. This is a great way to test your app to see if it works: #|export iface = gr . Interface ( fn = size , inputs = gr . Text ( value = \"tglcourse/CelebA-faces-cropped-128\" ), outputs = \"text\" ) iface . launch ( height = 450 , width = 500 ) Running on local URL: http://127.0.0.1:7861 To create a public link, set `share=True` in `launch()`. ![](../images/nbs/blog/posts/2022-11-07-spaces/gradio_local.png) Note how running the launch() method in a notebook runs a webserver in the background. Below, I call the close() method to close the webserver. # this is only necessary in a notebook iface . close () Closing server running on port: 7861 4. Convert This Notebook Into A Gradio App \u00a4 In order to host this code on Hugging Face Spaces, you will export parts of this notebook to a script named app.py . As a reminder, this is what the special #|export comment that you have seen in cells above do! You can export code from this notebook like so: from nbdev.export import nb_export nb_export ( 'app.ipynb' , lib_path = '.' , name = 'app' ) Understanding what is generated \u00a4 Notice how the contents of app.py only contain the exported cells from this notebook: ! cat app . py # AUTOGENERATED! DO NOT EDIT! File to edit: app.ipynb. # %% auto 0 __all__ = [ 'iface' , 'size' ] # %% app.ipynb 6 import gradio as gr from fastcore.net import urljson , HTTPError # %% app.ipynb 8 def size ( repo : str ): \"Returns the size in GB of a HuggingFace Dataset.\" url = f 'https://huggingface.co/api/datasets/ { repo } ' try : resp = urljson ( f ' { url } /treesize/main' ) except HTTPError : return f 'Did not find repo: { url } ' gb = resp [ 'size' ] / 1e9 return f ' { gb : .2f } GB' # %% app.ipynb 12 iface = gr . Interface ( fn = size , inputs = gr . Text ( value = \"tglcourse/CelebA-faces-cropped-128\" ), outputs = \"text\" ) iface . launch ( height = 450 , width = 500 ) Fill out requirements.txt \u00a4 You must supply a requirements.txt file so the Gradio app knows how to build your dependencies. In this example, the only dependency other than Gradio is fastcore . You don\u2019t need to specify Gradio itself as a dependency in requirements.txt , so our requirements.txt file has only one dependency: %% writefile requirements . txt fastcore Writing requirements.txt Note: you may want to add operating system dependencies in addition to python dependencies. You can do this via a packages.txt file as documented here . 5. Launch Your Gradio App \u00a4 To launch your gradio app, you need to commit the changes to the Hugging Face repo: git add -A ; git commit -m \"Add application files\" ; git push Voil\u00e0! Enjoy your Gradio App \u00a4 After a couple of minutes, you will see your app published! This app is published here . Shameless Plug: nbdev \u00a4 Hopefully you felt something magical while doing this example. Even though the target application required you to write a python script ( app.py ), you didn\u2019t have to refactor your script from a notebook! I believe that you shouldn\u2019t have to refactor your code and switch contexts even when creating python packages! If this intrigues you, check out nbdev [^1]: The prompt that generated the cover image is: \u201cA data scientist at a computer in a futuristic city with a view of the planet Jupyter in the night sky, trending on artstation, high detail, science-fiction\u201d","title":"Index"},{"location":"blog/posts/2022-11-07-spaces/#create-a-space-from-a-notebook","text":"Hamel Husain 11/7/22 Hugging Face Spaces provides an easy ways to deploy a web app with python. Gradio is one of my favorite tools for building these web apps. For example, the cover-image for this blog post was generated with a Gradio App ![^1] Gradio also allows you to prototype your web apps in notebooks which allows you to iterate fast. Unfortunately, Hugging Face Spaces requires you to package your web application code as a python script named app.py . However, thanks to nbdev , you can deploy a Gradio app to Spaces from a notebook without having to refactor your code into a script! When you finish this tutorial, you will have an app that looks like this: [![](../images/nbs/blog/posts/2022-11-07-spaces/final_app.png)](https://huggingface.co/spaces/hamel/hfspace_demo) A Gradio app that shows the size of a HF Dataset. The above app allows you to lookup the size of any Hugging Face Dataset , using the Hugging Face Datasets Server API . Authoring your spaces in notebooks offers a number of benefits such as the ability to: Document your code (with quarto or nbdev ) Prototype and author your code (with nbdev.export.export_nb ) Test your code (with nbdev_test ) \u2026 All from the same environment!","title":"Create A \ud83e\udd17 Space From A Notebook"},{"location":"blog/posts/2022-11-07-spaces/#1-create-a-gradio-enabled-space-on-hugging-face","text":"The first step is to create a space and select the appropriate sdk (which is Gradio in this example), according to these instructions : After you are done creating the space, clone the repo locally. In this example, I ran the command git clone https://huggingface.co/spaces/hamel/hfspace_demo .","title":"1. Create a Gradio-enabled Space on Hugging Face"},{"location":"blog/posts/2022-11-07-spaces/#2-create-a-notebook","text":"Before getting started you will want to install the dependencies for this tutorial: ! pip install git + https : // github . com / fastai / nbdev . git gradio fastcore Create a notebook called app.ipynb in the root of your newly cloned repo. Alternatively, download the notebook and follow along. > **Download the notebook and follow along** > > This blog post is a verbose version of the \u201cnotebook\u201d you can use to > create a Gradio app. However, it can be useful to see just the code > without any of the prose. A [concise version of this notebook is > here](https://gist.github.com/hamelsmu/35be07d242f3f19063c3a3839127dc67). > I recommend taking a look at this notebook during or after you read > this blog post.","title":"2. Create A Notebook"},{"location":"blog/posts/2022-11-07-spaces/#3-make-an-app-with-gradio","text":"Below, I will create a gradio app in a notebook and show you how to deploy it to Hugging Face Spaces . First, lets import the libraries we need, which in this case are gradio and fastcore : #|export import gradio as gr from fastcore.net import urljson , HTTPError Next, write the functions your gradio app will use. Because of nbdev , you can prototype and package your code all in one place. The special comment #|export marks which cells will be sent to a python script (more on this later). Note that there are only three cells in this notebook with the #|export directive. #|export def size ( repo : str ): \"Returns the size in GB of a HuggingFace Dataset.\" url = f 'https://huggingface.co/api/datasets/ { repo } ' try : resp = urljson ( f ' { url } /treesize/main' ) except HTTPError : return f 'Did not find repo: { url } ' gb = resp [ 'size' ] / 1e9 return f ' { gb : .2f } GB' size takes as an input a Hugging Face Dataset repo and returns the total size in GB of the data. For example, I can check the size of tglcourse/CelebA-faces-cropped-128 like so: size ( \"tglcourse/CelebA-faces-cropped-128\" ) '5.49 GB' You can construct a simple UI with the gradio.interface and then call the launch method of that interface to display a preview in a notebook. This is a great way to test your app to see if it works: #|export iface = gr . Interface ( fn = size , inputs = gr . Text ( value = \"tglcourse/CelebA-faces-cropped-128\" ), outputs = \"text\" ) iface . launch ( height = 450 , width = 500 ) Running on local URL: http://127.0.0.1:7861 To create a public link, set `share=True` in `launch()`. ![](../images/nbs/blog/posts/2022-11-07-spaces/gradio_local.png) Note how running the launch() method in a notebook runs a webserver in the background. Below, I call the close() method to close the webserver. # this is only necessary in a notebook iface . close () Closing server running on port: 7861","title":"3. Make an app with Gradio"},{"location":"blog/posts/2022-11-07-spaces/#4-convert-this-notebook-into-a-gradio-app","text":"In order to host this code on Hugging Face Spaces, you will export parts of this notebook to a script named app.py . As a reminder, this is what the special #|export comment that you have seen in cells above do! You can export code from this notebook like so: from nbdev.export import nb_export nb_export ( 'app.ipynb' , lib_path = '.' , name = 'app' )","title":"4. Convert This Notebook Into A Gradio App"},{"location":"blog/posts/2022-11-07-spaces/#understanding-what-is-generated","text":"Notice how the contents of app.py only contain the exported cells from this notebook: ! cat app . py # AUTOGENERATED! DO NOT EDIT! File to edit: app.ipynb. # %% auto 0 __all__ = [ 'iface' , 'size' ] # %% app.ipynb 6 import gradio as gr from fastcore.net import urljson , HTTPError # %% app.ipynb 8 def size ( repo : str ): \"Returns the size in GB of a HuggingFace Dataset.\" url = f 'https://huggingface.co/api/datasets/ { repo } ' try : resp = urljson ( f ' { url } /treesize/main' ) except HTTPError : return f 'Did not find repo: { url } ' gb = resp [ 'size' ] / 1e9 return f ' { gb : .2f } GB' # %% app.ipynb 12 iface = gr . Interface ( fn = size , inputs = gr . Text ( value = \"tglcourse/CelebA-faces-cropped-128\" ), outputs = \"text\" ) iface . launch ( height = 450 , width = 500 )","title":"Understanding what is generated"},{"location":"blog/posts/2022-11-07-spaces/#fill-out-requirementstxt","text":"You must supply a requirements.txt file so the Gradio app knows how to build your dependencies. In this example, the only dependency other than Gradio is fastcore . You don\u2019t need to specify Gradio itself as a dependency in requirements.txt , so our requirements.txt file has only one dependency: %% writefile requirements . txt fastcore Writing requirements.txt Note: you may want to add operating system dependencies in addition to python dependencies. You can do this via a packages.txt file as documented here .","title":"Fill out requirements.txt"},{"location":"blog/posts/2022-11-07-spaces/#5-launch-your-gradio-app","text":"To launch your gradio app, you need to commit the changes to the Hugging Face repo: git add -A ; git commit -m \"Add application files\" ; git push","title":"5. Launch Your Gradio App"},{"location":"blog/posts/2022-11-07-spaces/#voila-enjoy-your-gradio-app","text":"After a couple of minutes, you will see your app published! This app is published here .","title":"Voil\u00e0! Enjoy your Gradio App"},{"location":"blog/posts/2022-11-07-spaces/#shameless-plug-nbdev","text":"Hopefully you felt something magical while doing this example. Even though the target application required you to write a python script ( app.py ), you didn\u2019t have to refactor your script from a notebook! I believe that you shouldn\u2019t have to refactor your code and switch contexts even when creating python packages! If this intrigues you, check out nbdev [^1]: The prompt that generated the cover image is: \u201cA data scientist at a computer in a futuristic city with a view of the planet Jupyter in the night sky, trending on artstation, high detail, science-fiction\u201d","title":"Shameless Plug: nbdev"},{"location":"explanations/","text":"Explanations \u00a4 These explanations provide background information on how nbdev is designed and how it works. They are designed to help people who want to more deeply understand the nbdev system.","title":"Explanations"},{"location":"explanations/#explanations","text":"These explanations provide background information on how nbdev is designed and how it works. They are designed to help people who want to more deeply understand the nbdev system.","title":"Explanations"},{"location":"explanations/config/","text":"Settings.ini \u00a4 All of nbdev\u2019s configuration is done through a file called settings.ini which lives in the root of your repo. It\u2019s in ConfigParser format. For example, here\u2019s the first few lines of nbdev\u2019s settings.ini file [DEFAULT] lib_name = nbdev description = Create delightful software with Jupyter Notebooks copyright = 2020 onwards, Jeremy Howard keywords = nbdev fastai jupyter notebook export user = fastai author = Jeremy Howard and Hamel Husain author_email = j@fast.ai branch = master min_python = 3.7 You can create this file with nbdev_create_config (in which case you pass the settings manually), or with nbdev_new (which sets it up automatically for you from your repo settings). Here are all of nbdev\u2019s settings (excluding the path and cfg_name parameters which decide where the config file is saved): Type Default Details repo str None Repo name branch str None Repo default branch user str None Repo username author str None Package author\u2019s name author_email str None Package author\u2019s email address description str None Short summary of the package path str . Path to create config file cfg_name str settings.ini Name of config file to create lib_name str %(repo)s Package name git_url str https://github.com/%(user)s/%(repo)s Repo URL custom_sidebar bool_arg False Use a custom sidebar.yml? nbs_path Path nbs Path to notebooks lib_path Path None Path to package root (default: repo with - replaced by _ ) doc_path Path _docs Path to rendered docs tst_flags str notest Test flags version str 0.0.1 Version of this release doc_host str https://%(user)s.github.io Hostname for docs doc_baseurl str /%(repo)s Base URL for docs keywords str nbdev jupyter notebook python Package keywords license str apache2 License for the package copyright str None Copyright for the package, defaults to \u2018 current_year onwards, author \u2019 status str 3 Development status PyPI classifier min_python str 3.7 Minimum Python version PyPI classifier audience str Developers Intended audience PyPI classifier language str English Language PyPI classifier recursive bool_arg True Include subfolders in notebook globs? black_formatting bool_arg False Format libraries with black? readme_nb str index.ipynb Notebook to export as repo readme title str %(lib_name)s Quarto website title allowed_metadata_keys str Preserve the list of keys in the main notebook metadata allowed_cell_metadata_keys str Preserve the list of keys in cell level metadata jupyter_hooks bool_arg True Run Jupyter hooks? clean_ids bool_arg True Remove ids from plaintext reprs? clear_all bool_arg False Remove all cell metadata and cell outputs? put_version_in_init bool_arg True Add the version to the main init .py in nbdev_export You can customise nbdev for all repositories for your user with a ~/.config/nbdev/settings.ini file.","title":"Settings.ini"},{"location":"explanations/config/#settingsini","text":"All of nbdev\u2019s configuration is done through a file called settings.ini which lives in the root of your repo. It\u2019s in ConfigParser format. For example, here\u2019s the first few lines of nbdev\u2019s settings.ini file [DEFAULT] lib_name = nbdev description = Create delightful software with Jupyter Notebooks copyright = 2020 onwards, Jeremy Howard keywords = nbdev fastai jupyter notebook export user = fastai author = Jeremy Howard and Hamel Husain author_email = j@fast.ai branch = master min_python = 3.7 You can create this file with nbdev_create_config (in which case you pass the settings manually), or with nbdev_new (which sets it up automatically for you from your repo settings). Here are all of nbdev\u2019s settings (excluding the path and cfg_name parameters which decide where the config file is saved): Type Default Details repo str None Repo name branch str None Repo default branch user str None Repo username author str None Package author\u2019s name author_email str None Package author\u2019s email address description str None Short summary of the package path str . Path to create config file cfg_name str settings.ini Name of config file to create lib_name str %(repo)s Package name git_url str https://github.com/%(user)s/%(repo)s Repo URL custom_sidebar bool_arg False Use a custom sidebar.yml? nbs_path Path nbs Path to notebooks lib_path Path None Path to package root (default: repo with - replaced by _ ) doc_path Path _docs Path to rendered docs tst_flags str notest Test flags version str 0.0.1 Version of this release doc_host str https://%(user)s.github.io Hostname for docs doc_baseurl str /%(repo)s Base URL for docs keywords str nbdev jupyter notebook python Package keywords license str apache2 License for the package copyright str None Copyright for the package, defaults to \u2018 current_year onwards, author \u2019 status str 3 Development status PyPI classifier min_python str 3.7 Minimum Python version PyPI classifier audience str Developers Intended audience PyPI classifier language str English Language PyPI classifier recursive bool_arg True Include subfolders in notebook globs? black_formatting bool_arg False Format libraries with black? readme_nb str index.ipynb Notebook to export as repo readme title str %(lib_name)s Quarto website title allowed_metadata_keys str Preserve the list of keys in the main notebook metadata allowed_cell_metadata_keys str Preserve the list of keys in cell level metadata jupyter_hooks bool_arg True Run Jupyter hooks? clean_ids bool_arg True Remove ids from plaintext reprs? clear_all bool_arg False Remove all cell metadata and cell outputs? put_version_in_init bool_arg True Add the version to the main init .py in nbdev_export You can customise nbdev for all repositories for your user with a ~/.config/nbdev/settings.ini file.","title":"Settings.ini"},{"location":"explanations/directives/","text":"Directives \u00a4 Directives are special comments that are preceded by #| that control: Cell visibility in rendered documentation How source code is generated from notebook cells Execution of cells for tests and docs nbdev augments Quarto by providing additional directives than what are available in Quarto. All Quarto directives can be used in nbdev notebooks. This cheat sheet lists all nbdev directives in addition to some Quarto directives we believe are important. We recommend consulting the quarto docs to see all of the directives available to you. To clarify the origin of directives we use the following emojis: \ud83d\udcd3 for nbdev-only directives . \ud83d\udd35 for Quarto directives (which also work in nbdev). Cell Visibility \u00a4 The following directives control cell visibility in rendered documentation: \ud83d\udcd3 #|hide \u00a4 Hide cell input and output. > **Example** > > The following will result in the contents of the cell and it\u2019s output > from being hidden: > > #|hide print ( 'you will not see this' ) > > Note that using `#|hide` is equivalent to using the Quarto directive > `#|include: false`: > > #|include: false print ( 'you will not see this' ) > > See the quarto docs for more information about `#|include`. \ud83d\udd35 #|echo: <true|false> \u00a4 Toggle the visibility of code-cell inputs. > **Example** > > #|echo: false print ( 'you can see the output but not the code!' ) > > which results in: > > you can see the output but not the code! \ud83d\udd35 #|output: <true|false|asis> \u00a4 Setting this to false hides the output of a cell. Setting this to asis renders the output as raw markdown. > **Example** > > The following cell will not display any output: > > #|output: false 1 + 1 > > The following cell with `#|output: asis` will produce the output > `hello fastai` rendered as markdown instead of a string: > > #|output: asis print ( \"`hello fastai`\" ) \ud83d\udcd3 #|hide_line \u00a4 Hide a specific line of code in an input cell. > **Example** > > def _secret (): ... for i in range ( 3 ): _secret () #|hide_line print ( i ) > > becomes this: > > def _secret (): ... for i in range ( 3 ): print ( i ) > > 0 > 1 > 2 \ud83d\udcd3 #|filter_stream <keyword> ... \u00a4 Filter lines containing specific keywords in cell outputs. > **Example** > > #|filter_stream FutureWarning MultiIndex print ( ' \\n ' . join ([ 'A line' , 'Foobar baz FutureWarning blah' , 'zig zagMultiIndex zoom' , 'Another line.' ])) > > will output this: > > A line > Another line. \ud83d\udd35 #|code-fold: <show|true> \u00a4 The #|code-fold directive allows you to collapse code cells. When set to true , the element is collapsed by default, when set to show show the element is shown by default. > **Example** > > When you set `#|code-fold: true`, the input cell is collapsed: > > > Code > > print ( 'this is' ) print ( 'output' ) print ( 'that takes' ) print ( 'lots of vertical space' ) > > > > this is > output > that takes > lots of vertical space > > When you set `#|code-fold: show` the input cell is shown but still in > a collapsible element: > > > Code > > print ( 'this is' ) print ( 'output' ) print ( 'that takes' ) print ( 'lots of vertical space' ) > > > > this is > output > that takes > lots of vertical space Generating Source Code \u00a4 The following directives control how source code is exported from code cells. \ud83d\udcd3 #|default_exp <name> \u00a4 Names the module where cells with the #|export directive will be exported to by default. > **Example** > > #| default_exp baz # In a new notebook cell: #| export def my_function (): pass > > If our package is named: `bitsnbytes` then we can do: > > from bitsnbytes.baz import my_function > > You can define the package name by using `lib_name` in `settings.ini`. \ud83d\udcd3 #|export \u00a4 Exports the items in the cell into the generated module and documentation. > **Example** > > #|export def say_hello ( to : str # name of person to say hello to ): \"Say hello to somebody\" return f 'Hello { to } !' > > The above cell will get exported to the module specified by > `#|default_exp`. These exports are automatically included in > [`__all__`](https://docs.python.org/3/tutorial/modules.html#importing-from-a-package) > for the module. To learn how export without inclusion in `__all__`, > see the `#|exporti` directive. > > Furthermore, the documentation for this function will automatically be > rendered like this: > > ------------------------------------------------------------------------ > > ### say_hello > > > say_hello (to:str) > > Say hello to somebody > > | | **Type** | **Details** | > |-----|----------|--------------------------------| > | to | str | name of person to say hello to | > > The docs are generated from this export using > [`show_doc`](https://nbdev.fast.ai/api/showdoc.html#show_doc). See > [these docs](docs.ipynb#how-show_doc-works) for a detailed discussion > of [`show_doc`](https://nbdev.fast.ai/api/showdoc.html#show_doc). \ud83d\udcd3 #|export <some.thing> \u00a4 Similar to #|export , but instead of exporting to the module named by #|default_exp export to the specified module. > **Example** > > If our package is named: `bitsnbytes`, and we have previously > included: `#|default_exp core` in this notebook, and we have an > existing notebook with `#|default_exp bar`, then: > > Earlier in the notebook: > > #|default_exp core > > A new notebook cell: > > #|export bar def foo (): pass > > then we can import this as: > > from bitsnbytes.bar import foo \ud83d\udcd3 #|exporti \u00a4 An i nternal export. Not included in __all__ or the docs. Useful for a function that is called by other functions in this module but is not part of the public API. Equivalently, you can prefix your function or method with _ e.g. def _private(): pass . \ud83d\udcd3 #|exports \u00a4 A s ource export. Like #|export but in addition to showing docs via showdoc.show_doc , it also shows the source code. > **Example** > > #|exports def say_hello ( to ): \"Say hello to somebody\" return f 'Hello { to } !' > > this will produce the following output: > > def say_hello ( to ): \"Say hello to somebody\" return f 'Hello { to } !' > > ------------------------------------------------------------------------ > > ### say_hello > > > say_hello (to) > > Say hello to somebody Cell Execution \u00a4 The following directives allow you to control how cells are executed during docs rendering and testing. \ud83d\udcd3 #|exec_doc \u00a4 Ensures that a cell is executed each time before generating docs. When a cell does not have this annotation, it is run according to the default rules described here . > **Example** > > datetime . datetime . now () > > datetime.datetime(2022, 8, 18, 9, 1, 43, 907609) > > However with the annotation: > > #|exec_doc datetime . datetime . now () > > we can see that the time has been updated: > > datetime . datetime . now () > > datetime.datetime(2022, 12, 21, 6, 0, 0, 283413) \ud83d\udd35 #|eval: <true|false> \u00a4 When set to false , the cell is ignored during testing. > **Example** > > #|eval: false raise Exception ( \"I'm not raised because I'm not run\" ) Cell execution when there is no directive \u00a4 When a cell has no directives, cells are run by nbdev according to the behavior described here .","title":"Directives"},{"location":"explanations/directives/#directives","text":"Directives are special comments that are preceded by #| that control: Cell visibility in rendered documentation How source code is generated from notebook cells Execution of cells for tests and docs nbdev augments Quarto by providing additional directives than what are available in Quarto. All Quarto directives can be used in nbdev notebooks. This cheat sheet lists all nbdev directives in addition to some Quarto directives we believe are important. We recommend consulting the quarto docs to see all of the directives available to you. To clarify the origin of directives we use the following emojis: \ud83d\udcd3 for nbdev-only directives . \ud83d\udd35 for Quarto directives (which also work in nbdev).","title":"Directives"},{"location":"explanations/directives/#cell-visibility","text":"The following directives control cell visibility in rendered documentation:","title":"Cell Visibility"},{"location":"explanations/directives/#hide","text":"Hide cell input and output. > **Example** > > The following will result in the contents of the cell and it\u2019s output > from being hidden: > > #|hide print ( 'you will not see this' ) > > Note that using `#|hide` is equivalent to using the Quarto directive > `#|include: false`: > > #|include: false print ( 'you will not see this' ) > > See the quarto docs for more information about `#|include`.","title":"\ud83d\udcd3 #|hide"},{"location":"explanations/directives/#echo-truefalse","text":"Toggle the visibility of code-cell inputs. > **Example** > > #|echo: false print ( 'you can see the output but not the code!' ) > > which results in: > > you can see the output but not the code!","title":"\ud83d\udd35 #|echo: &lt;true|false&gt;"},{"location":"explanations/directives/#output-truefalseasis","text":"Setting this to false hides the output of a cell. Setting this to asis renders the output as raw markdown. > **Example** > > The following cell will not display any output: > > #|output: false 1 + 1 > > The following cell with `#|output: asis` will produce the output > `hello fastai` rendered as markdown instead of a string: > > #|output: asis print ( \"`hello fastai`\" )","title":"\ud83d\udd35 #|output: &lt;true|false|asis&gt;"},{"location":"explanations/directives/#hide_line","text":"Hide a specific line of code in an input cell. > **Example** > > def _secret (): ... for i in range ( 3 ): _secret () #|hide_line print ( i ) > > becomes this: > > def _secret (): ... for i in range ( 3 ): print ( i ) > > 0 > 1 > 2","title":"\ud83d\udcd3 #|hide_line"},{"location":"explanations/directives/#filter_stream-keyword","text":"Filter lines containing specific keywords in cell outputs. > **Example** > > #|filter_stream FutureWarning MultiIndex print ( ' \\n ' . join ([ 'A line' , 'Foobar baz FutureWarning blah' , 'zig zagMultiIndex zoom' , 'Another line.' ])) > > will output this: > > A line > Another line.","title":"\ud83d\udcd3 #|filter_stream &lt;keyword&gt; ..."},{"location":"explanations/directives/#code-fold-showtrue","text":"The #|code-fold directive allows you to collapse code cells. When set to true , the element is collapsed by default, when set to show show the element is shown by default. > **Example** > > When you set `#|code-fold: true`, the input cell is collapsed: > > > Code > > print ( 'this is' ) print ( 'output' ) print ( 'that takes' ) print ( 'lots of vertical space' ) > > > > this is > output > that takes > lots of vertical space > > When you set `#|code-fold: show` the input cell is shown but still in > a collapsible element: > > > Code > > print ( 'this is' ) print ( 'output' ) print ( 'that takes' ) print ( 'lots of vertical space' ) > > > > this is > output > that takes > lots of vertical space","title":"\ud83d\udd35 #|code-fold: &lt;show|true&gt;"},{"location":"explanations/directives/#generating-source-code","text":"The following directives control how source code is exported from code cells.","title":"Generating Source Code"},{"location":"explanations/directives/#default_exp-name","text":"Names the module where cells with the #|export directive will be exported to by default. > **Example** > > #| default_exp baz # In a new notebook cell: #| export def my_function (): pass > > If our package is named: `bitsnbytes` then we can do: > > from bitsnbytes.baz import my_function > > You can define the package name by using `lib_name` in `settings.ini`.","title":"\ud83d\udcd3 #|default_exp &lt;name&gt;"},{"location":"explanations/directives/#export","text":"Exports the items in the cell into the generated module and documentation. > **Example** > > #|export def say_hello ( to : str # name of person to say hello to ): \"Say hello to somebody\" return f 'Hello { to } !' > > The above cell will get exported to the module specified by > `#|default_exp`. These exports are automatically included in > [`__all__`](https://docs.python.org/3/tutorial/modules.html#importing-from-a-package) > for the module. To learn how export without inclusion in `__all__`, > see the `#|exporti` directive. > > Furthermore, the documentation for this function will automatically be > rendered like this: > > ------------------------------------------------------------------------ > > ### say_hello > > > say_hello (to:str) > > Say hello to somebody > > | | **Type** | **Details** | > |-----|----------|--------------------------------| > | to | str | name of person to say hello to | > > The docs are generated from this export using > [`show_doc`](https://nbdev.fast.ai/api/showdoc.html#show_doc). See > [these docs](docs.ipynb#how-show_doc-works) for a detailed discussion > of [`show_doc`](https://nbdev.fast.ai/api/showdoc.html#show_doc).","title":"\ud83d\udcd3 #|export"},{"location":"explanations/directives/#export-something","text":"Similar to #|export , but instead of exporting to the module named by #|default_exp export to the specified module. > **Example** > > If our package is named: `bitsnbytes`, and we have previously > included: `#|default_exp core` in this notebook, and we have an > existing notebook with `#|default_exp bar`, then: > > Earlier in the notebook: > > #|default_exp core > > A new notebook cell: > > #|export bar def foo (): pass > > then we can import this as: > > from bitsnbytes.bar import foo","title":"\ud83d\udcd3 #|export &lt;some.thing&gt;"},{"location":"explanations/directives/#exporti","text":"An i nternal export. Not included in __all__ or the docs. Useful for a function that is called by other functions in this module but is not part of the public API. Equivalently, you can prefix your function or method with _ e.g. def _private(): pass .","title":"\ud83d\udcd3 #|exporti"},{"location":"explanations/directives/#exports","text":"A s ource export. Like #|export but in addition to showing docs via showdoc.show_doc , it also shows the source code. > **Example** > > #|exports def say_hello ( to ): \"Say hello to somebody\" return f 'Hello { to } !' > > this will produce the following output: > > def say_hello ( to ): \"Say hello to somebody\" return f 'Hello { to } !' > > ------------------------------------------------------------------------ > > ### say_hello > > > say_hello (to) > > Say hello to somebody","title":"\ud83d\udcd3 #|exports"},{"location":"explanations/directives/#cell-execution","text":"The following directives allow you to control how cells are executed during docs rendering and testing.","title":"Cell Execution"},{"location":"explanations/directives/#exec_doc","text":"Ensures that a cell is executed each time before generating docs. When a cell does not have this annotation, it is run according to the default rules described here . > **Example** > > datetime . datetime . now () > > datetime.datetime(2022, 8, 18, 9, 1, 43, 907609) > > However with the annotation: > > #|exec_doc datetime . datetime . now () > > we can see that the time has been updated: > > datetime . datetime . now () > > datetime.datetime(2022, 12, 21, 6, 0, 0, 283413)","title":"\ud83d\udcd3 #|exec_doc"},{"location":"explanations/directives/#eval-truefalse","text":"When set to false , the cell is ignored during testing. > **Example** > > #|eval: false raise Exception ( \"I'm not raised because I'm not run\" )","title":"\ud83d\udd35 #|eval: &lt;true|false&gt;"},{"location":"explanations/directives/#cell-execution-when-there-is-no-directive","text":"When a cell has no directives, cells are run by nbdev according to the behavior described here .","title":"Cell execution when there is no directive"},{"location":"explanations/docs/","text":"Docs Website \u00a4 Concepts \u00a4 Source Files \u00a4 There are two mediums in which you can author documentation in nbdev: Jupyter Notebooks Quarto Markdown (.qmd) For most cases, you will use Jupyter Notebooks. However, you may choose to author a document in Quarto Markdown if there is no code on that particular page. When in doubt, we recommend using notebooks as they are more versatile. In the case of notebooks, nbdev pre-processes them to add, remove or change the content before passing it to Quarto. In some cases, nbdev even executes certain cells in order to render the documentation properly. The mechanics of this are discussed in the Notebook Processor section below. For markdown files, Quarto renders these directly. Notebook Processor \u00a4 Nbdev does special pre-processing on notebooks based on the following: Directives : Directives are special comments that allow you to perform operations on cells. For example, the comment #|hide allows you to hide cell inputs and outputs. You can read more about directives on this page . Directives that are unique to nbdev and not supported by Quarto are removed from the notebook before being passed to Quarto. Front Matter : Front matter allows you to specify document-level options so you don\u2019t have to repeat them on each cell. (Similarly, _quarto.yml allows you to specify project-level options.) You can read more about Quarto front-matter here . The directives and front-matter are used by a Processing Pipeline to transform notebooks. Many of these pre-processing steps are defined in nbdev.processors , which are then run by nbdev.process.NBProcessor . Some of these pre-processing steps involve running code (with execnb ) in order to dynamically render API documentation. This process is explained in the How show_doc works section below. When generating your docs site, the intermediate output of these pre-processed notebooks and other quarto project files are saved into a directory named _proc/ at the root of your repo. You can inspect the _proc/ directory in order to debug or understand how notebooks are pre-processed. Quarto \u00a4 Quarto is the mechanism nbdev uses to generate web pages from notebooks. It is useful to visit the Quarto docs and understand how it works. nbdev automatically generates the Quarto configuration files _quarto.yml and sidebar.yml for you. You can override any settings in _quarto.yml by defining a custom.yml file. This is explained further in the Customizing Quarto section. We explain how to customize your sidebar in the Customizing The Sidebar section. Static Site \u00a4 Quarto has a built-in static site generator that will generate HTML, Javascript and CSS files. These files will be placed in the doc_path directory as specified in your project\u2019s settings.ini file, which is _docs/ by default. Overview \u00a4 Below is a diagram on how these concepts fit together. Customizing Quarto \u00a4 You can create a custom.yml file in the same location as your _quarto.yml file to override any values in _quarto.yml . For example, assume your _quarto.yml file looks contains this: website : title : \"nbdev\" site-url : \"https://nbdev.fast.ai/\" description : \"Create delightful software with Jupyter Notebooks\" twitter-card : true open-graph : true repo-branch : master repo-url : \"https://github.com/fastai/nbdev\" repo-actions : [ issue ] navbar : background : primary search : true right : - icon : github href : \"https://github.com/fastai/nbdev\" sidebar : style : \"floating\" Let\u2019s assume you want to customize your sidebar navigation options such that instead of \u201cfloating\u201d for sidebar.style , you wanted your navbar to be \u201cdocked\u201d. Additionally, lets assume you want a different background color using the sidebar.background field which is not in the configuration above. To accomplish these tasks, you would create a custom.yml in the same location as _quarto.yml with these contents: website : sidebar : style : \"docked\" background : \"dark\" > **Note** > > You can also set `custom_quarto_yml = True` in settings.ini if you > wish to edit `_quarto.yml` directly instead of overriding settings in > `custom.yml`. Customizing The Sidebar \u00a4 By default nbdev automatically generates sidebar.yml , which specifies the tree structure of your sidebar. nbdev infers the tree structure by inspecting the directory structure containing your source files. You can see an example of this by inspecting the folder structure of the notebooks directory in nbdev and the corresponding left-hand sidebar on this website. Leading numbers in filenames and directories are ignored when naming elements of the sidebar (which you can see examples of in this project\u2019s notebooks directory). To customize the sidebar, you must set custom_sidebar = true in settings.ini . This will prevent nbdev from regenerating this file every time the docs are re-built. This way, you an edit this file directly instead of overriding the sidebar with custom.yml . How show_doc works \u00a4 When your documention website is built, all functions and classes you export to source code will be automatically documented with show_doc . This function outputs a summary of the symbol, showing its signature, docstring, and parameters. For instance, if you have this function: def say_gday ( greeting : str = \"G'day\" , # Greeting to use strine : bool = True , # Use incomprehensible Aussie accent? dropbears : bool = False ): # Also warn about drop-bears? \"Says g'day, the classic Aussie greeting\" ... This is how it\u2019s rendered in the documentation, by automatically generating a temporary cell containing: show_doc ( say_gday ) ------------------------------------------------------------------------ ### say_gday > say_gday (greeting:str=\"G'day\", strine:bool=True, dropbears:bool=False) Says g\u2019day, the classic Aussie greeting | | **Type** | **Default** | **Details** | |-----------|----------|-------------|-------------------------------------| | greeting | str | G\u2019day | Greeting to use | | strine | bool | True | Use incomprehensible Aussie accent? | | dropbears | bool | False | Also warn about drop-bears? | Because this is done automatically any time you build your docs (including automatically by continuous integration), your documentation will always contain current information about your code. You can also document code that\u2019s not created in a notebook, by using show_doc with imported code. For instance, if we wanted to document release_conda , we can import it and call show_doc(release_conda) : from nbdev.release import release_conda show_doc ( release_conda ) ------------------------------------------------------------------------ source ### release_conda > release_conda (path:str='conda', do_build: =True, > build_args:str='', skip_upload: store_true>=False, mambabuild: =False, > upload_user:str=None) Create a `meta.yaml` file ready to be built into a package, and optionally build and upload it | | **Type** | **Default** | **Details** | |-------------|------------|-------------|---------------------------------------------------| | path | str | conda | Path where package will be created | | do_build | bool_arg | True | Run `conda build` step | | build_args | str | | Additional args (as str) to send to `conda build` | | skip_upload | store_true | False | Skip `anaconda upload` step | | mambabuild | store_true | False | Use `mambabuild` (requires `boa`) | | upload_user | str | None | Optional user to upload package to | Automatic Cell Execution \u00a4 When your documentation is built, all your manually added show_doc cells are run automatically. nbdev also executes all cells containing an import statement, and all exported cells \u2013 that way we can be sure that the symbol used in your show_doc cell is available. We don\u2019t, however, execute any other cells. That\u2019s because you wouldn\u2019t want to wait for your entire notebook to run just to build your docs; for instance, your docs might demonstrate training a model which takes hours to complete! This leads to an important rule when authoring nbdev notebooks: > **Warning** > > Do not mix `import` statements (or calls to > [`show_doc`](https://nbdev.fast.ai/api/showdoc.html#show_doc)) with > other code in a single cell. If you do, *all* the code in that cell > will be executed every time you build your docs, which might lead to > errors (since not all previous cells will have been executed. > > Instead, put your imports in separate cells, and calls to > [`show_doc`](https://nbdev.fast.ai/api/showdoc.html#show_doc) should > contain only that one line of code \u2013 the > [`show_doc`](https://nbdev.fast.ai/api/showdoc.html#show_doc) call. Note that nbdev automatically hides the actual show_doc(...) line of code. So your users only see the output. Forcing Cells To Execute \u00a4 Sometimes you may want to execute additional cells beyond what is automatically executed by nbdev. For instance, on our Getting Started page we show a list of all nbdev commands, automatically generated with nbdev_help . We want this page to always have the most up to date list of commands and docs, so we want it to always execute when the docs are rendered. To do that, add the following directive to the top of a cell: #| exec_doc Alternatively, you can get nbdev to automatically execute all cells when rendering your docs, by adding the following to your notebook frontmatter: --- exec_all: true --- Skipping Execution \u00a4 Likewise, you can instruct nbdev to not execute any cells when rendering your docs with the following front matter: --- skip_showdoc: true --- Or ignore execution for a specific cell with this directive: #|eval: false Why use show_doc ? \u00a4 Many Python developers use sphinx autodoc to automatically document a whole module all at once. Whilst this can work reasonably well, we think there are huge benefits for both developers and users in using nbdev\u2019s approach instead The premise of nbdev\u2019s approach is that your documentation is important enough to be worth you taking the time to think carefully though each thing you want to show your users, what examples you\u2019re going to provide, maybe adding some images to explain more complex ideas, and so forth. Jupyter provides a terrific environment for creating just these kinds of documents. For instance, with Jupyter you can: Paste images directly from your clipboard into a cell Insert code and have it executed and the results displayed to users Create a hierarchy of headings to help structure your page \u2026and much more. With show_doc , you can insert automatically-updated API details for your library anywhere in a page. That means that you get to decide exactly how your page should look, and what information is provided where. You don\u2019t have to limit yourself to the limits of ASCII art for diagrams, and can include full end-to-end code walk-through of the processes your users will be following. Previewing Your Site Locally \u00a4 You can preview your docs anytime by running nbdev_preview . While in preview mode, you can make updates to notebooks and it will be reflected (after a small delay) in your browser. Deploying Docs With GitHub Actions \u00a4 If your nbdev project lives in GitHub, we include automation that deploys your documentation site for you on GitHub Pages . nbdev comes bundled with a workflow file that enables this automation. This workflow is automatically triggered whenever you change any of the content in your repo. The following GitHub Actions workflows will run to generate a docs site (in this order): Deploy to GitHub Pages : This workflow builds the docs with nbdev. This is defined in deploy.yaml and references fastai/workflows/quarto-ghp . pages build and deployment : This is an internal built-in workflow that GitHub provides whenever GitHub pages are enabled. Should anything go wrong in your page build, you can always look at the logs of these workflows. Like other workflows, these can be found in the Actions tab of your repo: To read more about GitHub Actions, see their docs . Deploying Your Docs On Other Platforms \u00a4 You can generate all of the static assets for your site (html, css, etc) by running the command nbdev_docs . After running this command, all of the files for your documentation site will be located in the _docs/ directory (the location is configurable by doc_path in settings.ini ) at the root of your repository. This directory is not checked into git and is ignored by .gitignore , but you can use these files to deploy to any hosting platform you want. You can also use the quarto publish command to render your docs on a wide variety of other platforms, which is discussed in the Quarto docs here . After running the command nbdev_docs , the quarto publish command must be run from the root of the _proc/ directory , which is located at the root of your repo. The built-in help of quarto publish provides a good overview of the various targets available: > **Call > [`nbdev_proc_nbs`](https://nbdev.fast.ai/api/quarto.html#nbdev_proc_nbs) > and publish from the `_proc/` directory** > > To use `quarto publish` with nbdev, you must run the > [`nbdev_proc_nbs`](https://nbdev.fast.ai/api/quarto.html#nbdev_proc_nbs) > command to pre-process your notebooks before publishing your docs. As > a reminder, > [`nbdev_proc_nbs`](https://nbdev.fast.ai/api/quarto.html#nbdev_proc_nbs) > creates the directory `_proc/` at the root of your project that Quarto > uses to render your site. > > For example, to publish a site to Netlify you can run the following > command from the root of your repo: > > nbdev_proc_nbs && cd _proc && quarto publish netlify ! quarto publish - h Usage: quarto publish [provider] [path] Version: 1.1.75 Description: Publish a document or project. Available providers include: - Quarto Pub (quarto-pub) - GitHub Pages (gh-pages) - RStudio Connect (connect) - Netlify (netlify) Accounts are configured interactively during publishing. Manage/remove accounts with: quarto publish accounts Options: -h, --help - Show this help. --id <id> - Identifier of content to publish --server <server> - Server to publish to --token <token> - Access token for publising provider --no-render - Do not render before publishing. --no-prompt - Do not prompt to confirm publishing destination --no-browser - Do not open a browser to the site after publishing --log <level> - Path to log file --log-level <level> - Log level (info, warning, error, critical) --log-format <format> - Log format (plain, json-stream) --quiet - Suppress console output. Commands: help [command] - Show this help or the help of a sub-command. Examples: Publish project (prompt for provider): quarto publish Publish document (prompt for provider): quarto publish document.qmd Publish project to Netlify: quarto publish netlify Publish with explicit target: quarto publish netlify --id DA36416-F950-4647-815C-01A24233E294 Publish project to GitHub Pages: quarto publish gh-pages Publish project to RStudio Connect: quarto publish connect Publish with explicit credentials: quarto publish connect --server example.com --token 01A24233E294 Publish without confirmation prompt: quarto publish --no-prompt Publish without rendering: quarto publish --no-render Publish without opening browser: quarto publish --no-browser Manage/remove publishing accounts: quarto publish accounts","title":"Docs Website"},{"location":"explanations/docs/#docs-website","text":"","title":"Docs Website"},{"location":"explanations/docs/#concepts","text":"","title":"Concepts"},{"location":"explanations/docs/#source-files","text":"There are two mediums in which you can author documentation in nbdev: Jupyter Notebooks Quarto Markdown (.qmd) For most cases, you will use Jupyter Notebooks. However, you may choose to author a document in Quarto Markdown if there is no code on that particular page. When in doubt, we recommend using notebooks as they are more versatile. In the case of notebooks, nbdev pre-processes them to add, remove or change the content before passing it to Quarto. In some cases, nbdev even executes certain cells in order to render the documentation properly. The mechanics of this are discussed in the Notebook Processor section below. For markdown files, Quarto renders these directly.","title":"Source Files"},{"location":"explanations/docs/#notebook-processor","text":"Nbdev does special pre-processing on notebooks based on the following: Directives : Directives are special comments that allow you to perform operations on cells. For example, the comment #|hide allows you to hide cell inputs and outputs. You can read more about directives on this page . Directives that are unique to nbdev and not supported by Quarto are removed from the notebook before being passed to Quarto. Front Matter : Front matter allows you to specify document-level options so you don\u2019t have to repeat them on each cell. (Similarly, _quarto.yml allows you to specify project-level options.) You can read more about Quarto front-matter here . The directives and front-matter are used by a Processing Pipeline to transform notebooks. Many of these pre-processing steps are defined in nbdev.processors , which are then run by nbdev.process.NBProcessor . Some of these pre-processing steps involve running code (with execnb ) in order to dynamically render API documentation. This process is explained in the How show_doc works section below. When generating your docs site, the intermediate output of these pre-processed notebooks and other quarto project files are saved into a directory named _proc/ at the root of your repo. You can inspect the _proc/ directory in order to debug or understand how notebooks are pre-processed.","title":"Notebook Processor"},{"location":"explanations/docs/#quarto","text":"Quarto is the mechanism nbdev uses to generate web pages from notebooks. It is useful to visit the Quarto docs and understand how it works. nbdev automatically generates the Quarto configuration files _quarto.yml and sidebar.yml for you. You can override any settings in _quarto.yml by defining a custom.yml file. This is explained further in the Customizing Quarto section. We explain how to customize your sidebar in the Customizing The Sidebar section.","title":"Quarto"},{"location":"explanations/docs/#static-site","text":"Quarto has a built-in static site generator that will generate HTML, Javascript and CSS files. These files will be placed in the doc_path directory as specified in your project\u2019s settings.ini file, which is _docs/ by default.","title":"Static Site"},{"location":"explanations/docs/#overview","text":"Below is a diagram on how these concepts fit together.","title":"Overview"},{"location":"explanations/docs/#customizing-quarto","text":"You can create a custom.yml file in the same location as your _quarto.yml file to override any values in _quarto.yml . For example, assume your _quarto.yml file looks contains this: website : title : \"nbdev\" site-url : \"https://nbdev.fast.ai/\" description : \"Create delightful software with Jupyter Notebooks\" twitter-card : true open-graph : true repo-branch : master repo-url : \"https://github.com/fastai/nbdev\" repo-actions : [ issue ] navbar : background : primary search : true right : - icon : github href : \"https://github.com/fastai/nbdev\" sidebar : style : \"floating\" Let\u2019s assume you want to customize your sidebar navigation options such that instead of \u201cfloating\u201d for sidebar.style , you wanted your navbar to be \u201cdocked\u201d. Additionally, lets assume you want a different background color using the sidebar.background field which is not in the configuration above. To accomplish these tasks, you would create a custom.yml in the same location as _quarto.yml with these contents: website : sidebar : style : \"docked\" background : \"dark\" > **Note** > > You can also set `custom_quarto_yml = True` in settings.ini if you > wish to edit `_quarto.yml` directly instead of overriding settings in > `custom.yml`.","title":"Customizing Quarto"},{"location":"explanations/docs/#customizing-the-sidebar","text":"By default nbdev automatically generates sidebar.yml , which specifies the tree structure of your sidebar. nbdev infers the tree structure by inspecting the directory structure containing your source files. You can see an example of this by inspecting the folder structure of the notebooks directory in nbdev and the corresponding left-hand sidebar on this website. Leading numbers in filenames and directories are ignored when naming elements of the sidebar (which you can see examples of in this project\u2019s notebooks directory). To customize the sidebar, you must set custom_sidebar = true in settings.ini . This will prevent nbdev from regenerating this file every time the docs are re-built. This way, you an edit this file directly instead of overriding the sidebar with custom.yml .","title":"Customizing The Sidebar"},{"location":"explanations/docs/#how-show_doc-works","text":"When your documention website is built, all functions and classes you export to source code will be automatically documented with show_doc . This function outputs a summary of the symbol, showing its signature, docstring, and parameters. For instance, if you have this function: def say_gday ( greeting : str = \"G'day\" , # Greeting to use strine : bool = True , # Use incomprehensible Aussie accent? dropbears : bool = False ): # Also warn about drop-bears? \"Says g'day, the classic Aussie greeting\" ... This is how it\u2019s rendered in the documentation, by automatically generating a temporary cell containing: show_doc ( say_gday ) ------------------------------------------------------------------------ ### say_gday > say_gday (greeting:str=\"G'day\", strine:bool=True, dropbears:bool=False) Says g\u2019day, the classic Aussie greeting | | **Type** | **Default** | **Details** | |-----------|----------|-------------|-------------------------------------| | greeting | str | G\u2019day | Greeting to use | | strine | bool | True | Use incomprehensible Aussie accent? | | dropbears | bool | False | Also warn about drop-bears? | Because this is done automatically any time you build your docs (including automatically by continuous integration), your documentation will always contain current information about your code. You can also document code that\u2019s not created in a notebook, by using show_doc with imported code. For instance, if we wanted to document release_conda , we can import it and call show_doc(release_conda) : from nbdev.release import release_conda show_doc ( release_conda ) ------------------------------------------------------------------------ source ### release_conda > release_conda (path:str='conda', do_build: =True, > build_args:str='', skip_upload: store_true>=False, mambabuild: =False, > upload_user:str=None) Create a `meta.yaml` file ready to be built into a package, and optionally build and upload it | | **Type** | **Default** | **Details** | |-------------|------------|-------------|---------------------------------------------------| | path | str | conda | Path where package will be created | | do_build | bool_arg | True | Run `conda build` step | | build_args | str | | Additional args (as str) to send to `conda build` | | skip_upload | store_true | False | Skip `anaconda upload` step | | mambabuild | store_true | False | Use `mambabuild` (requires `boa`) | | upload_user | str | None | Optional user to upload package to |","title":"How show_doc works"},{"location":"explanations/docs/#automatic-cell-execution","text":"When your documentation is built, all your manually added show_doc cells are run automatically. nbdev also executes all cells containing an import statement, and all exported cells \u2013 that way we can be sure that the symbol used in your show_doc cell is available. We don\u2019t, however, execute any other cells. That\u2019s because you wouldn\u2019t want to wait for your entire notebook to run just to build your docs; for instance, your docs might demonstrate training a model which takes hours to complete! This leads to an important rule when authoring nbdev notebooks: > **Warning** > > Do not mix `import` statements (or calls to > [`show_doc`](https://nbdev.fast.ai/api/showdoc.html#show_doc)) with > other code in a single cell. If you do, *all* the code in that cell > will be executed every time you build your docs, which might lead to > errors (since not all previous cells will have been executed. > > Instead, put your imports in separate cells, and calls to > [`show_doc`](https://nbdev.fast.ai/api/showdoc.html#show_doc) should > contain only that one line of code \u2013 the > [`show_doc`](https://nbdev.fast.ai/api/showdoc.html#show_doc) call. Note that nbdev automatically hides the actual show_doc(...) line of code. So your users only see the output.","title":"Automatic Cell Execution"},{"location":"explanations/docs/#forcing-cells-to-execute","text":"Sometimes you may want to execute additional cells beyond what is automatically executed by nbdev. For instance, on our Getting Started page we show a list of all nbdev commands, automatically generated with nbdev_help . We want this page to always have the most up to date list of commands and docs, so we want it to always execute when the docs are rendered. To do that, add the following directive to the top of a cell: #| exec_doc Alternatively, you can get nbdev to automatically execute all cells when rendering your docs, by adding the following to your notebook frontmatter: --- exec_all: true ---","title":"Forcing Cells To Execute"},{"location":"explanations/docs/#skipping-execution","text":"Likewise, you can instruct nbdev to not execute any cells when rendering your docs with the following front matter: --- skip_showdoc: true --- Or ignore execution for a specific cell with this directive: #|eval: false","title":"Skipping Execution"},{"location":"explanations/docs/#why-use-show_doc","text":"Many Python developers use sphinx autodoc to automatically document a whole module all at once. Whilst this can work reasonably well, we think there are huge benefits for both developers and users in using nbdev\u2019s approach instead The premise of nbdev\u2019s approach is that your documentation is important enough to be worth you taking the time to think carefully though each thing you want to show your users, what examples you\u2019re going to provide, maybe adding some images to explain more complex ideas, and so forth. Jupyter provides a terrific environment for creating just these kinds of documents. For instance, with Jupyter you can: Paste images directly from your clipboard into a cell Insert code and have it executed and the results displayed to users Create a hierarchy of headings to help structure your page \u2026and much more. With show_doc , you can insert automatically-updated API details for your library anywhere in a page. That means that you get to decide exactly how your page should look, and what information is provided where. You don\u2019t have to limit yourself to the limits of ASCII art for diagrams, and can include full end-to-end code walk-through of the processes your users will be following.","title":"Why use show_doc?"},{"location":"explanations/docs/#previewing-your-site-locally","text":"You can preview your docs anytime by running nbdev_preview . While in preview mode, you can make updates to notebooks and it will be reflected (after a small delay) in your browser.","title":"Previewing Your Site Locally"},{"location":"explanations/docs/#deploying-docs-with-github-actions","text":"If your nbdev project lives in GitHub, we include automation that deploys your documentation site for you on GitHub Pages . nbdev comes bundled with a workflow file that enables this automation. This workflow is automatically triggered whenever you change any of the content in your repo. The following GitHub Actions workflows will run to generate a docs site (in this order): Deploy to GitHub Pages : This workflow builds the docs with nbdev. This is defined in deploy.yaml and references fastai/workflows/quarto-ghp . pages build and deployment : This is an internal built-in workflow that GitHub provides whenever GitHub pages are enabled. Should anything go wrong in your page build, you can always look at the logs of these workflows. Like other workflows, these can be found in the Actions tab of your repo: To read more about GitHub Actions, see their docs .","title":"Deploying Docs With GitHub Actions"},{"location":"explanations/docs/#deploying-your-docs-on-other-platforms","text":"You can generate all of the static assets for your site (html, css, etc) by running the command nbdev_docs . After running this command, all of the files for your documentation site will be located in the _docs/ directory (the location is configurable by doc_path in settings.ini ) at the root of your repository. This directory is not checked into git and is ignored by .gitignore , but you can use these files to deploy to any hosting platform you want. You can also use the quarto publish command to render your docs on a wide variety of other platforms, which is discussed in the Quarto docs here . After running the command nbdev_docs , the quarto publish command must be run from the root of the _proc/ directory , which is located at the root of your repo. The built-in help of quarto publish provides a good overview of the various targets available: > **Call > [`nbdev_proc_nbs`](https://nbdev.fast.ai/api/quarto.html#nbdev_proc_nbs) > and publish from the `_proc/` directory** > > To use `quarto publish` with nbdev, you must run the > [`nbdev_proc_nbs`](https://nbdev.fast.ai/api/quarto.html#nbdev_proc_nbs) > command to pre-process your notebooks before publishing your docs. As > a reminder, > [`nbdev_proc_nbs`](https://nbdev.fast.ai/api/quarto.html#nbdev_proc_nbs) > creates the directory `_proc/` at the root of your project that Quarto > uses to render your site. > > For example, to publish a site to Netlify you can run the following > command from the root of your repo: > > nbdev_proc_nbs && cd _proc && quarto publish netlify ! quarto publish - h Usage: quarto publish [provider] [path] Version: 1.1.75 Description: Publish a document or project. Available providers include: - Quarto Pub (quarto-pub) - GitHub Pages (gh-pages) - RStudio Connect (connect) - Netlify (netlify) Accounts are configured interactively during publishing. Manage/remove accounts with: quarto publish accounts Options: -h, --help - Show this help. --id <id> - Identifier of content to publish --server <server> - Server to publish to --token <token> - Access token for publising provider --no-render - Do not render before publishing. --no-prompt - Do not prompt to confirm publishing destination --no-browser - Do not open a browser to the site after publishing --log <level> - Path to log file --log-level <level> - Log level (info, warning, error, critical) --log-format <format> - Log format (plain, json-stream) --quiet - Suppress console output. Commands: help [command] - Show this help or the help of a sub-command. Examples: Publish project (prompt for provider): quarto publish Publish document (prompt for provider): quarto publish document.qmd Publish project to Netlify: quarto publish netlify Publish with explicit target: quarto publish netlify --id DA36416-F950-4647-815C-01A24233E294 Publish project to GitHub Pages: quarto publish gh-pages Publish project to RStudio Connect: quarto publish connect Publish with explicit credentials: quarto publish connect --server example.com --token 01A24233E294 Publish without confirmation prompt: quarto publish --no-prompt Publish without rendering: quarto publish --no-render Publish without opening browser: quarto publish --no-browser Manage/remove publishing accounts: quarto publish accounts","title":"Deploying Your Docs On Other Platforms"},{"location":"explanations/why_nbdev/","text":"Why nbdev \u00a4 Popular Python documentation standards such as numpy docstrings and sphinx facilitate documentation of source code with docstrings, which are limited in their expressiveness and functionality. Notebooks, on the other hand, offer a richer medium for authoring documentation (with markdown and code cells) compared to docstrings, and unlock new ways of documenting your code that are otherwhise infeasible. Furthermore, traditional testing frameworks such as pytest and unittest encourage writing tests in a separate context that is disjointed from the associated source code and documentation. With nbdev, you write tests in the same context as your source code and documentation, such that tests can optionally become part of the narrative within your documentation. Since nbdev allows your colleagues and users to view the tests, code and documentation in a single context with a REPL that invites experimentation, the way you author code, documentation and tests in nbdev are very different than traditional software development workflows. In Notebook Best Practices we compare a function coded, tested, and documented in nbdev versus ordinary .py files. Here are a few of the challenges we faced with other approaches that led us to using nbdev. In .py files: Docstrings repeat information that is already contained in the function signature, such as names of parameters, default values, and types Examples are manually entered. This requires the author to copy and paste both the code and outputs. Furthermore, the author must manually re-enter or change these examples anytime the code changes, which is an error-prone process Examples are limited to short code snippets and cannot contain rich output like plots or graphics Examples cannot have prose interleaved with code except for code comments Readers of your code must copy and paste contents of the docstring if they wish to reproduce the examples.","title":"Why nbdev"},{"location":"explanations/why_nbdev/#why-nbdev","text":"Popular Python documentation standards such as numpy docstrings and sphinx facilitate documentation of source code with docstrings, which are limited in their expressiveness and functionality. Notebooks, on the other hand, offer a richer medium for authoring documentation (with markdown and code cells) compared to docstrings, and unlock new ways of documenting your code that are otherwhise infeasible. Furthermore, traditional testing frameworks such as pytest and unittest encourage writing tests in a separate context that is disjointed from the associated source code and documentation. With nbdev, you write tests in the same context as your source code and documentation, such that tests can optionally become part of the narrative within your documentation. Since nbdev allows your colleagues and users to view the tests, code and documentation in a single context with a REPL that invites experimentation, the way you author code, documentation and tests in nbdev are very different than traditional software development workflows. In Notebook Best Practices we compare a function coded, tested, and documented in nbdev versus ordinary .py files. Here are a few of the challenges we faced with other approaches that led us to using nbdev. In .py files: Docstrings repeat information that is already contained in the function signature, such as names of parameters, default values, and types Examples are manually entered. This requires the author to copy and paste both the code and outputs. Furthermore, the author must manually re-enter or change these examples anytime the code changes, which is an error-prone process Examples are limited to short code snippets and cannot contain rich output like plots or graphics Examples cannot have prose interleaved with code except for code comments Readers of your code must copy and paste contents of the docstring if they wish to reproduce the examples.","title":"Why nbdev"},{"location":"nbdev_api/nbdev/clean/","text":"clean_jupyter ( path , model , ** kwargs ) \u00a4 Clean Jupyter model pre save to path Source code in nbdev/clean.py def clean_jupyter ( path , model , ** kwargs ): \"Clean Jupyter `model` pre save to `path`\" if not ( model [ 'type' ] == 'notebook' and model [ 'content' ][ 'nbformat' ] == 4 ): return get_config . cache_clear () # Allow config changes without restarting Jupyter jupyter_hooks = get_config ( path = path ) . jupyter_hooks if jupyter_hooks : _nbdev_clean ( model [ 'content' ], path = path ) clean_nb ( nb , clear_all = False , allowed_metadata_keys = None , allowed_cell_metadata_keys = None , clean_ids = True ) \u00a4 Clean nb from superfluous metadata Source code in nbdev/clean.py def clean_nb ( nb , # The notebook to clean clear_all = False , # Remove all cell metadata and cell outputs? allowed_metadata_keys : list = None , # Preserve the list of keys in the main notebook metadata allowed_cell_metadata_keys : list = None , # Preserve the list of keys in cell level metadata clean_ids = True , # Remove ids from plaintext reprs? ): \"Clean `nb` from superfluous metadata\" metadata_keys = { \"kernelspec\" , \"jekyll\" , \"jupytext\" , \"doc\" , \"widgets\" } if allowed_metadata_keys : metadata_keys . update ( allowed_metadata_keys ) cell_metadata_keys = { \"hide_input\" } if allowed_cell_metadata_keys : cell_metadata_keys . update ( allowed_cell_metadata_keys ) for c in nb [ 'cells' ]: _clean_cell ( c , clear_all , cell_metadata_keys , clean_ids ) if nested_attr ( nb , 'metadata.kernelspec.name' ): nb [ 'metadata' ][ 'kernelspec' ][ 'display_name' ] = nb . metadata . kernelspec . name nb [ 'metadata' ] = { k : v for k , v in nb [ 'metadata' ] . items () if k in metadata_keys } nbdev_clean ( fname = None , clear_all = False , disp = False , stdin = False ) \u00a4 Clean all notebooks in fname to avoid merge conflicts Source code in nbdev/clean.py @call_parse def nbdev_clean ( fname : str = None , # A notebook name or glob to clean clear_all : bool = False , # Remove all cell metadata and cell outputs? disp : bool = False , # Print the cleaned outputs stdin : bool = False # Read notebook from input stream ): \"Clean all notebooks in `fname` to avoid merge conflicts\" # Git hooks will pass the notebooks in stdin _clean = partial ( _nbdev_clean , clear_all = clear_all ) _write = partial ( process_write , warn_msg = 'Failed to clean notebook' , proc_nb = _clean ) if stdin : return _write ( f_in = sys . stdin , f_out = sys . stdout ) if fname is None : fname = get_config () . nbs_path for f in globtastic ( fname , file_glob = '*.ipynb' , skip_folder_re = '^[_.]' ): _write ( f_in = f , disp = disp ) nbdev_install_hooks () \u00a4 Install Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks Source code in nbdev/clean.py @call_parse def nbdev_install_hooks (): \"Install Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks\" cfg_path = Path . home () / '.jupyter' cfg_path . mkdir ( exist_ok = True ) cfg_fns = [ cfg_path / f 'jupyter_ { o } _config.py' for o in ( 'notebook' , 'server' )] for fn in cfg_fns : src = fn . read_text () if fn . exists () else '' upd = _add_jupyter_hooks ( src , fn ) if upd is not None : fn . write_text ( upd ) repo_path = _git_root () if repo_path is None : sys . stderr . write ( 'Not in a git repository, git hooks cannot be installed. \\n ' ) return hook_path = repo_path / '.git' / 'hooks' fn = hook_path / 'post-merge' hook_path . mkdir ( parents = True , exist_ok = True ) fn . write_text ( \"#!/bin/bash \\n nbdev_trust\" ) os . chmod ( fn , os . stat ( fn ) . st_mode | stat . S_IEXEC ) cmd = 'git config --local include.path ../.gitconfig' ( repo_path / '.gitconfig' ) . write_text ( f '''# Generated by nbdev_install_hooks # # If you need to disable this instrumentation do: # git config --local --unset include.path # # To restore: # { cmd } # [merge \"nbdev-merge\"] name = resolve conflicts with nbdev_fix driver = nbdev_merge %O %A %B %P ''' ) run ( cmd ) attrs_path = repo_path / '.gitattributes' nbdev_attr = '*.ipynb merge=nbdev-merge \\n ' try : attrs = attrs_path . read_text () if nbdev_attr not in attrs : if not attrs . endswith ( ' \\n ' ): attrs += ' \\n ' attrs_path . write_text ( attrs + nbdev_attr ) except FileNotFoundError : attrs_path . write_text ( nbdev_attr ) print ( \"Hooks are installed.\" ) nbdev_trust ( fname = None , force_all = False ) \u00a4 Trust notebooks matching fname Source code in nbdev/clean.py @call_parse def nbdev_trust ( fname : str = None , # A notebook name or glob to trust force_all : bool = False # Also trust notebooks that haven't changed ): \"Trust notebooks matching `fname`\" try : from nbformat.sign import NotebookNotary except : import warnings warnings . warn ( \"Please install jupyter and try again\" ) return fname = Path ( fname if fname else get_config () . nbs_path ) path = fname if fname . is_dir () else fname . parent check_fname = path / \".last_checked\" last_checked = os . path . getmtime ( check_fname ) if check_fname . exists () else None nbs = globtastic ( fname , file_glob = '*.ipynb' , skip_folder_re = '^[_.]' ) if fname . is_dir () else [ fname ] for fn in nbs : if last_checked and not force_all : last_changed = os . path . getmtime ( fn ) if last_changed < last_checked : continue nb = read_nb ( fn ) if not NotebookNotary () . check_signature ( nb ): NotebookNotary () . sign ( nb ) check_fname . touch ( exist_ok = True )","title":"nbdev.clean"},{"location":"nbdev_api/nbdev/clean/#nbdev.clean.clean_jupyter","text":"Clean Jupyter model pre save to path Source code in nbdev/clean.py def clean_jupyter ( path , model , ** kwargs ): \"Clean Jupyter `model` pre save to `path`\" if not ( model [ 'type' ] == 'notebook' and model [ 'content' ][ 'nbformat' ] == 4 ): return get_config . cache_clear () # Allow config changes without restarting Jupyter jupyter_hooks = get_config ( path = path ) . jupyter_hooks if jupyter_hooks : _nbdev_clean ( model [ 'content' ], path = path )","title":"clean_jupyter()"},{"location":"nbdev_api/nbdev/clean/#nbdev.clean.clean_nb","text":"Clean nb from superfluous metadata Source code in nbdev/clean.py def clean_nb ( nb , # The notebook to clean clear_all = False , # Remove all cell metadata and cell outputs? allowed_metadata_keys : list = None , # Preserve the list of keys in the main notebook metadata allowed_cell_metadata_keys : list = None , # Preserve the list of keys in cell level metadata clean_ids = True , # Remove ids from plaintext reprs? ): \"Clean `nb` from superfluous metadata\" metadata_keys = { \"kernelspec\" , \"jekyll\" , \"jupytext\" , \"doc\" , \"widgets\" } if allowed_metadata_keys : metadata_keys . update ( allowed_metadata_keys ) cell_metadata_keys = { \"hide_input\" } if allowed_cell_metadata_keys : cell_metadata_keys . update ( allowed_cell_metadata_keys ) for c in nb [ 'cells' ]: _clean_cell ( c , clear_all , cell_metadata_keys , clean_ids ) if nested_attr ( nb , 'metadata.kernelspec.name' ): nb [ 'metadata' ][ 'kernelspec' ][ 'display_name' ] = nb . metadata . kernelspec . name nb [ 'metadata' ] = { k : v for k , v in nb [ 'metadata' ] . items () if k in metadata_keys }","title":"clean_nb()"},{"location":"nbdev_api/nbdev/clean/#nbdev.clean.nbdev_clean","text":"Clean all notebooks in fname to avoid merge conflicts Source code in nbdev/clean.py @call_parse def nbdev_clean ( fname : str = None , # A notebook name or glob to clean clear_all : bool = False , # Remove all cell metadata and cell outputs? disp : bool = False , # Print the cleaned outputs stdin : bool = False # Read notebook from input stream ): \"Clean all notebooks in `fname` to avoid merge conflicts\" # Git hooks will pass the notebooks in stdin _clean = partial ( _nbdev_clean , clear_all = clear_all ) _write = partial ( process_write , warn_msg = 'Failed to clean notebook' , proc_nb = _clean ) if stdin : return _write ( f_in = sys . stdin , f_out = sys . stdout ) if fname is None : fname = get_config () . nbs_path for f in globtastic ( fname , file_glob = '*.ipynb' , skip_folder_re = '^[_.]' ): _write ( f_in = f , disp = disp )","title":"nbdev_clean()"},{"location":"nbdev_api/nbdev/clean/#nbdev.clean.nbdev_install_hooks","text":"Install Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks Source code in nbdev/clean.py @call_parse def nbdev_install_hooks (): \"Install Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks\" cfg_path = Path . home () / '.jupyter' cfg_path . mkdir ( exist_ok = True ) cfg_fns = [ cfg_path / f 'jupyter_ { o } _config.py' for o in ( 'notebook' , 'server' )] for fn in cfg_fns : src = fn . read_text () if fn . exists () else '' upd = _add_jupyter_hooks ( src , fn ) if upd is not None : fn . write_text ( upd ) repo_path = _git_root () if repo_path is None : sys . stderr . write ( 'Not in a git repository, git hooks cannot be installed. \\n ' ) return hook_path = repo_path / '.git' / 'hooks' fn = hook_path / 'post-merge' hook_path . mkdir ( parents = True , exist_ok = True ) fn . write_text ( \"#!/bin/bash \\n nbdev_trust\" ) os . chmod ( fn , os . stat ( fn ) . st_mode | stat . S_IEXEC ) cmd = 'git config --local include.path ../.gitconfig' ( repo_path / '.gitconfig' ) . write_text ( f '''# Generated by nbdev_install_hooks # # If you need to disable this instrumentation do: # git config --local --unset include.path # # To restore: # { cmd } # [merge \"nbdev-merge\"] name = resolve conflicts with nbdev_fix driver = nbdev_merge %O %A %B %P ''' ) run ( cmd ) attrs_path = repo_path / '.gitattributes' nbdev_attr = '*.ipynb merge=nbdev-merge \\n ' try : attrs = attrs_path . read_text () if nbdev_attr not in attrs : if not attrs . endswith ( ' \\n ' ): attrs += ' \\n ' attrs_path . write_text ( attrs + nbdev_attr ) except FileNotFoundError : attrs_path . write_text ( nbdev_attr ) print ( \"Hooks are installed.\" )","title":"nbdev_install_hooks()"},{"location":"nbdev_api/nbdev/clean/#nbdev.clean.nbdev_trust","text":"Trust notebooks matching fname Source code in nbdev/clean.py @call_parse def nbdev_trust ( fname : str = None , # A notebook name or glob to trust force_all : bool = False # Also trust notebooks that haven't changed ): \"Trust notebooks matching `fname`\" try : from nbformat.sign import NotebookNotary except : import warnings warnings . warn ( \"Please install jupyter and try again\" ) return fname = Path ( fname if fname else get_config () . nbs_path ) path = fname if fname . is_dir () else fname . parent check_fname = path / \".last_checked\" last_checked = os . path . getmtime ( check_fname ) if check_fname . exists () else None nbs = globtastic ( fname , file_glob = '*.ipynb' , skip_folder_re = '^[_.]' ) if fname . is_dir () else [ fname ] for fn in nbs : if last_checked and not force_all : last_changed = os . path . getmtime ( fn ) if last_changed < last_checked : continue nb = read_nb ( fn ) if not NotebookNotary () . check_signature ( nb ): NotebookNotary () . sign ( nb ) check_fname . touch ( exist_ok = True )","title":"nbdev_trust()"},{"location":"nbdev_api/nbdev/cli/","text":"chelp () \u00a4 Show help for all console scripts Source code in nbdev/cli.py @call_parse def chelp (): \"Show help for all console scripts\" from fastcore.xtras import console_help console_help ( 'nbdev' ) nbdev_filter ( nb_txt = None , fname = None , printit = True ) \u00a4 A notebook filter for Quarto Source code in nbdev/cli.py @call_parse def nbdev_filter ( nb_txt : str = None , # Notebook text (uses stdin if not provided) fname : str = None , # Notebook to read (uses `nb_txt` if not provided) printit : bool_arg = True , # Print to stdout? ): \"A notebook filter for Quarto\" os . environ [ \"IN_TEST\" ] = \"1\" try : filt = globals ()[ get_config () . get ( 'exporter' , 'FilterDefaults' )]() except FileNotFoundError : filt = FilterDefaults () if fname : nb_txt = Path ( fname ) . read_text () elif not nb_txt : nb_txt = sys . stdin . read () nb = dict2nb ( loads ( nb_txt )) if printit : with open ( os . devnull , 'w' ) as dn : with redirect_stdout ( dn ): filt ( nb ) else : filt ( nb ) res = nb2str ( nb ) del os . environ [ \"IN_TEST\" ] if printit : print ( res , flush = True ) else : return res nbdev_new ( * , repo = None , branch = None , user = None , author = None , author_email = None , description = None , path = '.' , cfg_name = 'settings.ini' , lib_name = ' %(repo)s ' , git_url = 'https://github.com/ %(user)s / %(repo)s ' , custom_sidebar = False , nbs_path = 'nbs' , lib_path = None , doc_path = '_docs' , tst_flags = 'notest' , version = '0.0.1' , doc_host = 'https:// %(user)s .github.io' , doc_baseurl = '/ %(repo)s ' , keywords = 'nbdev jupyter notebook python' , license = 'apache2' , copyright = None , status = '3' , min_python = '3.7' , audience = 'Developers' , language = 'English' , recursive = True , black_formatting = False , readme_nb = 'index.ipynb' , title = ' %(lib_name)s ' , allowed_metadata_keys = '' , allowed_cell_metadata_keys = '' , jupyter_hooks = True , clean_ids = True , clear_all = False , put_version_in_init = True ) \u00a4 Create an nbdev project. Source code in nbdev/cli.py @call_parse @delegates ( nbdev_create_config ) def nbdev_new ( ** kwargs ): \"Create an nbdev project.\" from ghapi.core import GhApi nbdev_create_config . __wrapped__ ( ** kwargs ) cfg = get_config () _update_repo_meta ( cfg ) path = Path () with warnings . catch_warnings (): warnings . simplefilter ( 'ignore' , UserWarning ) tag = GhApi ( gh_host = 'https://api.github.com' , authenticate = False ) . repos . get_latest_release ( 'fastai' , 'nbdev-template' ) . tag_name url = f \"https://github.com/fastai/nbdev-template/archive/ { tag } .tar.gz\" extract_tgz ( url ) tmpl_path = path / f 'nbdev-template- { tag } ' cfg . nbs_path . mkdir ( exist_ok = True ) nbexists = bool ( first ( cfg . nbs_path . glob ( '*.ipynb' ))) _nbs_path_sufs = ( '.ipynb' , '.css' ) for o in tmpl_path . ls (): p = cfg . nbs_path if o . suffix in _nbs_path_sufs else path if o . name == '_quarto.yml' : continue if o . name == 'index.ipynb' : _render_nb ( o , cfg ) if o . name == '00_core.ipynb' and not nbexists : move ( o , p ) elif not ( path / o . name ) . exists (): move ( o , p ) rmtree ( tmpl_path ) refresh_quarto_yml () nbdev_export . __wrapped__ () nbdev_readme . __wrapped__ ()","title":"nbdev.cli"},{"location":"nbdev_api/nbdev/cli/#nbdev.cli.chelp","text":"Show help for all console scripts Source code in nbdev/cli.py @call_parse def chelp (): \"Show help for all console scripts\" from fastcore.xtras import console_help console_help ( 'nbdev' )","title":"chelp()"},{"location":"nbdev_api/nbdev/cli/#nbdev.cli.nbdev_filter","text":"A notebook filter for Quarto Source code in nbdev/cli.py @call_parse def nbdev_filter ( nb_txt : str = None , # Notebook text (uses stdin if not provided) fname : str = None , # Notebook to read (uses `nb_txt` if not provided) printit : bool_arg = True , # Print to stdout? ): \"A notebook filter for Quarto\" os . environ [ \"IN_TEST\" ] = \"1\" try : filt = globals ()[ get_config () . get ( 'exporter' , 'FilterDefaults' )]() except FileNotFoundError : filt = FilterDefaults () if fname : nb_txt = Path ( fname ) . read_text () elif not nb_txt : nb_txt = sys . stdin . read () nb = dict2nb ( loads ( nb_txt )) if printit : with open ( os . devnull , 'w' ) as dn : with redirect_stdout ( dn ): filt ( nb ) else : filt ( nb ) res = nb2str ( nb ) del os . environ [ \"IN_TEST\" ] if printit : print ( res , flush = True ) else : return res","title":"nbdev_filter()"},{"location":"nbdev_api/nbdev/cli/#nbdev.cli.nbdev_new","text":"Create an nbdev project. Source code in nbdev/cli.py @call_parse @delegates ( nbdev_create_config ) def nbdev_new ( ** kwargs ): \"Create an nbdev project.\" from ghapi.core import GhApi nbdev_create_config . __wrapped__ ( ** kwargs ) cfg = get_config () _update_repo_meta ( cfg ) path = Path () with warnings . catch_warnings (): warnings . simplefilter ( 'ignore' , UserWarning ) tag = GhApi ( gh_host = 'https://api.github.com' , authenticate = False ) . repos . get_latest_release ( 'fastai' , 'nbdev-template' ) . tag_name url = f \"https://github.com/fastai/nbdev-template/archive/ { tag } .tar.gz\" extract_tgz ( url ) tmpl_path = path / f 'nbdev-template- { tag } ' cfg . nbs_path . mkdir ( exist_ok = True ) nbexists = bool ( first ( cfg . nbs_path . glob ( '*.ipynb' ))) _nbs_path_sufs = ( '.ipynb' , '.css' ) for o in tmpl_path . ls (): p = cfg . nbs_path if o . suffix in _nbs_path_sufs else path if o . name == '_quarto.yml' : continue if o . name == 'index.ipynb' : _render_nb ( o , cfg ) if o . name == '00_core.ipynb' and not nbexists : move ( o , p ) elif not ( path / o . name ) . exists (): move ( o , p ) rmtree ( tmpl_path ) refresh_quarto_yml () nbdev_export . __wrapped__ () nbdev_readme . __wrapped__ ()","title":"nbdev_new()"},{"location":"nbdev_api/nbdev/config/","text":"Read and write nbdev's settings.ini file. get_config is the main function for reading settings. add_init ( path = None ) \u00a4 Add __init__.py in all subdirs of path containing python files if it's not there already. Source code in nbdev/config.py def add_init ( path = None ): \"Add `__init__.py` in all subdirs of `path` containing python files if it's not there already.\" # we add the lowest-level `__init__.py` files first, which ensures _has_py succeeds for parent modules path = Path ( path or get_config () . lib_path ) path . mkdir ( exist_ok = True ) if not ( path / _init ) . exists (): ( path / _init ) . touch () for r , ds , fs in os . walk ( path , topdown = False ): r = Path ( r ) subds = ( os . listdir ( r / d ) for d in ds ) if _has_py ( fs ) or any ( filter ( _has_py , subds )) and not ( r / _init ) . exists (): ( r / _init ) . touch () if get_config () . get ( 'put_version_in_init' , True ): update_version ( path ) config_key ( c , default = None , path = True , missing_ok = None ) \u00a4 Deprecated: use get_config().get or get_config().path instead. Source code in nbdev/config.py def config_key ( c , default = None , path = True , missing_ok = None ): \"Deprecated: use `get_config().get` or `get_config().path` instead.\" warn ( \"`config_key` is deprecated. Use `get_config().get` or `get_config().path` instead.\" , DeprecationWarning ) return get_config () . path ( c , default ) if path else get_config () . get ( c , default ) create_output ( txt , mime ) \u00a4 Add a cell output containing txt of the mime text MIME sub-type Source code in nbdev/config.py def create_output ( txt , mime ): \"Add a cell output containing `txt` of the `mime` text MIME sub-type\" return [{ \"data\" : { f \"text/ { mime } \" : str ( txt ) . splitlines ( True ) }, \"execution_count\" : 1 , \"metadata\" : {}, \"output_type\" : \"execute_result\" }] get_config ( cfg_name = 'settings.ini' , path = None ) \u00a4 Return nbdev config. Source code in nbdev/config.py @functools . lru_cache ( maxsize = None ) def get_config ( cfg_name = _nbdev_cfg_name , path = None ): \"Return nbdev config.\" cfg_file = _nbdev_config_file ( cfg_name , path ) extra_files = _xdg_config_paths ( cfg_name ) cfg = Config ( cfg_file . parent , cfg_file . name , extra_files = extra_files , types = _types ) return _apply_defaults ( cfg ) nbdev_create_config ( repo = None , branch = None , user = None , author = None , author_email = None , description = None , path = '.' , cfg_name = 'settings.ini' , * , lib_name = ' %(repo)s ' , git_url = 'https://github.com/ %(user)s / %(repo)s ' , custom_sidebar = False , nbs_path = 'nbs' , lib_path = None , doc_path = '_docs' , tst_flags = 'notest' , version = '0.0.1' , doc_host = 'https:// %(user)s .github.io' , doc_baseurl = '/ %(repo)s ' , keywords = 'nbdev jupyter notebook python' , license = 'apache2' , copyright = None , status = '3' , min_python = '3.7' , audience = 'Developers' , language = 'English' , recursive = True , black_formatting = False , readme_nb = 'index.ipynb' , title = ' %(lib_name)s ' , allowed_metadata_keys = '' , allowed_cell_metadata_keys = '' , jupyter_hooks = True , clean_ids = True , clear_all = False , put_version_in_init = True ) \u00a4 Create a config file. Source code in nbdev/config.py @call_parse @delegates ( _apply_defaults , but = 'cfg' ) def nbdev_create_config ( repo : str = None , # Repo name branch : str = None , # Repo default branch user : str = None , # Repo username author : str = None , # Package author's name author_email : str = None , # Package author's email address description : str = None , # Short summary of the package path : str = '.' , # Path to create config file cfg_name : str = _nbdev_cfg_name , # Name of config file to create ** kwargs ): \"Create a config file.\" req = { k : v for k , v in locals () . items () if k not in ( 'path' , 'cfg_name' , 'kwargs' )} inf = _fetch_from_git () d = _prompt_user ( req , inf ) cfg = Config ( path , cfg_name , d , save = False ) if cfg . config_file . exists (): warn ( f 'Config file already exists: { cfg . config_file } and will be used as a base' ) cfg = _apply_defaults ( cfg , ** kwargs ) txt = _cfg2txt ( cfg , _nbdev_cfg_head , _nbdev_cfg_sections , _nbdev_cfg_tail ) cfg . config_file . write_text ( txt ) cfg_fn = Path ( path ) / cfg_name print ( f ' { cfg_fn } created.' ) update_version ( path = None ) \u00a4 Add or update __version__ in the main __init__.py of the library. Source code in nbdev/config.py def update_version ( path = None ): \"Add or update `__version__` in the main `__init__.py` of the library.\" path = Path ( path or get_config () . lib_path ) fname = path / _init if not fname . exists (): fname . touch () version = f '__version__ = \" { get_config () . version } \"' code = fname . read_text () if _re_version . search ( code ) is None : code = version + \" \\n \" + code else : code = _re_version . sub ( version , code ) fname . write_text ( code ) write_cells ( cells , hdr , file , offset = 0 ) \u00a4 Write cells to file along with header hdr starting at index offset (mainly for nbdev internal use). Source code in nbdev/config.py def write_cells ( cells , hdr , file , offset = 0 ): \"Write `cells` to `file` along with header `hdr` starting at index `offset` (mainly for nbdev internal use).\" for cell in cells : if cell . source . strip (): file . write ( f ' \\n\\n { hdr } { cell . idx_ + offset } \\n { cell . source } ' )","title":"nbdev.config"},{"location":"nbdev_api/nbdev/config/#nbdev.config.add_init","text":"Add __init__.py in all subdirs of path containing python files if it's not there already. Source code in nbdev/config.py def add_init ( path = None ): \"Add `__init__.py` in all subdirs of `path` containing python files if it's not there already.\" # we add the lowest-level `__init__.py` files first, which ensures _has_py succeeds for parent modules path = Path ( path or get_config () . lib_path ) path . mkdir ( exist_ok = True ) if not ( path / _init ) . exists (): ( path / _init ) . touch () for r , ds , fs in os . walk ( path , topdown = False ): r = Path ( r ) subds = ( os . listdir ( r / d ) for d in ds ) if _has_py ( fs ) or any ( filter ( _has_py , subds )) and not ( r / _init ) . exists (): ( r / _init ) . touch () if get_config () . get ( 'put_version_in_init' , True ): update_version ( path )","title":"add_init()"},{"location":"nbdev_api/nbdev/config/#nbdev.config.config_key","text":"Deprecated: use get_config().get or get_config().path instead. Source code in nbdev/config.py def config_key ( c , default = None , path = True , missing_ok = None ): \"Deprecated: use `get_config().get` or `get_config().path` instead.\" warn ( \"`config_key` is deprecated. Use `get_config().get` or `get_config().path` instead.\" , DeprecationWarning ) return get_config () . path ( c , default ) if path else get_config () . get ( c , default )","title":"config_key()"},{"location":"nbdev_api/nbdev/config/#nbdev.config.create_output","text":"Add a cell output containing txt of the mime text MIME sub-type Source code in nbdev/config.py def create_output ( txt , mime ): \"Add a cell output containing `txt` of the `mime` text MIME sub-type\" return [{ \"data\" : { f \"text/ { mime } \" : str ( txt ) . splitlines ( True ) }, \"execution_count\" : 1 , \"metadata\" : {}, \"output_type\" : \"execute_result\" }]","title":"create_output()"},{"location":"nbdev_api/nbdev/config/#nbdev.config.get_config","text":"Return nbdev config. Source code in nbdev/config.py @functools . lru_cache ( maxsize = None ) def get_config ( cfg_name = _nbdev_cfg_name , path = None ): \"Return nbdev config.\" cfg_file = _nbdev_config_file ( cfg_name , path ) extra_files = _xdg_config_paths ( cfg_name ) cfg = Config ( cfg_file . parent , cfg_file . name , extra_files = extra_files , types = _types ) return _apply_defaults ( cfg )","title":"get_config()"},{"location":"nbdev_api/nbdev/config/#nbdev.config.nbdev_create_config","text":"Create a config file. Source code in nbdev/config.py @call_parse @delegates ( _apply_defaults , but = 'cfg' ) def nbdev_create_config ( repo : str = None , # Repo name branch : str = None , # Repo default branch user : str = None , # Repo username author : str = None , # Package author's name author_email : str = None , # Package author's email address description : str = None , # Short summary of the package path : str = '.' , # Path to create config file cfg_name : str = _nbdev_cfg_name , # Name of config file to create ** kwargs ): \"Create a config file.\" req = { k : v for k , v in locals () . items () if k not in ( 'path' , 'cfg_name' , 'kwargs' )} inf = _fetch_from_git () d = _prompt_user ( req , inf ) cfg = Config ( path , cfg_name , d , save = False ) if cfg . config_file . exists (): warn ( f 'Config file already exists: { cfg . config_file } and will be used as a base' ) cfg = _apply_defaults ( cfg , ** kwargs ) txt = _cfg2txt ( cfg , _nbdev_cfg_head , _nbdev_cfg_sections , _nbdev_cfg_tail ) cfg . config_file . write_text ( txt ) cfg_fn = Path ( path ) / cfg_name print ( f ' { cfg_fn } created.' )","title":"nbdev_create_config()"},{"location":"nbdev_api/nbdev/config/#nbdev.config.update_version","text":"Add or update __version__ in the main __init__.py of the library. Source code in nbdev/config.py def update_version ( path = None ): \"Add or update `__version__` in the main `__init__.py` of the library.\" path = Path ( path or get_config () . lib_path ) fname = path / _init if not fname . exists (): fname . touch () version = f '__version__ = \" { get_config () . version } \"' code = fname . read_text () if _re_version . search ( code ) is None : code = version + \" \\n \" + code else : code = _re_version . sub ( version , code ) fname . write_text ( code )","title":"update_version()"},{"location":"nbdev_api/nbdev/config/#nbdev.config.write_cells","text":"Write cells to file along with header hdr starting at index offset (mainly for nbdev internal use). Source code in nbdev/config.py def write_cells ( cells , hdr , file , offset = 0 ): \"Write `cells` to `file` along with header `hdr` starting at index `offset` (mainly for nbdev internal use).\" for cell in cells : if cell . source . strip (): file . write ( f ' \\n\\n { hdr } { cell . idx_ + offset } \\n { cell . source } ' )","title":"write_cells()"},{"location":"nbdev_api/nbdev/doclinks/","text":"NbdevLookup \u00a4 Mapping from symbol names to docs and source URLs Source code in nbdev/doclinks.py @lru_cache ( None ) class NbdevLookup : \"Mapping from symbol names to docs and source URLs\" def __init__ ( self , strip_libs = None , incl_libs = None , skip_mods = None ): cfg = get_config () if strip_libs is None : try : strip_libs = cfg . get ( 'strip_libs' , cfg . get ( 'lib_path' , 'nbdev' ) . name ) . split () except FileNotFoundError : strip_libs = 'nbdev' skip_mods = setify ( skip_mods ) strip_libs = L ( strip_libs ) if incl_libs is not None : incl_libs = ( L ( incl_libs ) + strip_libs ) . unique () # Dict from lib name to _nbdev module for incl_libs (defaults to all) self . entries = { o . name : _qual_syms ( o . resolve ()) for o in list ( pkg_resources . iter_entry_points ( group = 'nbdev' )) if incl_libs is None or o . dist . key in incl_libs } py_syms = merge ( * L ( o [ 'syms' ] . values () for o in self . entries . values ()) . concat ()) for m in strip_libs : if m in self . entries : _d = self . entries [ m ] stripped = { remove_prefix ( k , f \" { mod } .\" ): v for mod , dets in _d [ 'syms' ] . items () if mod not in skip_mods for k , v in dets . items ()} py_syms = merge ( stripped , py_syms ) self . syms = py_syms def __getitem__ ( self , s ): return self . syms . get ( s , None ) def doc ( self , sym ): \"Link to docs for `sym`\" res = self [ sym ] return res [ 0 ] if isinstance ( res , tuple ) else res def code ( self , sym ): \"Link to source code for `sym`\" res = self [ sym ] if not isinstance ( res , tuple ): return None _ , py , gh = res line = _lineno ( sym , py ) return f ' { gh } #L { line } ' def _link_sym ( self , m ): l = m . group ( 1 ) s = self . doc ( l ) if s is None : return m . group ( 0 ) l = l . replace ( ' \\\\ ' , r ' \\\\ ' ) return rf \"[` { l } `]( { s } )\" def link_line ( self , l ): return _re_backticks . sub ( self . _link_sym , l ) def linkify ( self , md ): if md : in_fence = False lines = md . splitlines () for i , l in enumerate ( lines ): if l . startswith ( \"```\" ): in_fence = not in_fence elif not l . startswith ( ' ' ) and not in_fence : lines [ i ] = self . link_line ( l ) return ' \\n ' . join ( lines ) code ( self , sym ) \u00a4 Link to source code for sym Source code in nbdev/doclinks.py def code ( self , sym ): \"Link to source code for `sym`\" res = self [ sym ] if not isinstance ( res , tuple ): return None _ , py , gh = res line = _lineno ( sym , py ) return f ' { gh } #L { line } ' doc ( self , sym ) \u00a4 Link to docs for sym Source code in nbdev/doclinks.py def doc ( self , sym ): \"Link to docs for `sym`\" res = self [ sym ] return res [ 0 ] if isinstance ( res , tuple ) else res nbdev_export ( path = None , * , symlinks = False , file_glob = '*.ipynb' , file_re = None , folder_re = None , skip_file_glob = None , skip_file_re = '^[_.]' , skip_folder_re = '^[_.]' ) \u00a4 Export notebooks in path to Python modules Source code in nbdev/doclinks.py @call_parse @delegates ( nbglob_cli ) def nbdev_export ( path : str = None , # Path or filename ** kwargs ): \"Export notebooks in `path` to Python modules\" if os . environ . get ( 'IN_TEST' , 0 ): return files = nbglob ( path = path , as_path = True , ** kwargs ) . sorted ( 'name' ) for f in files : nb_export ( f ) add_init ( get_config () . lib_path ) _build_modidx () nbglob ( path = None , skip_folder_re = '^[_.]' , file_glob = '*.ipynb' , skip_file_re = '^[_.]' , key = 'nbs_path' , as_path = False , * , recursive = True , symlinks = True , file_re = None , folder_re = None , skip_file_glob = None , func =< function join at 0x7f2f64d01e50 > , ret_folders = False ) \u00a4 Find all files in a directory matching an extension given a config key. Source code in nbdev/doclinks.py @delegates ( globtastic ) def nbglob ( path = None , skip_folder_re = '^[_.]' , file_glob = '*.ipynb' , skip_file_re = '^[_.]' , key = 'nbs_path' , as_path = False , ** kwargs ): \"Find all files in a directory matching an extension given a config key.\" path = Path ( path or get_config ()[ key ]) recursive = get_config () . recursive res = globtastic ( path , file_glob = file_glob , skip_folder_re = skip_folder_re , skip_file_re = skip_file_re , recursive = recursive , ** kwargs ) return res . map ( Path ) if as_path else res nbglob_cli ( path = None , symlinks = False , file_glob = '*.ipynb' , file_re = None , folder_re = None , skip_file_glob = None , skip_file_re = '^[_.]' , skip_folder_re = '^[_.]' ) \u00a4 Find all files in a directory matching an extension given a config key. Source code in nbdev/doclinks.py def nbglob_cli ( path : str = None , # Path to notebooks symlinks : bool = False , # Follow symlinks? file_glob : str = '*.ipynb' , # Only include files matching glob file_re : str = None , # Only include files matching regex folder_re : str = None , # Only enter folders matching regex skip_file_glob : str = None , # Skip files matching glob skip_file_re : str = '^[_.]' , # Skip files matching regex skip_folder_re : str = '^[_.]' ): # Skip folders matching regex \"Find all files in a directory matching an extension given a config key.\" return nbglob ( path , symlinks = symlinks , file_glob = file_glob , file_re = file_re , folder_re = folder_re , skip_file_glob = skip_file_glob , skip_file_re = skip_file_re , skip_folder_re = skip_folder_re ) patch_name ( o ) \u00a4 If o is decorated with patch or patch_to , return its class-prefix name Source code in nbdev/doclinks.py def patch_name ( o ): \"If `o` is decorated with `patch` or `patch_to`, return its class-prefix name\" if not isinstance ( o , ( ast . FunctionDef , ast . AsyncFunctionDef )): return o . name d = first ([ d for d in o . decorator_list if decor_id ( d ) . startswith ( 'patch' )]) if not d : return o . name nm = decor_id ( d ) if nm == 'patch' : a = o . args . args [ 0 ] . annotation if isinstance ( a , ast . BinOp ): return _binop_leafs ( a , o ) elif nm == 'patch_to' : a = d . args [ 0 ] else : return o . name return _sym_nm ( a , o )","title":"nbdev.doclinks"},{"location":"nbdev_api/nbdev/doclinks/#nbdev.doclinks.NbdevLookup","text":"Mapping from symbol names to docs and source URLs Source code in nbdev/doclinks.py @lru_cache ( None ) class NbdevLookup : \"Mapping from symbol names to docs and source URLs\" def __init__ ( self , strip_libs = None , incl_libs = None , skip_mods = None ): cfg = get_config () if strip_libs is None : try : strip_libs = cfg . get ( 'strip_libs' , cfg . get ( 'lib_path' , 'nbdev' ) . name ) . split () except FileNotFoundError : strip_libs = 'nbdev' skip_mods = setify ( skip_mods ) strip_libs = L ( strip_libs ) if incl_libs is not None : incl_libs = ( L ( incl_libs ) + strip_libs ) . unique () # Dict from lib name to _nbdev module for incl_libs (defaults to all) self . entries = { o . name : _qual_syms ( o . resolve ()) for o in list ( pkg_resources . iter_entry_points ( group = 'nbdev' )) if incl_libs is None or o . dist . key in incl_libs } py_syms = merge ( * L ( o [ 'syms' ] . values () for o in self . entries . values ()) . concat ()) for m in strip_libs : if m in self . entries : _d = self . entries [ m ] stripped = { remove_prefix ( k , f \" { mod } .\" ): v for mod , dets in _d [ 'syms' ] . items () if mod not in skip_mods for k , v in dets . items ()} py_syms = merge ( stripped , py_syms ) self . syms = py_syms def __getitem__ ( self , s ): return self . syms . get ( s , None ) def doc ( self , sym ): \"Link to docs for `sym`\" res = self [ sym ] return res [ 0 ] if isinstance ( res , tuple ) else res def code ( self , sym ): \"Link to source code for `sym`\" res = self [ sym ] if not isinstance ( res , tuple ): return None _ , py , gh = res line = _lineno ( sym , py ) return f ' { gh } #L { line } ' def _link_sym ( self , m ): l = m . group ( 1 ) s = self . doc ( l ) if s is None : return m . group ( 0 ) l = l . replace ( ' \\\\ ' , r ' \\\\ ' ) return rf \"[` { l } `]( { s } )\" def link_line ( self , l ): return _re_backticks . sub ( self . _link_sym , l ) def linkify ( self , md ): if md : in_fence = False lines = md . splitlines () for i , l in enumerate ( lines ): if l . startswith ( \"```\" ): in_fence = not in_fence elif not l . startswith ( ' ' ) and not in_fence : lines [ i ] = self . link_line ( l ) return ' \\n ' . join ( lines )","title":"NbdevLookup"},{"location":"nbdev_api/nbdev/doclinks/#nbdev.doclinks.NbdevLookup.code","text":"Link to source code for sym Source code in nbdev/doclinks.py def code ( self , sym ): \"Link to source code for `sym`\" res = self [ sym ] if not isinstance ( res , tuple ): return None _ , py , gh = res line = _lineno ( sym , py ) return f ' { gh } #L { line } '","title":"code()"},{"location":"nbdev_api/nbdev/doclinks/#nbdev.doclinks.NbdevLookup.doc","text":"Link to docs for sym Source code in nbdev/doclinks.py def doc ( self , sym ): \"Link to docs for `sym`\" res = self [ sym ] return res [ 0 ] if isinstance ( res , tuple ) else res","title":"doc()"},{"location":"nbdev_api/nbdev/doclinks/#nbdev.doclinks.nbdev_export","text":"Export notebooks in path to Python modules Source code in nbdev/doclinks.py @call_parse @delegates ( nbglob_cli ) def nbdev_export ( path : str = None , # Path or filename ** kwargs ): \"Export notebooks in `path` to Python modules\" if os . environ . get ( 'IN_TEST' , 0 ): return files = nbglob ( path = path , as_path = True , ** kwargs ) . sorted ( 'name' ) for f in files : nb_export ( f ) add_init ( get_config () . lib_path ) _build_modidx ()","title":"nbdev_export()"},{"location":"nbdev_api/nbdev/doclinks/#nbdev.doclinks.nbglob","text":"Find all files in a directory matching an extension given a config key. Source code in nbdev/doclinks.py @delegates ( globtastic ) def nbglob ( path = None , skip_folder_re = '^[_.]' , file_glob = '*.ipynb' , skip_file_re = '^[_.]' , key = 'nbs_path' , as_path = False , ** kwargs ): \"Find all files in a directory matching an extension given a config key.\" path = Path ( path or get_config ()[ key ]) recursive = get_config () . recursive res = globtastic ( path , file_glob = file_glob , skip_folder_re = skip_folder_re , skip_file_re = skip_file_re , recursive = recursive , ** kwargs ) return res . map ( Path ) if as_path else res","title":"nbglob()"},{"location":"nbdev_api/nbdev/doclinks/#nbdev.doclinks.nbglob_cli","text":"Find all files in a directory matching an extension given a config key. Source code in nbdev/doclinks.py def nbglob_cli ( path : str = None , # Path to notebooks symlinks : bool = False , # Follow symlinks? file_glob : str = '*.ipynb' , # Only include files matching glob file_re : str = None , # Only include files matching regex folder_re : str = None , # Only enter folders matching regex skip_file_glob : str = None , # Skip files matching glob skip_file_re : str = '^[_.]' , # Skip files matching regex skip_folder_re : str = '^[_.]' ): # Skip folders matching regex \"Find all files in a directory matching an extension given a config key.\" return nbglob ( path , symlinks = symlinks , file_glob = file_glob , file_re = file_re , folder_re = folder_re , skip_file_glob = skip_file_glob , skip_file_re = skip_file_re , skip_folder_re = skip_folder_re )","title":"nbglob_cli()"},{"location":"nbdev_api/nbdev/doclinks/#nbdev.doclinks.patch_name","text":"If o is decorated with patch or patch_to , return its class-prefix name Source code in nbdev/doclinks.py def patch_name ( o ): \"If `o` is decorated with `patch` or `patch_to`, return its class-prefix name\" if not isinstance ( o , ( ast . FunctionDef , ast . AsyncFunctionDef )): return o . name d = first ([ d for d in o . decorator_list if decor_id ( d ) . startswith ( 'patch' )]) if not d : return o . name nm = decor_id ( d ) if nm == 'patch' : a = o . args . args [ 0 ] . annotation if isinstance ( a , ast . BinOp ): return _binop_leafs ( a , o ) elif nm == 'patch_to' : a = d . args [ 0 ] else : return o . name return _sym_nm ( a , o )","title":"patch_name()"},{"location":"nbdev_api/nbdev/export/","text":"ExportModuleProc \u00a4 A processor which exports code to a module Source code in nbdev/export.py class ExportModuleProc : \"A processor which exports code to a module\" def begin ( self ): self . modules , self . in_all = defaultdict ( L ), defaultdict ( L ) def _default_exp_ ( self , cell , exp_to ): self . default_exp = exp_to def _exporti_ ( self , cell , exp_to = None ): self . modules [ ifnone ( exp_to , '#' )] . append ( cell ) def _export_ ( self , cell , exp_to = None ): self . _exporti_ ( cell , exp_to ) self . in_all [ ifnone ( exp_to , '#' )] . append ( cell ) _exports_ = _export_ black_format ( cell , force = False ) \u00a4 Processor to format code with black Source code in nbdev/export.py def black_format ( cell , # Cell to format force = False ): # Turn black formatting on regardless of settings.ini \"Processor to format code with `black`\" try : cfg = get_config () except FileNotFoundError : return if ( not cfg . black_formatting and not force ) or cell . cell_type != 'code' : return try : import black except : raise ImportError ( \"You must install black: `pip install black` if you wish to use black formatting with nbdev\" ) else : _format_str = partial ( black . format_str , mode = black . Mode ()) try : cell . source = _format_str ( cell . source ) . strip () except : pass nb_export ( nbname , lib_path = None , procs =< function black_format at 0x7f2f62cc0e50 > , debug = False , mod_maker =< class ' nbdev . maker . ModuleMaker '>, name=None) \u00a4 Create module(s) from notebook Source code in nbdev/export.py def nb_export ( nbname , lib_path = None , procs = black_format , debug = False , mod_maker = ModuleMaker , name = None ): \"Create module(s) from notebook\" if lib_path is None : lib_path = get_config () . lib_path exp = ExportModuleProc () nb = NBProcessor ( nbname , [ exp ] + L ( procs ), debug = debug ) nb . process () for mod , cells in exp . modules . items (): all_cells = exp . in_all [ mod ] nm = ifnone ( name , getattr ( exp , 'default_exp' , None ) if mod == '#' else mod ) if not nm : warn ( f \"Notebook ' { nbname } ' uses `#|export` without `#|default_exp` cell. \\n \" \"Note nbdev2 no longer supports nbdev1 syntax. Run `nbdev_migrate` to upgrade. \\n \" \"See https://nbdev.fast.ai/getting_started.html for more information.\" ) return mm = mod_maker ( dest = lib_path , name = nm , nb_path = nbname , is_new = bool ( name ) or mod == '#' ) mm . make ( cells , all_cells , lib_path = lib_path )","title":"nbdev.export"},{"location":"nbdev_api/nbdev/export/#nbdev.export.ExportModuleProc","text":"A processor which exports code to a module Source code in nbdev/export.py class ExportModuleProc : \"A processor which exports code to a module\" def begin ( self ): self . modules , self . in_all = defaultdict ( L ), defaultdict ( L ) def _default_exp_ ( self , cell , exp_to ): self . default_exp = exp_to def _exporti_ ( self , cell , exp_to = None ): self . modules [ ifnone ( exp_to , '#' )] . append ( cell ) def _export_ ( self , cell , exp_to = None ): self . _exporti_ ( cell , exp_to ) self . in_all [ ifnone ( exp_to , '#' )] . append ( cell ) _exports_ = _export_","title":"ExportModuleProc"},{"location":"nbdev_api/nbdev/export/#nbdev.export.black_format","text":"Processor to format code with black Source code in nbdev/export.py def black_format ( cell , # Cell to format force = False ): # Turn black formatting on regardless of settings.ini \"Processor to format code with `black`\" try : cfg = get_config () except FileNotFoundError : return if ( not cfg . black_formatting and not force ) or cell . cell_type != 'code' : return try : import black except : raise ImportError ( \"You must install black: `pip install black` if you wish to use black formatting with nbdev\" ) else : _format_str = partial ( black . format_str , mode = black . Mode ()) try : cell . source = _format_str ( cell . source ) . strip () except : pass","title":"black_format()"},{"location":"nbdev_api/nbdev/export/#nbdev.export.nb_export","text":"Create module(s) from notebook Source code in nbdev/export.py def nb_export ( nbname , lib_path = None , procs = black_format , debug = False , mod_maker = ModuleMaker , name = None ): \"Create module(s) from notebook\" if lib_path is None : lib_path = get_config () . lib_path exp = ExportModuleProc () nb = NBProcessor ( nbname , [ exp ] + L ( procs ), debug = debug ) nb . process () for mod , cells in exp . modules . items (): all_cells = exp . in_all [ mod ] nm = ifnone ( name , getattr ( exp , 'default_exp' , None ) if mod == '#' else mod ) if not nm : warn ( f \"Notebook ' { nbname } ' uses `#|export` without `#|default_exp` cell. \\n \" \"Note nbdev2 no longer supports nbdev1 syntax. Run `nbdev_migrate` to upgrade. \\n \" \"See https://nbdev.fast.ai/getting_started.html for more information.\" ) return mm = mod_maker ( dest = lib_path , name = nm , nb_path = nbname , is_new = bool ( name ) or mod == '#' ) mm . make ( cells , all_cells , lib_path = lib_path )","title":"nb_export()"},{"location":"nbdev_api/nbdev/extract_attachments/","text":"A preprocessor that extracts all of the attachments from the notebook file. The extracted attachments are returned in the 'resources' dictionary. Based on the ExtractOutputsProcessor in nbconvert... the license for nbconvert is: Licensing terms \u00a4 This project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows: Copyright (c) 2001-2015, IPython Development Team Copyright (c) 2015-, Jupyter Development Team All rights reserved. ExtractAttachmentsPreprocessor ( Preprocessor ) \u00a4 Extracts all of the outputs from the notebook file. Source code in nbdev/extract_attachments.py class ExtractAttachmentsPreprocessor ( Preprocessor ): \"Extracts all of the outputs from the notebook file.\" output_filename_template = Unicode ( \"attach_ {cell_index} _ {name} \" ) . tag ( config = True ) extract_output_types = Set ( { 'image/png' , 'image/jpeg' , 'image/svg+xml' , 'application/pdf' }) . tag ( config = True ) def preprocess_cell ( self , cell , resources , cell_index ): output_files_dir = resources . get ( 'output_files_dir' , None ) if not isinstance ( resources [ 'outputs' ], dict ): resources [ 'outputs' ] = {} for name , attach in cell . get ( \"attachments\" , {}) . items (): for mime , data in attach . items (): if mime not in self . extract_output_types : continue # Binary files are base64-encoded, SVG is already XML if mime in { 'image/png' , 'image/jpeg' , 'application/pdf' }: data = a2b_base64 ( data ) elif sys . platform == 'win32' : data = data . replace ( ' \\n ' , ' \\r\\n ' ) . encode ( \"UTF-8\" ) else : data = data . encode ( \"UTF-8\" ) filename = self . output_filename_template . format ( cell_index = cell_index , name = name ) if output_files_dir is not None : filename = os . path . join ( output_files_dir , filename ) if name . endswith ( \".gif\" ) and mime == \"image/png\" : filename = filename . replace ( \".gif\" , \".png\" ) resources [ 'outputs' ][ filename ] = data attach_str = \"attachment:\" + name if attach_str in cell . source : cell . source = cell . source . replace ( attach_str , filename ) return cell , resources preprocess_cell ( self , cell , resources , cell_index ) \u00a4 Override if you want to apply some preprocessing to each cell. Must return modified cell and resource dictionary. Parameters \u00a4 cell : NotebookNode cell Notebook cell being processed resources : dictionary Additional resources used in the conversion process. Allows preprocessors to pass variables into the Jinja engine. index : int Index of the cell being processed Source code in nbdev/extract_attachments.py def preprocess_cell ( self , cell , resources , cell_index ): output_files_dir = resources . get ( 'output_files_dir' , None ) if not isinstance ( resources [ 'outputs' ], dict ): resources [ 'outputs' ] = {} for name , attach in cell . get ( \"attachments\" , {}) . items (): for mime , data in attach . items (): if mime not in self . extract_output_types : continue # Binary files are base64-encoded, SVG is already XML if mime in { 'image/png' , 'image/jpeg' , 'application/pdf' }: data = a2b_base64 ( data ) elif sys . platform == 'win32' : data = data . replace ( ' \\n ' , ' \\r\\n ' ) . encode ( \"UTF-8\" ) else : data = data . encode ( \"UTF-8\" ) filename = self . output_filename_template . format ( cell_index = cell_index , name = name ) if output_files_dir is not None : filename = os . path . join ( output_files_dir , filename ) if name . endswith ( \".gif\" ) and mime == \"image/png\" : filename = filename . replace ( \".gif\" , \".png\" ) resources [ 'outputs' ][ filename ] = data attach_str = \"attachment:\" + name if attach_str in cell . source : cell . source = cell . source . replace ( attach_str , filename ) return cell , resources","title":"nbdev.extract_attachments"},{"location":"nbdev_api/nbdev/extract_attachments/#nbdev.extract_attachments--licensing-terms","text":"This project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows: Copyright (c) 2001-2015, IPython Development Team Copyright (c) 2015-, Jupyter Development Team All rights reserved.","title":"Licensing terms"},{"location":"nbdev_api/nbdev/extract_attachments/#nbdev.extract_attachments.ExtractAttachmentsPreprocessor","text":"Extracts all of the outputs from the notebook file. Source code in nbdev/extract_attachments.py class ExtractAttachmentsPreprocessor ( Preprocessor ): \"Extracts all of the outputs from the notebook file.\" output_filename_template = Unicode ( \"attach_ {cell_index} _ {name} \" ) . tag ( config = True ) extract_output_types = Set ( { 'image/png' , 'image/jpeg' , 'image/svg+xml' , 'application/pdf' }) . tag ( config = True ) def preprocess_cell ( self , cell , resources , cell_index ): output_files_dir = resources . get ( 'output_files_dir' , None ) if not isinstance ( resources [ 'outputs' ], dict ): resources [ 'outputs' ] = {} for name , attach in cell . get ( \"attachments\" , {}) . items (): for mime , data in attach . items (): if mime not in self . extract_output_types : continue # Binary files are base64-encoded, SVG is already XML if mime in { 'image/png' , 'image/jpeg' , 'application/pdf' }: data = a2b_base64 ( data ) elif sys . platform == 'win32' : data = data . replace ( ' \\n ' , ' \\r\\n ' ) . encode ( \"UTF-8\" ) else : data = data . encode ( \"UTF-8\" ) filename = self . output_filename_template . format ( cell_index = cell_index , name = name ) if output_files_dir is not None : filename = os . path . join ( output_files_dir , filename ) if name . endswith ( \".gif\" ) and mime == \"image/png\" : filename = filename . replace ( \".gif\" , \".png\" ) resources [ 'outputs' ][ filename ] = data attach_str = \"attachment:\" + name if attach_str in cell . source : cell . source = cell . source . replace ( attach_str , filename ) return cell , resources","title":"ExtractAttachmentsPreprocessor"},{"location":"nbdev_api/nbdev/extract_attachments/#nbdev.extract_attachments.ExtractAttachmentsPreprocessor.preprocess_cell","text":"Override if you want to apply some preprocessing to each cell. Must return modified cell and resource dictionary.","title":"preprocess_cell()"},{"location":"nbdev_api/nbdev/extract_attachments/#nbdev.extract_attachments.ExtractAttachmentsPreprocessor.preprocess_cell--parameters","text":"cell : NotebookNode cell Notebook cell being processed resources : dictionary Additional resources used in the conversion process. Allows preprocessors to pass variables into the Jinja engine. index : int Index of the cell being processed Source code in nbdev/extract_attachments.py def preprocess_cell ( self , cell , resources , cell_index ): output_files_dir = resources . get ( 'output_files_dir' , None ) if not isinstance ( resources [ 'outputs' ], dict ): resources [ 'outputs' ] = {} for name , attach in cell . get ( \"attachments\" , {}) . items (): for mime , data in attach . items (): if mime not in self . extract_output_types : continue # Binary files are base64-encoded, SVG is already XML if mime in { 'image/png' , 'image/jpeg' , 'application/pdf' }: data = a2b_base64 ( data ) elif sys . platform == 'win32' : data = data . replace ( ' \\n ' , ' \\r\\n ' ) . encode ( \"UTF-8\" ) else : data = data . encode ( \"UTF-8\" ) filename = self . output_filename_template . format ( cell_index = cell_index , name = name ) if output_files_dir is not None : filename = os . path . join ( output_files_dir , filename ) if name . endswith ( \".gif\" ) and mime == \"image/png\" : filename = filename . replace ( \".gif\" , \".png\" ) resources [ 'outputs' ][ filename ] = data attach_str = \"attachment:\" + name if attach_str in cell . source : cell . source = cell . source . replace ( attach_str , filename ) return cell , resources","title":"Parameters"},{"location":"nbdev_api/nbdev/frontmatter/","text":"FrontmatterProc ( Processor ) \u00a4 A YAML and formatted-markdown frontmatter processor Source code in nbdev/frontmatter.py class FrontmatterProc ( Processor ): \"A YAML and formatted-markdown frontmatter processor\" def begin ( self ): self . fm = getattr ( self . nb , 'frontmatter_' , {}) def _update ( self , f , cell ): s = cell . get ( 'source' ) if not s : return d = f ( s ) if not d : return self . fm . update ( d ) cell . source = None def cell ( self , cell ): if cell . cell_type == 'raw' : self . _update ( _fm2dict , cell ) elif cell . cell_type == 'markdown' and 'title' not in self . fm : self . _update ( _md2dict , cell ) def end ( self ): self . nb . frontmatter_ = self . fm if not self . fm : return self . fm . update ({ 'output-file' : _nbpath2html ( Path ( self . nb . path_ )) . name }) _insertfm ( self . nb , self . fm )","title":"nbdev.frontmatter"},{"location":"nbdev_api/nbdev/frontmatter/#nbdev.frontmatter.FrontmatterProc","text":"A YAML and formatted-markdown frontmatter processor Source code in nbdev/frontmatter.py class FrontmatterProc ( Processor ): \"A YAML and formatted-markdown frontmatter processor\" def begin ( self ): self . fm = getattr ( self . nb , 'frontmatter_' , {}) def _update ( self , f , cell ): s = cell . get ( 'source' ) if not s : return d = f ( s ) if not d : return self . fm . update ( d ) cell . source = None def cell ( self , cell ): if cell . cell_type == 'raw' : self . _update ( _fm2dict , cell ) elif cell . cell_type == 'markdown' and 'title' not in self . fm : self . _update ( _md2dict , cell ) def end ( self ): self . nb . frontmatter_ = self . fm if not self . fm : return self . fm . update ({ 'output-file' : _nbpath2html ( Path ( self . nb . path_ )) . name }) _insertfm ( self . nb , self . fm )","title":"FrontmatterProc"},{"location":"nbdev_api/nbdev/imports/","text":"","title":"nbdev.imports"},{"location":"nbdev_api/nbdev/maker/","text":"ModuleMaker \u00a4 Helper class to create exported library from notebook source cells Source code in nbdev/maker.py class ModuleMaker : \"Helper class to create exported library from notebook source cells\" def __init__ ( self , dest , name , nb_path , is_new = True , parse = True ): dest , nb_path = Path ( dest ), Path ( nb_path ) store_attr () self . fname = dest / ( name . replace ( '.' , '/' ) + \".py\" ) if is_new : dest . mkdir ( parents = True , exist_ok = True ) else : assert self . fname . exists (), f \" { self . fname } does not exist\" self . dest2nb = nb_path . relpath ( self . fname . parent ) . as_posix () self . hdr = f \"# %% { self . dest2nb } \" make ( self , cells , all_cells = None , lib_path = None ) \u00a4 Write module containing cells with __all__ generated from all_cells Source code in nbdev/maker.py @patch def make ( self : ModuleMaker , cells , all_cells = None , lib_path = None ): \"Write module containing `cells` with `__all__` generated from `all_cells`\" if all_cells is None : all_cells = cells cells , all_cells = L ( cells ), L ( all_cells ) if self . parse : if not lib_path : lib_path = get_config () . lib_path mod_dir = os . path . relpath ( self . fname . parent , Path ( lib_path ) . parent ) _import2relative ( all_cells , mod_dir ) if not self . is_new : return self . _make_exists ( cells , all_cells ) self . fname . parent . mkdir ( exist_ok = True , parents = True ) last_future = 0 if self . parse : _all = self . make_all ( all_cells ) last_future = self . _last_future ( cells ) if len ( all_cells ) > 0 else 0 tw = TextWrapper ( width = 120 , initial_indent = '' , subsequent_indent = ' ' * 11 , break_long_words = False ) all_str = ' \\n ' . join ( tw . wrap ( str ( _all ))) with self . fname . open ( 'w' ) as f : f . write ( _retr_mdoc ( cells )) f . write ( f \"# AUTOGENERATED! DO NOT EDIT! File to edit: { self . dest2nb } .\" ) if last_future > 0 : write_cells ( cells [: last_future ], self . hdr , f ) if self . parse : f . write ( f \" \\n\\n # %% auto 0 \\n __all__ = { all_str } \" ) write_cells ( cells [ last_future :], self . hdr , f ) f . write ( ' \\n ' ) make_all ( self , cells ) \u00a4 Create __all__ with all exports in cells Source code in nbdev/maker.py @patch def make_all ( self : ModuleMaker , cells ): \"Create `__all__` with all exports in `cells`\" if cells is None : return '' trees = L ( cells ) . map ( NbCell . parsed_ ) . concat () # include anything mentioned in \"_all_\", even if otherwise private # NB: \"_all_\" can include strings (names), or symbols, so we look for \"id\" or \"value\" assigns = trees . filter ( risinstance ( _assign_types )) all_assigns = assigns . filter ( lambda o : getattr ( _targets ( o )[ 0 ], 'id' , None ) == '_all_' ) all_vals = all_assigns . map ( _val_or_id ) . concat () syms = trees . filter ( _wants ) . attrgot ( 'name' ) # assignment targets (NB: can be multiple, e.g. \"a=b=c\", and/or destructuring e.g \"a,b=(1,2)\") assign_targs = L ( L ( _targets ( assn )) . map ( _all_targets ) . concat () for assn in assigns ) . concat () exports = ( assign_targs . attrgot ( 'id' ) + syms ) . filter ( lambda o : o and o [ 0 ] != '_' ) return ( exports + all_vals ) . unique () decor_id ( d ) \u00a4 id attr of decorator, regardless of whether called as function or bare Source code in nbdev/maker.py def decor_id ( d ): \"`id` attr of decorator, regardless of whether called as function or bare\" return d . id if hasattr ( d , 'id' ) else nested_attr ( d , 'func.id' , '' ) find_var ( lines , varname ) \u00a4 Find the line numbers where varname is defined in lines Source code in nbdev/maker.py def find_var ( lines , varname ): \"Find the line numbers where `varname` is defined in `lines`\" start = first ( i for i , o in enumerate ( lines ) if o . startswith ( varname )) if start is None : return None , None empty = ' ' , ' \\t ' if start == len ( lines ) - 1 or lines [ start + 1 ][: 1 ] not in empty : return start , start + 1 end = first ( i for i , o in enumerate ( lines [ start + 1 :]) if o [: 1 ] not in empty ) return start , len ( lines ) if end is None else ( end + start + 1 ) read_var ( code , varname ) \u00a4 Eval and return the value of varname defined in code Source code in nbdev/maker.py def read_var ( code , varname ): \"Eval and return the value of `varname` defined in `code`\" lines = code . splitlines () start , end = find_var ( lines , varname ) if start is None : return None res = [ lines [ start ] . split ( '=' )[ - 1 ] . strip ()] res += lines [ start + 1 : end ] try : return eval ( ' \\n ' . join ( res )) except SyntaxError : raise Exception ( ' \\n ' . join ( res )) from None relative_import ( name , fname , level = 0 ) \u00a4 Convert a module name to a name relative to fname Source code in nbdev/maker.py def relative_import ( name , fname , level = 0 ): \"Convert a module `name` to a name relative to `fname`\" assert not level sname = name . replace ( '.' , '/' ) if not ( os . path . commonpath ([ sname , fname ])): return name rel = os . path . relpath ( sname , fname ) if rel == \".\" : return \".\" res = rel . replace ( f \".. { os . path . sep } \" , \".\" ) if not all ( o == '.' for o in res ): res = '.' + res return res . replace ( os . path . sep , \".\" ) update_var ( varname , func , fn = None , code = None ) \u00a4 Update the definition of varname in file fn , by calling func with the current definition Source code in nbdev/maker.py def update_var ( varname , func , fn = None , code = None ): \"Update the definition of `varname` in file `fn`, by calling `func` with the current definition\" if fn : fn = Path ( fn ) code = fn . read_text () lines = code . splitlines () v = read_var ( code , varname ) res = func ( v ) start , end = find_var ( lines , varname ) del ( lines [ start : end ]) lines . insert ( start , f \" { varname } = { res } \" ) code = ' \\n ' . join ( lines ) if fn : fn . write_text ( code ) else : return code","title":"nbdev.maker"},{"location":"nbdev_api/nbdev/maker/#nbdev.maker.ModuleMaker","text":"Helper class to create exported library from notebook source cells Source code in nbdev/maker.py class ModuleMaker : \"Helper class to create exported library from notebook source cells\" def __init__ ( self , dest , name , nb_path , is_new = True , parse = True ): dest , nb_path = Path ( dest ), Path ( nb_path ) store_attr () self . fname = dest / ( name . replace ( '.' , '/' ) + \".py\" ) if is_new : dest . mkdir ( parents = True , exist_ok = True ) else : assert self . fname . exists (), f \" { self . fname } does not exist\" self . dest2nb = nb_path . relpath ( self . fname . parent ) . as_posix () self . hdr = f \"# %% { self . dest2nb } \"","title":"ModuleMaker"},{"location":"nbdev_api/nbdev/maker/#nbdev.maker.ModuleMaker.make","text":"Write module containing cells with __all__ generated from all_cells Source code in nbdev/maker.py @patch def make ( self : ModuleMaker , cells , all_cells = None , lib_path = None ): \"Write module containing `cells` with `__all__` generated from `all_cells`\" if all_cells is None : all_cells = cells cells , all_cells = L ( cells ), L ( all_cells ) if self . parse : if not lib_path : lib_path = get_config () . lib_path mod_dir = os . path . relpath ( self . fname . parent , Path ( lib_path ) . parent ) _import2relative ( all_cells , mod_dir ) if not self . is_new : return self . _make_exists ( cells , all_cells ) self . fname . parent . mkdir ( exist_ok = True , parents = True ) last_future = 0 if self . parse : _all = self . make_all ( all_cells ) last_future = self . _last_future ( cells ) if len ( all_cells ) > 0 else 0 tw = TextWrapper ( width = 120 , initial_indent = '' , subsequent_indent = ' ' * 11 , break_long_words = False ) all_str = ' \\n ' . join ( tw . wrap ( str ( _all ))) with self . fname . open ( 'w' ) as f : f . write ( _retr_mdoc ( cells )) f . write ( f \"# AUTOGENERATED! DO NOT EDIT! File to edit: { self . dest2nb } .\" ) if last_future > 0 : write_cells ( cells [: last_future ], self . hdr , f ) if self . parse : f . write ( f \" \\n\\n # %% auto 0 \\n __all__ = { all_str } \" ) write_cells ( cells [ last_future :], self . hdr , f ) f . write ( ' \\n ' )","title":"make()"},{"location":"nbdev_api/nbdev/maker/#nbdev.maker.ModuleMaker.make_all","text":"Create __all__ with all exports in cells Source code in nbdev/maker.py @patch def make_all ( self : ModuleMaker , cells ): \"Create `__all__` with all exports in `cells`\" if cells is None : return '' trees = L ( cells ) . map ( NbCell . parsed_ ) . concat () # include anything mentioned in \"_all_\", even if otherwise private # NB: \"_all_\" can include strings (names), or symbols, so we look for \"id\" or \"value\" assigns = trees . filter ( risinstance ( _assign_types )) all_assigns = assigns . filter ( lambda o : getattr ( _targets ( o )[ 0 ], 'id' , None ) == '_all_' ) all_vals = all_assigns . map ( _val_or_id ) . concat () syms = trees . filter ( _wants ) . attrgot ( 'name' ) # assignment targets (NB: can be multiple, e.g. \"a=b=c\", and/or destructuring e.g \"a,b=(1,2)\") assign_targs = L ( L ( _targets ( assn )) . map ( _all_targets ) . concat () for assn in assigns ) . concat () exports = ( assign_targs . attrgot ( 'id' ) + syms ) . filter ( lambda o : o and o [ 0 ] != '_' ) return ( exports + all_vals ) . unique ()","title":"make_all()"},{"location":"nbdev_api/nbdev/maker/#nbdev.maker.decor_id","text":"id attr of decorator, regardless of whether called as function or bare Source code in nbdev/maker.py def decor_id ( d ): \"`id` attr of decorator, regardless of whether called as function or bare\" return d . id if hasattr ( d , 'id' ) else nested_attr ( d , 'func.id' , '' )","title":"decor_id()"},{"location":"nbdev_api/nbdev/maker/#nbdev.maker.find_var","text":"Find the line numbers where varname is defined in lines Source code in nbdev/maker.py def find_var ( lines , varname ): \"Find the line numbers where `varname` is defined in `lines`\" start = first ( i for i , o in enumerate ( lines ) if o . startswith ( varname )) if start is None : return None , None empty = ' ' , ' \\t ' if start == len ( lines ) - 1 or lines [ start + 1 ][: 1 ] not in empty : return start , start + 1 end = first ( i for i , o in enumerate ( lines [ start + 1 :]) if o [: 1 ] not in empty ) return start , len ( lines ) if end is None else ( end + start + 1 )","title":"find_var()"},{"location":"nbdev_api/nbdev/maker/#nbdev.maker.read_var","text":"Eval and return the value of varname defined in code Source code in nbdev/maker.py def read_var ( code , varname ): \"Eval and return the value of `varname` defined in `code`\" lines = code . splitlines () start , end = find_var ( lines , varname ) if start is None : return None res = [ lines [ start ] . split ( '=' )[ - 1 ] . strip ()] res += lines [ start + 1 : end ] try : return eval ( ' \\n ' . join ( res )) except SyntaxError : raise Exception ( ' \\n ' . join ( res )) from None","title":"read_var()"},{"location":"nbdev_api/nbdev/maker/#nbdev.maker.relative_import","text":"Convert a module name to a name relative to fname Source code in nbdev/maker.py def relative_import ( name , fname , level = 0 ): \"Convert a module `name` to a name relative to `fname`\" assert not level sname = name . replace ( '.' , '/' ) if not ( os . path . commonpath ([ sname , fname ])): return name rel = os . path . relpath ( sname , fname ) if rel == \".\" : return \".\" res = rel . replace ( f \".. { os . path . sep } \" , \".\" ) if not all ( o == '.' for o in res ): res = '.' + res return res . replace ( os . path . sep , \".\" )","title":"relative_import()"},{"location":"nbdev_api/nbdev/maker/#nbdev.maker.update_var","text":"Update the definition of varname in file fn , by calling func with the current definition Source code in nbdev/maker.py def update_var ( varname , func , fn = None , code = None ): \"Update the definition of `varname` in file `fn`, by calling `func` with the current definition\" if fn : fn = Path ( fn ) code = fn . read_text () lines = code . splitlines () v = read_var ( code , varname ) res = func ( v ) start , end = find_var ( lines , varname ) del ( lines [ start : end ]) lines . insert ( start , f \" { varname } = { res } \" ) code = ' \\n ' . join ( lines ) if fn : fn . write_text ( code ) else : return code","title":"update_var()"},{"location":"nbdev_api/nbdev/merge/","text":"nbdev_fix ( nbname , outname = None , nobackup = True , theirs = False , noprint = False ) \u00a4 Create working notebook from conflicted notebook nbname Source code in nbdev/merge.py @call_parse def nbdev_fix ( nbname : str , # Notebook filename to fix outname : str = None , # Filename of output notebook (defaults to `nbname`) nobackup : bool_arg = True , # Do not backup `nbname` to `nbname`.bak if `outname` not provided theirs : bool = False , # Use their outputs and metadata instead of ours noprint : bool = False ): # Do not print info about whether conflicts are found \"Create working notebook from conflicted notebook `nbname`\" nbname = Path ( nbname ) if not nobackup and not outname : shutil . copy ( nbname , nbname . with_suffix ( '.ipynb.bak' )) nbtxt = nbname . read_text () a , b , branch1 , branch2 = unpatch ( nbtxt ) ac , bc = dict2nb ( loads ( a )), dict2nb ( loads ( b )) dest = bc if theirs else ac cells , conflict = _merge_cells ( ac . cells , bc . cells , branch1 , branch2 , theirs = theirs ) dest . cells = cells write_nb ( dest , ifnone ( outname , nbname )) if not noprint : if conflict : print ( \"One or more conflict remains in the notebook, please inspect manually.\" ) else : print ( \"Successfully merged conflicts!\" ) return conflict nbdev_merge ( base , ours , theirs , path ) \u00a4 Git merge driver for notebooks Source code in nbdev/merge.py @call_parse def nbdev_merge ( base : str , ours : str , theirs : str , path : str ): \"Git merge driver for notebooks\" if not _git_merge_file ( base , ours , theirs ) . returncode : return theirs = str2bool ( os . environ . get ( 'THEIRS' , False )) return nbdev_fix . __wrapped__ ( ours , theirs = theirs ) unpatch ( s ) \u00a4 Takes a string with conflict markers and returns the two original files, and their branch names Source code in nbdev/merge.py def unpatch ( s : str ): \"Takes a string with conflict markers and returns the two original files, and their branch names\" * main , last = conf_re . split ( s ) r1 , r2 , c1b , c2b = [],[], None , None for before , c1_branch , c1 , c2 , c2_branch in chunked ( main , 5 ): c1b = _unpatch_f ( before , c1b , c1_branch , c1 , r1 ) c2b = _unpatch_f ( before , c2b , c2_branch , c2 , r2 ) return '' . join ( r1 + [ last ]), '' . join ( r2 + [ last ]), c1b , c2b","title":"nbdev.merge"},{"location":"nbdev_api/nbdev/merge/#nbdev.merge.nbdev_fix","text":"Create working notebook from conflicted notebook nbname Source code in nbdev/merge.py @call_parse def nbdev_fix ( nbname : str , # Notebook filename to fix outname : str = None , # Filename of output notebook (defaults to `nbname`) nobackup : bool_arg = True , # Do not backup `nbname` to `nbname`.bak if `outname` not provided theirs : bool = False , # Use their outputs and metadata instead of ours noprint : bool = False ): # Do not print info about whether conflicts are found \"Create working notebook from conflicted notebook `nbname`\" nbname = Path ( nbname ) if not nobackup and not outname : shutil . copy ( nbname , nbname . with_suffix ( '.ipynb.bak' )) nbtxt = nbname . read_text () a , b , branch1 , branch2 = unpatch ( nbtxt ) ac , bc = dict2nb ( loads ( a )), dict2nb ( loads ( b )) dest = bc if theirs else ac cells , conflict = _merge_cells ( ac . cells , bc . cells , branch1 , branch2 , theirs = theirs ) dest . cells = cells write_nb ( dest , ifnone ( outname , nbname )) if not noprint : if conflict : print ( \"One or more conflict remains in the notebook, please inspect manually.\" ) else : print ( \"Successfully merged conflicts!\" ) return conflict","title":"nbdev_fix()"},{"location":"nbdev_api/nbdev/merge/#nbdev.merge.nbdev_merge","text":"Git merge driver for notebooks Source code in nbdev/merge.py @call_parse def nbdev_merge ( base : str , ours : str , theirs : str , path : str ): \"Git merge driver for notebooks\" if not _git_merge_file ( base , ours , theirs ) . returncode : return theirs = str2bool ( os . environ . get ( 'THEIRS' , False )) return nbdev_fix . __wrapped__ ( ours , theirs = theirs )","title":"nbdev_merge()"},{"location":"nbdev_api/nbdev/merge/#nbdev.merge.unpatch","text":"Takes a string with conflict markers and returns the two original files, and their branch names Source code in nbdev/merge.py def unpatch ( s : str ): \"Takes a string with conflict markers and returns the two original files, and their branch names\" * main , last = conf_re . split ( s ) r1 , r2 , c1b , c2b = [],[], None , None for before , c1_branch , c1 , c2 , c2_branch in chunked ( main , 5 ): c1b = _unpatch_f ( before , c1b , c1_branch , c1 , r1 ) c2b = _unpatch_f ( before , c2b , c2_branch , c2 , r2 ) return '' . join ( r1 + [ last ]), '' . join ( r2 + [ last ]), c1b , c2b","title":"unpatch()"},{"location":"nbdev_api/nbdev/migrate/","text":"MigrateProc ( Processor ) \u00a4 Migrate fastpages front matter in notebooks to a raw cell. Source code in nbdev/migrate.py class MigrateProc ( Processor ): \"Migrate fastpages front matter in notebooks to a raw cell.\" def begin ( self ): self . nb . frontmatter_ = _fp_convert ( self . nb . frontmatter_ , self . nb . path_ ) if getattr ( first ( self . nb . cells ), 'cell_type' , None ) == 'raw' : del self . nb . cells [ 0 ] _insertfm ( self . nb , self . nb . frontmatter_ ) fp_md_fm ( path ) \u00a4 Make fastpages front matter in markdown files quarto compliant. Source code in nbdev/migrate.py def fp_md_fm ( path ): \"Make fastpages front matter in markdown files quarto compliant.\" p = Path ( path ) md = p . read_text () fm = _fm2dict ( md , nb = False ) if fm : fm = _fp_convert ( fm , path ) return _re_fm_md . sub ( _dict2fm ( fm ), md ) else : return md migrate_md ( path , overwrite = True ) \u00a4 Migrate Markdown Files from fastpages. Source code in nbdev/migrate.py def migrate_md ( path , overwrite = True ): \"Migrate Markdown Files from fastpages.\" txt = fp_md_fm ( path ) if overwrite : path . write_text ( txt ) return txt migrate_nb ( path , overwrite = True ) \u00a4 Migrate Notebooks from nbdev v1 and fastpages. Source code in nbdev/migrate.py def migrate_nb ( path , overwrite = True ): \"Migrate Notebooks from nbdev v1 and fastpages.\" nbp = NBProcessor ( path , procs = [ FrontmatterProc , MigrateProc , _repl_v1shortcuts , _repl_v1dir ], rm_directives = False ) nbp . process () if overwrite : write_nb ( nbp . nb , path ) return nbp . nb nbdev_migrate ( path = None , no_skip = False ) \u00a4 Convert all markdown and notebook files in path from v1 to v2 Source code in nbdev/migrate.py @call_parse def nbdev_migrate ( path : str = None , # A path or glob containing notebooks and markdown files to migrate no_skip : bool = False , # Do not skip directories beginning with an underscore ): \"Convert all markdown and notebook files in `path` from v1 to v2\" _skip_re = None if no_skip else '^[_.]' if path is None : path = get_config () . nbs_path for f in globtastic ( path , file_re = '(.ipynb$)|(.md$)' , skip_folder_re = _skip_re , func = Path ): try : if f . name . endswith ( '.ipynb' ): migrate_nb ( f ) if f . name . endswith ( '.md' ): migrate_md ( f ) except Exception as e : raise Exception ( f 'Error in migrating file: { f } ' ) from e","title":"nbdev.migrate"},{"location":"nbdev_api/nbdev/migrate/#nbdev.migrate.MigrateProc","text":"Migrate fastpages front matter in notebooks to a raw cell. Source code in nbdev/migrate.py class MigrateProc ( Processor ): \"Migrate fastpages front matter in notebooks to a raw cell.\" def begin ( self ): self . nb . frontmatter_ = _fp_convert ( self . nb . frontmatter_ , self . nb . path_ ) if getattr ( first ( self . nb . cells ), 'cell_type' , None ) == 'raw' : del self . nb . cells [ 0 ] _insertfm ( self . nb , self . nb . frontmatter_ )","title":"MigrateProc"},{"location":"nbdev_api/nbdev/migrate/#nbdev.migrate.fp_md_fm","text":"Make fastpages front matter in markdown files quarto compliant. Source code in nbdev/migrate.py def fp_md_fm ( path ): \"Make fastpages front matter in markdown files quarto compliant.\" p = Path ( path ) md = p . read_text () fm = _fm2dict ( md , nb = False ) if fm : fm = _fp_convert ( fm , path ) return _re_fm_md . sub ( _dict2fm ( fm ), md ) else : return md","title":"fp_md_fm()"},{"location":"nbdev_api/nbdev/migrate/#nbdev.migrate.migrate_md","text":"Migrate Markdown Files from fastpages. Source code in nbdev/migrate.py def migrate_md ( path , overwrite = True ): \"Migrate Markdown Files from fastpages.\" txt = fp_md_fm ( path ) if overwrite : path . write_text ( txt ) return txt","title":"migrate_md()"},{"location":"nbdev_api/nbdev/migrate/#nbdev.migrate.migrate_nb","text":"Migrate Notebooks from nbdev v1 and fastpages. Source code in nbdev/migrate.py def migrate_nb ( path , overwrite = True ): \"Migrate Notebooks from nbdev v1 and fastpages.\" nbp = NBProcessor ( path , procs = [ FrontmatterProc , MigrateProc , _repl_v1shortcuts , _repl_v1dir ], rm_directives = False ) nbp . process () if overwrite : write_nb ( nbp . nb , path ) return nbp . nb","title":"migrate_nb()"},{"location":"nbdev_api/nbdev/migrate/#nbdev.migrate.nbdev_migrate","text":"Convert all markdown and notebook files in path from v1 to v2 Source code in nbdev/migrate.py @call_parse def nbdev_migrate ( path : str = None , # A path or glob containing notebooks and markdown files to migrate no_skip : bool = False , # Do not skip directories beginning with an underscore ): \"Convert all markdown and notebook files in `path` from v1 to v2\" _skip_re = None if no_skip else '^[_.]' if path is None : path = get_config () . nbs_path for f in globtastic ( path , file_re = '(.ipynb$)|(.md$)' , skip_folder_re = _skip_re , func = Path ): try : if f . name . endswith ( '.ipynb' ): migrate_nb ( f ) if f . name . endswith ( '.md' ): migrate_md ( f ) except Exception as e : raise Exception ( f 'Error in migrating file: { f } ' ) from e","title":"nbdev_migrate()"},{"location":"nbdev_api/nbdev/process/","text":"NBProcessor \u00a4 Process cells and nbdev comments in a notebook Source code in nbdev/process.py class NBProcessor : \"Process cells and nbdev comments in a notebook\" def __init__ ( self , path = None , procs = None , nb = None , debug = False , rm_directives = True , process = False ): self . nb = read_nb ( path ) if nb is None else nb self . lang = nb_lang ( self . nb ) for cell in self . nb . cells : cell . directives_ = extract_directives ( cell , remove = rm_directives , lang = self . lang ) self . procs = _mk_procs ( procs , nb = self . nb ) self . debug , self . rm_directives = debug , rm_directives if process : self . process () def _process_cell ( self , proc , cell ): if not hasattr ( cell , 'source' ): return if cell . cell_type == 'code' and cell . directives_ : # Option 1: `proc` is directive name with `_` suffix f = getattr ( proc , '__name__' , '-' ) . rstrip ( '_' ) if f in cell . directives_ : self . _process_comment ( proc , cell , f ) # Option 2: `proc` contains a method named `_{directive}_` for cmd in cell . directives_ : f = getattr ( proc , f '_ { cmd } _' , None ) if f : self . _process_comment ( f , cell , cmd ) if callable ( proc ) and not _is_direc ( proc ): cell = opt_set ( cell , proc ( cell )) def _process_comment ( self , proc , cell , cmd ): args = cell . directives_ [ cmd ] if self . debug : print ( cmd , args , proc ) return proc ( cell , * args ) def _proc ( self , proc ): if hasattr ( proc , 'begin' ): proc . begin () for cell in self . nb . cells : self . _process_cell ( proc , cell ) if hasattr ( proc , 'end' ): proc . end () self . nb . cells = [ c for c in self . nb . cells if c and getattr ( c , 'source' , None ) is not None ] for i , cell in enumerate ( self . nb . cells ): cell . idx_ = i def process ( self ): \"Process all cells with all processors\" for proc in self . procs : self . _proc ( proc ) process ( self ) \u00a4 Process all cells with all processors Source code in nbdev/process.py def process ( self ): \"Process all cells with all processors\" for proc in self . procs : self . _proc ( proc ) Processor \u00a4 Base class for processors Source code in nbdev/process.py class Processor : \"Base class for processors\" def __init__ ( self , nb ): self . nb = nb def cell ( self , cell ): pass def __call__ ( self , cell ): return self . cell ( cell ) extract_directives ( cell , remove = True , lang = 'python' ) \u00a4 Take leading comment directives from lines of code in ss , remove #| , and split Source code in nbdev/process.py def extract_directives ( cell , remove = True , lang = 'python' ): \"Take leading comment directives from lines of code in `ss`, remove `#|`, and split\" dirs , code = _partition_cell ( cell , lang ) if not dirs : return {} if remove : # Leave Quarto directives and cell magic in place for later processing cell [ 'source' ] = '' . join ([ _norm_quarto ( o , lang ) for o in dirs if _quarto_re ( lang ) . match ( o ) or _cell_mgc . match ( o )] + code ) return dict ( L ( _directive ( s , lang ) for s in dirs ) . filter ()) first_code_ln ( code_list , re_pattern = None , lang = 'python' ) \u00a4 get first line number where code occurs, where code_list is a list of code Source code in nbdev/process.py def first_code_ln ( code_list , re_pattern = None , lang = 'python' ): \"get first line number where code occurs, where `code_list` is a list of code\" if re_pattern is None : re_pattern = _dir_pre ( lang ) return first ( i for i , o in enumerate ( code_list ) if o . strip () != '' and not re . match ( re_pattern , o ) and not _cell_mgc . match ( o )) instantiate ( x , ** kwargs ) \u00a4 Instantiate x if it's a type Source code in nbdev/process.py def instantiate ( x , ** kwargs ): \"Instantiate `x` if it's a type\" return x ( ** kwargs ) if isinstance ( x , type ) else x opt_set ( var , newval ) \u00a4 newval if newval else var Source code in nbdev/process.py def opt_set ( var , newval ): \"newval if newval else var\" return newval if newval else var","title":"nbdev.process"},{"location":"nbdev_api/nbdev/process/#nbdev.process.NBProcessor","text":"Process cells and nbdev comments in a notebook Source code in nbdev/process.py class NBProcessor : \"Process cells and nbdev comments in a notebook\" def __init__ ( self , path = None , procs = None , nb = None , debug = False , rm_directives = True , process = False ): self . nb = read_nb ( path ) if nb is None else nb self . lang = nb_lang ( self . nb ) for cell in self . nb . cells : cell . directives_ = extract_directives ( cell , remove = rm_directives , lang = self . lang ) self . procs = _mk_procs ( procs , nb = self . nb ) self . debug , self . rm_directives = debug , rm_directives if process : self . process () def _process_cell ( self , proc , cell ): if not hasattr ( cell , 'source' ): return if cell . cell_type == 'code' and cell . directives_ : # Option 1: `proc` is directive name with `_` suffix f = getattr ( proc , '__name__' , '-' ) . rstrip ( '_' ) if f in cell . directives_ : self . _process_comment ( proc , cell , f ) # Option 2: `proc` contains a method named `_{directive}_` for cmd in cell . directives_ : f = getattr ( proc , f '_ { cmd } _' , None ) if f : self . _process_comment ( f , cell , cmd ) if callable ( proc ) and not _is_direc ( proc ): cell = opt_set ( cell , proc ( cell )) def _process_comment ( self , proc , cell , cmd ): args = cell . directives_ [ cmd ] if self . debug : print ( cmd , args , proc ) return proc ( cell , * args ) def _proc ( self , proc ): if hasattr ( proc , 'begin' ): proc . begin () for cell in self . nb . cells : self . _process_cell ( proc , cell ) if hasattr ( proc , 'end' ): proc . end () self . nb . cells = [ c for c in self . nb . cells if c and getattr ( c , 'source' , None ) is not None ] for i , cell in enumerate ( self . nb . cells ): cell . idx_ = i def process ( self ): \"Process all cells with all processors\" for proc in self . procs : self . _proc ( proc )","title":"NBProcessor"},{"location":"nbdev_api/nbdev/process/#nbdev.process.NBProcessor.process","text":"Process all cells with all processors Source code in nbdev/process.py def process ( self ): \"Process all cells with all processors\" for proc in self . procs : self . _proc ( proc )","title":"process()"},{"location":"nbdev_api/nbdev/process/#nbdev.process.Processor","text":"Base class for processors Source code in nbdev/process.py class Processor : \"Base class for processors\" def __init__ ( self , nb ): self . nb = nb def cell ( self , cell ): pass def __call__ ( self , cell ): return self . cell ( cell )","title":"Processor"},{"location":"nbdev_api/nbdev/process/#nbdev.process.extract_directives","text":"Take leading comment directives from lines of code in ss , remove #| , and split Source code in nbdev/process.py def extract_directives ( cell , remove = True , lang = 'python' ): \"Take leading comment directives from lines of code in `ss`, remove `#|`, and split\" dirs , code = _partition_cell ( cell , lang ) if not dirs : return {} if remove : # Leave Quarto directives and cell magic in place for later processing cell [ 'source' ] = '' . join ([ _norm_quarto ( o , lang ) for o in dirs if _quarto_re ( lang ) . match ( o ) or _cell_mgc . match ( o )] + code ) return dict ( L ( _directive ( s , lang ) for s in dirs ) . filter ())","title":"extract_directives()"},{"location":"nbdev_api/nbdev/process/#nbdev.process.first_code_ln","text":"get first line number where code occurs, where code_list is a list of code Source code in nbdev/process.py def first_code_ln ( code_list , re_pattern = None , lang = 'python' ): \"get first line number where code occurs, where `code_list` is a list of code\" if re_pattern is None : re_pattern = _dir_pre ( lang ) return first ( i for i , o in enumerate ( code_list ) if o . strip () != '' and not re . match ( re_pattern , o ) and not _cell_mgc . match ( o ))","title":"first_code_ln()"},{"location":"nbdev_api/nbdev/process/#nbdev.process.instantiate","text":"Instantiate x if it's a type Source code in nbdev/process.py def instantiate ( x , ** kwargs ): \"Instantiate `x` if it's a type\" return x ( ** kwargs ) if isinstance ( x , type ) else x","title":"instantiate()"},{"location":"nbdev_api/nbdev/process/#nbdev.process.opt_set","text":"newval if newval else var Source code in nbdev/process.py def opt_set ( var , newval ): \"newval if newval else var\" return newval if newval else var","title":"opt_set()"},{"location":"nbdev_api/nbdev/processors/","text":"FilterDefaults \u00a4 Override FilterDefaults to change which notebook processors are used Source code in nbdev/processors.py class FilterDefaults : \"Override `FilterDefaults` to change which notebook processors are used\" def xtra_procs ( self ): imps = get_config () . get ( 'procs' , '' ) . split () return [ _import_obj ( o ) for o in imps ] def base_procs ( self ): return [ FrontmatterProc , populate_language , add_show_docs , insert_warning , strip_ansi , hide_line , filter_stream_ , rm_header_dash , clean_show_doc , exec_show_docs , rm_export , clean_magics , hide_ , add_links , strip_hidden_metadata ] def procs ( self ): \"Processors for export\" return self . base_procs () + self . xtra_procs () def nb_proc ( self , nb ): \"Get an `NBProcessor` with these processors\" return NBProcessor ( nb = nb , procs = self . procs ()) def __call__ ( self , nb ): return self . nb_proc ( nb ) . process () nb_proc ( self , nb ) \u00a4 Get an NBProcessor with these processors Source code in nbdev/processors.py def nb_proc ( self , nb ): \"Get an `NBProcessor` with these processors\" return NBProcessor ( nb = nb , procs = self . procs ()) procs ( self ) \u00a4 Processors for export Source code in nbdev/processors.py def procs ( self ): \"Processors for export\" return self . base_procs () + self . xtra_procs () add_show_docs ( Processor ) \u00a4 Add show_doc cells after exported cells, unless they are already documented Source code in nbdev/processors.py class add_show_docs ( Processor ): \"Add show_doc cells after exported cells, unless they are already documented\" def begin ( self ): nb = self . nb exports = L ( cell for cell in nb . cells if _want_doc ( cell )) trees = L ( nb . cells ) . map ( NbCell . parsed_ ) . concat () shown_docs = { _get_nm ( t ) for t in _show_docs ( trees )} for cell in reversed ( exports ): if cell_lang ( cell ) != 'python' : raise ValueError ( f \" { cell . metadata . language } can't export: \\n { cell . source } \" ) for nm in _def_names ( cell , shown_docs ): nb . cells . insert ( cell . idx_ + 1 , mk_cell ( f 'show_doc( { nm } )' )) nb . has_docs_ = shown_docs or exports exec_show_docs ( Processor ) \u00a4 Execute cells needed for show_docs output, including exported cells and imports Source code in nbdev/processors.py class exec_show_docs ( Processor ): \"Execute cells needed for `show_docs` output, including exported cells and imports\" def begin ( self ): if nb_lang ( self . nb ) != 'python' : return self . k = CaptureShell () self . k . run_cell ( 'from nbdev.showdoc import show_doc' ) def __call__ ( self , cell ): if not self . nb . has_docs_ or not hasattr ( self , 'k' ): return fm = getattr ( self . nb , 'frontmatter_' , {}) if str2bool ( fm . get ( 'skip_showdoc' , False )): return if _do_eval ( cell ): self . k . cell ( cell ) title = fm . get ( 'title' , '' ) if self . k . exc : raise Exception ( f \"Error { ' in notebook: ' + title if title else '' } in cell { cell . idx_ } : \\n { cell . source } \" ) from self.k.exc [ 1 ] def end ( self ): try : from ipywidgets import Widget except ImportError : pass else : mimetype = 'application/vnd.jupyter.widget-state+json' old = nested_idx ( self . nb . metadata , 'widgets' , mimetype ) or { 'state' : {}} new = Widget . get_manager_state ( drop_defaults = True ) widgets = { ** old , ** new , 'state' : { ** old . get ( 'state' , {}), ** new [ 'state' ]}} self . nb . metadata [ 'widgets' ] = { mimetype : widgets } insert_warning ( Processor ) \u00a4 Insert Autogenerated Warning Into Notebook after the first cell. Source code in nbdev/processors.py class insert_warning ( Processor ): \"Insert Autogenerated Warning Into Notebook after the first cell.\" content = \"<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->\" def begin ( self ): self . nb . cells . insert ( 1 , mk_cell ( self . content , 'markdown' )) populate_language ( Processor ) \u00a4 Set cell language based on NB metadata and magics Source code in nbdev/processors.py class populate_language ( Processor ): \"Set cell language based on NB metadata and magics\" def begin ( self ): self . language = nb_lang ( self . nb ) def cell ( self , cell ): if cell . cell_type != 'code' : return lang = _lang_pattern . findall ( cell . source ) if lang : cell . metadata . language = lang [ 0 ] else : cell . metadata . language = self . language add_links ( cell ) \u00a4 Add links to markdown cells Source code in nbdev/processors.py def add_links ( cell ): \"Add links to markdown cells\" nl = NbdevLookup () if cell . cell_type == 'markdown' : cell . source = nl . linkify ( cell . source ) for o in cell . get ( 'outputs' , []): if hasattr ( o , 'data' ) and hasattr ( o [ 'data' ], 'text/markdown' ): o . data [ 'text/markdown' ] = [ nl . link_line ( s ) for s in o . data [ 'text/markdown' ]] clean_magics ( cell ) \u00a4 A preprocessor to remove cell magic commands Source code in nbdev/processors.py def clean_magics ( cell ): \"A preprocessor to remove cell magic commands\" if cell . cell_type == 'code' : cell . source = _magics_pattern . sub ( '' , cell . source ) . strip () clean_show_doc ( cell ) \u00a4 Remove ShowDoc input cells Source code in nbdev/processors.py def clean_show_doc ( cell ): \"Remove ShowDoc input cells\" if not _is_showdoc ( cell ): return _add_directives ( cell , { 'output' : 'asis' , 'echo' : 'false' }) filter_stream_ ( cell , * words ) \u00a4 Remove output lines containing any of words in cell stream output Source code in nbdev/processors.py def filter_stream_ ( cell , * words ): \"Remove output lines containing any of `words` in `cell` stream output\" if not words : return for outp in cell . get ( 'outputs' , []): if outp . output_type == 'stream' : outp [ 'text' ] = [ l for l in outp . text if not re . search ( '|' . join ( words ), l )] hide_ ( cell ) \u00a4 Hide cell from output Source code in nbdev/processors.py def hide_ ( cell ): \"Hide cell from output\" del ( cell [ 'source' ]) hide_line ( cell ) \u00a4 Hide lines of code in code cells with the directive hide_line at the end of a line of code Source code in nbdev/processors.py def hide_line ( cell ): \"Hide lines of code in code cells with the directive `hide_line` at the end of a line of code\" lang = cell_lang ( cell ) if cell . cell_type == 'code' and _re_hideline ( lang ) . search ( cell . source ): cell . source = ' \\n ' . join ([ c for c in cell . source . splitlines () if not _re_hideline ( lang ) . search ( c )]) rm_export ( cell ) \u00a4 Remove cells that are exported or hidden Source code in nbdev/processors.py def rm_export ( cell ): \"Remove cells that are exported or hidden\" if cell . directives_ and ( cell . directives_ . keys () & _hide_dirs ): del ( cell [ 'source' ]) rm_header_dash ( cell ) \u00a4 Remove headings that end with a dash - Source code in nbdev/processors.py def rm_header_dash ( cell ): \"Remove headings that end with a dash -\" if cell . source : src = cell . source . strip () if cell . cell_type == 'markdown' and src . startswith ( '#' ) and src . endswith ( ' -' ): del ( cell [ 'source' ]) strip_ansi ( cell ) \u00a4 Strip Ansi Characters. Source code in nbdev/processors.py def strip_ansi ( cell ): \"Strip Ansi Characters.\" for outp in cell . get ( 'outputs' , []): if outp . get ( 'name' ) == 'stdout' : outp [ 'text' ] = [ _re_ansi_escape . sub ( '' , o ) for o in outp . text ] strip_hidden_metadata ( cell ) \u00a4 Strips \"hidden\" metadata property from code cells so it doesn't interfere with docs rendering Source code in nbdev/processors.py def strip_hidden_metadata ( cell ): '''Strips \"hidden\" metadata property from code cells so it doesn't interfere with docs rendering''' if cell . cell_type == 'code' and 'metadata' in cell : cell . metadata . pop ( 'hidden' , None )","title":"nbdev.processors"},{"location":"nbdev_api/nbdev/processors/#nbdev.processors.FilterDefaults","text":"Override FilterDefaults to change which notebook processors are used Source code in nbdev/processors.py class FilterDefaults : \"Override `FilterDefaults` to change which notebook processors are used\" def xtra_procs ( self ): imps = get_config () . get ( 'procs' , '' ) . split () return [ _import_obj ( o ) for o in imps ] def base_procs ( self ): return [ FrontmatterProc , populate_language , add_show_docs , insert_warning , strip_ansi , hide_line , filter_stream_ , rm_header_dash , clean_show_doc , exec_show_docs , rm_export , clean_magics , hide_ , add_links , strip_hidden_metadata ] def procs ( self ): \"Processors for export\" return self . base_procs () + self . xtra_procs () def nb_proc ( self , nb ): \"Get an `NBProcessor` with these processors\" return NBProcessor ( nb = nb , procs = self . procs ()) def __call__ ( self , nb ): return self . nb_proc ( nb ) . process ()","title":"FilterDefaults"},{"location":"nbdev_api/nbdev/processors/#nbdev.processors.FilterDefaults.nb_proc","text":"Get an NBProcessor with these processors Source code in nbdev/processors.py def nb_proc ( self , nb ): \"Get an `NBProcessor` with these processors\" return NBProcessor ( nb = nb , procs = self . procs ())","title":"nb_proc()"},{"location":"nbdev_api/nbdev/processors/#nbdev.processors.FilterDefaults.procs","text":"Processors for export Source code in nbdev/processors.py def procs ( self ): \"Processors for export\" return self . base_procs () + self . xtra_procs ()","title":"procs()"},{"location":"nbdev_api/nbdev/processors/#nbdev.processors.add_show_docs","text":"Add show_doc cells after exported cells, unless they are already documented Source code in nbdev/processors.py class add_show_docs ( Processor ): \"Add show_doc cells after exported cells, unless they are already documented\" def begin ( self ): nb = self . nb exports = L ( cell for cell in nb . cells if _want_doc ( cell )) trees = L ( nb . cells ) . map ( NbCell . parsed_ ) . concat () shown_docs = { _get_nm ( t ) for t in _show_docs ( trees )} for cell in reversed ( exports ): if cell_lang ( cell ) != 'python' : raise ValueError ( f \" { cell . metadata . language } can't export: \\n { cell . source } \" ) for nm in _def_names ( cell , shown_docs ): nb . cells . insert ( cell . idx_ + 1 , mk_cell ( f 'show_doc( { nm } )' )) nb . has_docs_ = shown_docs or exports","title":"add_show_docs"},{"location":"nbdev_api/nbdev/processors/#nbdev.processors.exec_show_docs","text":"Execute cells needed for show_docs output, including exported cells and imports Source code in nbdev/processors.py class exec_show_docs ( Processor ): \"Execute cells needed for `show_docs` output, including exported cells and imports\" def begin ( self ): if nb_lang ( self . nb ) != 'python' : return self . k = CaptureShell () self . k . run_cell ( 'from nbdev.showdoc import show_doc' ) def __call__ ( self , cell ): if not self . nb . has_docs_ or not hasattr ( self , 'k' ): return fm = getattr ( self . nb , 'frontmatter_' , {}) if str2bool ( fm . get ( 'skip_showdoc' , False )): return if _do_eval ( cell ): self . k . cell ( cell ) title = fm . get ( 'title' , '' ) if self . k . exc : raise Exception ( f \"Error { ' in notebook: ' + title if title else '' } in cell { cell . idx_ } : \\n { cell . source } \" ) from self.k.exc [ 1 ] def end ( self ): try : from ipywidgets import Widget except ImportError : pass else : mimetype = 'application/vnd.jupyter.widget-state+json' old = nested_idx ( self . nb . metadata , 'widgets' , mimetype ) or { 'state' : {}} new = Widget . get_manager_state ( drop_defaults = True ) widgets = { ** old , ** new , 'state' : { ** old . get ( 'state' , {}), ** new [ 'state' ]}} self . nb . metadata [ 'widgets' ] = { mimetype : widgets }","title":"exec_show_docs"},{"location":"nbdev_api/nbdev/processors/#nbdev.processors.insert_warning","text":"Insert Autogenerated Warning Into Notebook after the first cell. Source code in nbdev/processors.py class insert_warning ( Processor ): \"Insert Autogenerated Warning Into Notebook after the first cell.\" content = \"<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->\" def begin ( self ): self . nb . cells . insert ( 1 , mk_cell ( self . content , 'markdown' ))","title":"insert_warning"},{"location":"nbdev_api/nbdev/processors/#nbdev.processors.populate_language","text":"Set cell language based on NB metadata and magics Source code in nbdev/processors.py class populate_language ( Processor ): \"Set cell language based on NB metadata and magics\" def begin ( self ): self . language = nb_lang ( self . nb ) def cell ( self , cell ): if cell . cell_type != 'code' : return lang = _lang_pattern . findall ( cell . source ) if lang : cell . metadata . language = lang [ 0 ] else : cell . metadata . language = self . language","title":"populate_language"},{"location":"nbdev_api/nbdev/processors/#nbdev.processors.add_links","text":"Add links to markdown cells Source code in nbdev/processors.py def add_links ( cell ): \"Add links to markdown cells\" nl = NbdevLookup () if cell . cell_type == 'markdown' : cell . source = nl . linkify ( cell . source ) for o in cell . get ( 'outputs' , []): if hasattr ( o , 'data' ) and hasattr ( o [ 'data' ], 'text/markdown' ): o . data [ 'text/markdown' ] = [ nl . link_line ( s ) for s in o . data [ 'text/markdown' ]]","title":"add_links()"},{"location":"nbdev_api/nbdev/processors/#nbdev.processors.clean_magics","text":"A preprocessor to remove cell magic commands Source code in nbdev/processors.py def clean_magics ( cell ): \"A preprocessor to remove cell magic commands\" if cell . cell_type == 'code' : cell . source = _magics_pattern . sub ( '' , cell . source ) . strip ()","title":"clean_magics()"},{"location":"nbdev_api/nbdev/processors/#nbdev.processors.clean_show_doc","text":"Remove ShowDoc input cells Source code in nbdev/processors.py def clean_show_doc ( cell ): \"Remove ShowDoc input cells\" if not _is_showdoc ( cell ): return _add_directives ( cell , { 'output' : 'asis' , 'echo' : 'false' })","title":"clean_show_doc()"},{"location":"nbdev_api/nbdev/processors/#nbdev.processors.filter_stream_","text":"Remove output lines containing any of words in cell stream output Source code in nbdev/processors.py def filter_stream_ ( cell , * words ): \"Remove output lines containing any of `words` in `cell` stream output\" if not words : return for outp in cell . get ( 'outputs' , []): if outp . output_type == 'stream' : outp [ 'text' ] = [ l for l in outp . text if not re . search ( '|' . join ( words ), l )]","title":"filter_stream_()"},{"location":"nbdev_api/nbdev/processors/#nbdev.processors.hide_","text":"Hide cell from output Source code in nbdev/processors.py def hide_ ( cell ): \"Hide cell from output\" del ( cell [ 'source' ])","title":"hide_()"},{"location":"nbdev_api/nbdev/processors/#nbdev.processors.hide_line","text":"Hide lines of code in code cells with the directive hide_line at the end of a line of code Source code in nbdev/processors.py def hide_line ( cell ): \"Hide lines of code in code cells with the directive `hide_line` at the end of a line of code\" lang = cell_lang ( cell ) if cell . cell_type == 'code' and _re_hideline ( lang ) . search ( cell . source ): cell . source = ' \\n ' . join ([ c for c in cell . source . splitlines () if not _re_hideline ( lang ) . search ( c )])","title":"hide_line()"},{"location":"nbdev_api/nbdev/processors/#nbdev.processors.rm_export","text":"Remove cells that are exported or hidden Source code in nbdev/processors.py def rm_export ( cell ): \"Remove cells that are exported or hidden\" if cell . directives_ and ( cell . directives_ . keys () & _hide_dirs ): del ( cell [ 'source' ])","title":"rm_export()"},{"location":"nbdev_api/nbdev/processors/#nbdev.processors.rm_header_dash","text":"Remove headings that end with a dash - Source code in nbdev/processors.py def rm_header_dash ( cell ): \"Remove headings that end with a dash -\" if cell . source : src = cell . source . strip () if cell . cell_type == 'markdown' and src . startswith ( '#' ) and src . endswith ( ' -' ): del ( cell [ 'source' ])","title":"rm_header_dash()"},{"location":"nbdev_api/nbdev/processors/#nbdev.processors.strip_ansi","text":"Strip Ansi Characters. Source code in nbdev/processors.py def strip_ansi ( cell ): \"Strip Ansi Characters.\" for outp in cell . get ( 'outputs' , []): if outp . get ( 'name' ) == 'stdout' : outp [ 'text' ] = [ _re_ansi_escape . sub ( '' , o ) for o in outp . text ]","title":"strip_ansi()"},{"location":"nbdev_api/nbdev/processors/#nbdev.processors.strip_hidden_metadata","text":"Strips \"hidden\" metadata property from code cells so it doesn't interfere with docs rendering Source code in nbdev/processors.py def strip_hidden_metadata ( cell ): '''Strips \"hidden\" metadata property from code cells so it doesn't interfere with docs rendering''' if cell . cell_type == 'code' and 'metadata' in cell : cell . metadata . pop ( 'hidden' , None )","title":"strip_hidden_metadata()"},{"location":"nbdev_api/nbdev/qmd/","text":"btn ( txt , link , classes = None , style = None , ** kwargs ) \u00a4 A qmd button Source code in nbdev/qmd.py def btn ( txt , # Button text link , # Button link URL classes = None , # List of CSS classes to add style = None , # Dict of CSS styles to add ** kwargs ): \"A qmd button\" return meta ( f '[ { txt } ]( { link } )' , classes = classes , style = style , role = \"button\" ) div ( txt , classes = None , style = None , ** kwargs ) \u00a4 A qmd div with optional metadata section Source code in nbdev/qmd.py def div ( txt , # Markdown to add meta to classes = None , # List of CSS classes to add style = None , # Dict of CSS styles to add ** kwargs ): \"A qmd div with optional metadata section\" return meta ( \"::: \" , classes = classes , style = style , ** kwargs ) + f \" \\n\\n { txt } \\n\\n ::: \\n\\n \" img ( fname , classes = None , style = None , height = None , relative = None , link = False , ** kwargs ) \u00a4 A qmd image Source code in nbdev/qmd.py def img ( fname , # Image to link to classes = None , # List of CSS classes to add style = None , # Dict of CSS styles to add height = None , # Height attribute relative = None , # Tuple of (position,px) link = False , # Hyperlink to this image ** kwargs ): \"A qmd image\" kwargs , style = kwargs or {}, style or {} if height : kwargs [ \"height\" ] = f \" { height } px\" if relative : pos , px = relative style [ \"position\" ] = \"relative\" style [ pos ] = f \" { px } px\" res = meta ( f '![]( { fname } )' , classes = classes , style = style , ** kwargs ) return f '[ { res } ]( { fname } )' if link else res meta ( md , classes = None , style = None , ** kwargs ) \u00a4 A metadata section for qmd div in {} Source code in nbdev/qmd.py def meta ( md , # Markdown to add meta to classes = None , # List of CSS classes to add style = None , # Dict of CSS styles to add ** kwargs ): # Additional attributes to add to meta \"A metadata section for qmd div in ` {} `\" if style : kwargs [ 'style' ] = \"; \" . join ( f ' { k } : { v } ' for k , v in style . items ()) props = ' ' . join ( f ' { k } =\" { v } \"' for k , v in kwargs . items ()) classes = ' ' . join ( '.' + c for c in L ( classes )) meta = [] if classes : meta . append ( classes ) if props : meta . append ( props ) meta = ' ' . join ( meta ) return md + ( \"{\" + meta + \"}\" if meta else \"\" ) tbl_row ( cols ) \u00a4 Create a markdown table row from cols Source code in nbdev/qmd.py def tbl_row ( cols : list , # Auto-stringified columns to show in the row ): \"Create a markdown table row from `cols`\" return '|' + '|' . join ( str ( c or '' ) for c in cols ) + '|' tbl_sep ( sizes = 3 ) \u00a4 Create a markdown table separator with relative column size sizes Source code in nbdev/qmd.py def tbl_sep ( sizes : int | list = 3 # List of column sizes, or single `int` if all sizes the same ): \"Create a markdown table separator with relative column size `sizes`\" if isinstance ( sizes , int ): sizes = [ 3 ] * sizes return tbl_row ( '-' * s for s in sizes )","title":"nbdev.qmd"},{"location":"nbdev_api/nbdev/qmd/#nbdev.qmd.btn","text":"A qmd button Source code in nbdev/qmd.py def btn ( txt , # Button text link , # Button link URL classes = None , # List of CSS classes to add style = None , # Dict of CSS styles to add ** kwargs ): \"A qmd button\" return meta ( f '[ { txt } ]( { link } )' , classes = classes , style = style , role = \"button\" )","title":"btn()"},{"location":"nbdev_api/nbdev/qmd/#nbdev.qmd.div","text":"A qmd div with optional metadata section Source code in nbdev/qmd.py def div ( txt , # Markdown to add meta to classes = None , # List of CSS classes to add style = None , # Dict of CSS styles to add ** kwargs ): \"A qmd div with optional metadata section\" return meta ( \"::: \" , classes = classes , style = style , ** kwargs ) + f \" \\n\\n { txt } \\n\\n ::: \\n\\n \"","title":"div()"},{"location":"nbdev_api/nbdev/qmd/#nbdev.qmd.img","text":"A qmd image Source code in nbdev/qmd.py def img ( fname , # Image to link to classes = None , # List of CSS classes to add style = None , # Dict of CSS styles to add height = None , # Height attribute relative = None , # Tuple of (position,px) link = False , # Hyperlink to this image ** kwargs ): \"A qmd image\" kwargs , style = kwargs or {}, style or {} if height : kwargs [ \"height\" ] = f \" { height } px\" if relative : pos , px = relative style [ \"position\" ] = \"relative\" style [ pos ] = f \" { px } px\" res = meta ( f '![]( { fname } )' , classes = classes , style = style , ** kwargs ) return f '[ { res } ]( { fname } )' if link else res","title":"img()"},{"location":"nbdev_api/nbdev/qmd/#nbdev.qmd.meta","text":"A metadata section for qmd div in {} Source code in nbdev/qmd.py def meta ( md , # Markdown to add meta to classes = None , # List of CSS classes to add style = None , # Dict of CSS styles to add ** kwargs ): # Additional attributes to add to meta \"A metadata section for qmd div in ` {} `\" if style : kwargs [ 'style' ] = \"; \" . join ( f ' { k } : { v } ' for k , v in style . items ()) props = ' ' . join ( f ' { k } =\" { v } \"' for k , v in kwargs . items ()) classes = ' ' . join ( '.' + c for c in L ( classes )) meta = [] if classes : meta . append ( classes ) if props : meta . append ( props ) meta = ' ' . join ( meta ) return md + ( \"{\" + meta + \"}\" if meta else \"\" )","title":"meta()"},{"location":"nbdev_api/nbdev/qmd/#nbdev.qmd.tbl_row","text":"Create a markdown table row from cols Source code in nbdev/qmd.py def tbl_row ( cols : list , # Auto-stringified columns to show in the row ): \"Create a markdown table row from `cols`\" return '|' + '|' . join ( str ( c or '' ) for c in cols ) + '|'","title":"tbl_row()"},{"location":"nbdev_api/nbdev/qmd/#nbdev.qmd.tbl_sep","text":"Create a markdown table separator with relative column size sizes Source code in nbdev/qmd.py def tbl_sep ( sizes : int | list = 3 # List of column sizes, or single `int` if all sizes the same ): \"Create a markdown table separator with relative column size `sizes`\" if isinstance ( sizes , int ): sizes = [ 3 ] * sizes return tbl_row ( '-' * s for s in sizes )","title":"tbl_sep()"},{"location":"nbdev_api/nbdev/quarto/","text":"fs_watchdog ( func , path , recursive = True ) \u00a4 File system watchdog dispatching to func Source code in nbdev/quarto.py @contextmanager def fs_watchdog ( func , path , recursive : bool = True ): \"File system watchdog dispatching to `func`\" from watchdog.observers import Observer from watchdog.events import FileSystemEventHandler class _ProcessHandler ( FileSystemEventHandler ): dispatch = func observer = Observer () observer . schedule ( _ProcessHandler , path , recursive = True ) observer . start () try : yield except KeyboardInterrupt : pass finally : observer . stop () observer . join () install () \u00a4 Install Quarto and the current library Source code in nbdev/quarto.py @call_parse def install (): \"Install Quarto and the current library\" install_quarto . __wrapped__ () d = get_config () . lib_path if ( d / '__init__.py' ) . exists (): system ( f 'pip install -e \" { d . parent } [dev]\"' ) install_quarto () \u00a4 Install latest Quarto on macOS or Linux, prints instructions for Windows Source code in nbdev/quarto.py @call_parse def install_quarto (): \"Install latest Quarto on macOS or Linux, prints instructions for Windows\" if sys . platform not in ( 'darwin' , 'linux' ): return print ( 'Please visit https://quarto.org/docs/get-started/ to install quarto' ) print ( \"Installing or upgrading quarto -- this requires root access.\" ) system ( 'sudo touch .installing' ) try : installing = Path ( '.installing' ) if not installing . exists (): return print ( \"Cancelled. Please download and install Quarto from quarto.org.\" ) if 'darwin' in sys . platform : _install_mac () elif 'linux' in sys . platform : _install_linux () finally : system ( 'sudo rm -f .installing' ) nbdev_docs ( path = None , n_workers = 2 , * , file_glob = None , file_re = ' \\\\ .(?:ipynb|qmd|html)$' , symlinks = False , folder_re = None , skip_file_glob = None , skip_file_re = '^[_.]' , skip_folder_re = '^[_.]' ) \u00a4 Create Quarto docs and README.md Source code in nbdev/quarto.py @call_parse @delegates ( _nbglob_docs ) def nbdev_docs ( path : str = None , # Path to notebooks n_workers : int = defaults . cpus , # Number of workers ** kwargs ): \"Create Quarto docs and README.md\" cache , cfg , path = _pre_docs ( path , n_workers = n_workers , ** kwargs ) nbdev_readme . __wrapped__ ( path = path , chk_time = True ) _sprun ( f 'cd \" { cache } \" && quarto render --no-cache' ) shutil . rmtree ( cfg . doc_path , ignore_errors = True ) move ( cache / cfg . doc_path . name , cfg . config_path ) nbdev_preview ( path = None , port = None , host = None , n_workers = 2 , * , file_glob = None , file_re = ' \\\\ .(?:ipynb|qmd|html)$' , symlinks = False , folder_re = None , skip_file_glob = None , skip_file_re = '^[_.]' , skip_folder_re = '^[_.]' ) \u00a4 Preview docs locally Source code in nbdev/quarto.py @call_parse @delegates ( _nbglob_docs ) def nbdev_preview ( path : str = None , # Path to notebooks port : int = None , # The port on which to run preview host : str = None , # The host on which to run preview n_workers : int = defaults . cpus , # Number of workers ** kwargs ): \"Preview docs locally\" os . environ [ 'QUARTO_PREVIEW' ] = '1' cache , cfg , path = _pre_docs ( path , n_workers = n_workers , ** kwargs ) xtra = [] if port : xtra += [ '--port' , str ( port )] if host : xtra += [ '--host' , host ] def _f ( e ): res = _proc_file ( Path ( e . src_path ), cache , path ) if res : try : serve_drv . main ( res ) except : traceback . print_exc () os . chdir ( cache ) xtra = xtra or [] with fs_watchdog ( _f , path ): subprocess . run ([ 'quarto' , 'preview' ] + xtra ) nbdev_proc_nbs ( * , path = '' , n_workers = 2 , force = False , file_glob = '' , file_re = '' , symlinks = False , folder_re = None , skip_file_glob = None , skip_file_re = '^[_.]' , skip_folder_re = '^[_.]' ) \u00a4 Process notebooks in path for docs rendering Source code in nbdev/quarto.py @call_parse @delegates ( proc_nbs ) def nbdev_proc_nbs ( ** kwargs ): \"Process notebooks in `path` for docs rendering\" _pre_docs ( ** kwargs )[ 0 ] nbdev_sidebar ( path = None , printit = False , force = False , skip_folder_re = '(?:^[_.]|^www \\\\ $)' , * , file_glob = None , file_re = ' \\\\ .(?:ipynb|qmd|html)$' , symlinks = False , folder_re = None , skip_file_glob = None , skip_file_re = '^[_.]' ) \u00a4 Create sidebar.yml Source code in nbdev/quarto.py @call_parse @delegates ( _nbglob_docs ) def nbdev_sidebar ( path : str = None , # Path to notebooks printit : bool = False , # Print YAML for debugging force : bool = False , # Create sidebar even if settings.ini custom_sidebar=False skip_folder_re : str = '(?:^[_.]|^www\\$)' , # Skip folders matching regex ** kwargs ): \"Create sidebar.yml\" if not force and get_config () . custom_sidebar : return path = get_config () . nbs_path if not path else Path ( path ) def _f ( a , b ): return Path ( a ), b files = nbglob ( path , func = _f , skip_folder_re = skip_folder_re , ** kwargs ) . sorted ( key = _sort ) lastd , res = Path (),[] for dabs , name in files : drel = dabs . relative_to ( path ) d = Path () for p in drel . parts : d /= p if d == lastd : continue title = re . sub ( '^\\d+_' , '' , d . name ) res . append ( _pre ( d . parent ) + f 'section: { title } ' ) res . append ( _pre ( d . parent , False ) + 'contents:' ) lastd = d res . append ( f ' { _pre ( d ) }{ d . joinpath ( name ) } ' ) yml_path = path / 'sidebar.yml' yml = \"website: \\n sidebar: \\n contents: \\n \" yml += ' \\n ' . join ( f ' { o } ' for o in res ) + ' \\n ' if printit : return print ( yml ) yml_path . write_text ( yml ) prepare () \u00a4 Export, test, and clean notebooks, and render README if needed Source code in nbdev/quarto.py @call_parse def prepare (): \"Export, test, and clean notebooks, and render README if needed\" import nbdev.test , nbdev.clean nbdev_export . __wrapped__ () nbdev . test . nbdev_test . __wrapped__ () nbdev . clean . nbdev_clean . __wrapped__ () refresh_quarto_yml () nbdev_readme . __wrapped__ ( chk_time = True ) refresh_quarto_yml () \u00a4 Generate _quarto.yml from settings.ini . Source code in nbdev/quarto.py def refresh_quarto_yml (): \"Generate `_quarto.yml` from `settings.ini`.\" cfg = get_config () ny = cfg . nbs_path / 'nbdev.yml' vals = { k : cfg [ k ] for k in [ 'title' , 'description' , 'branch' , 'git_url' , 'doc_host' , 'doc_baseurl' ]} vals [ 'doc_path' ] = cfg . doc_path . name if 'title' not in vals : vals [ 'title' ] = vals [ 'lib_name' ] ny . write_text ( _nbdev_yml . format ( ** vals )) qy = cfg . nbs_path / '_quarto.yml' if 'custom_quarto_yml' in cfg . d : print ( \"NB: `_quarto.yml` is no longer auto-updated. Remove `custom_quarto_yml` from `settings.ini`\" ) if qy . exists () and not str2bool ( cfg . get ( 'custom_quarto_yml' , True )): qy . unlink () if not qy . exists (): qy . write_text ( _quarto_yml )","title":"nbdev.quarto"},{"location":"nbdev_api/nbdev/quarto/#nbdev.quarto.fs_watchdog","text":"File system watchdog dispatching to func Source code in nbdev/quarto.py @contextmanager def fs_watchdog ( func , path , recursive : bool = True ): \"File system watchdog dispatching to `func`\" from watchdog.observers import Observer from watchdog.events import FileSystemEventHandler class _ProcessHandler ( FileSystemEventHandler ): dispatch = func observer = Observer () observer . schedule ( _ProcessHandler , path , recursive = True ) observer . start () try : yield except KeyboardInterrupt : pass finally : observer . stop () observer . join ()","title":"fs_watchdog()"},{"location":"nbdev_api/nbdev/quarto/#nbdev.quarto.install","text":"Install Quarto and the current library Source code in nbdev/quarto.py @call_parse def install (): \"Install Quarto and the current library\" install_quarto . __wrapped__ () d = get_config () . lib_path if ( d / '__init__.py' ) . exists (): system ( f 'pip install -e \" { d . parent } [dev]\"' )","title":"install()"},{"location":"nbdev_api/nbdev/quarto/#nbdev.quarto.install_quarto","text":"Install latest Quarto on macOS or Linux, prints instructions for Windows Source code in nbdev/quarto.py @call_parse def install_quarto (): \"Install latest Quarto on macOS or Linux, prints instructions for Windows\" if sys . platform not in ( 'darwin' , 'linux' ): return print ( 'Please visit https://quarto.org/docs/get-started/ to install quarto' ) print ( \"Installing or upgrading quarto -- this requires root access.\" ) system ( 'sudo touch .installing' ) try : installing = Path ( '.installing' ) if not installing . exists (): return print ( \"Cancelled. Please download and install Quarto from quarto.org.\" ) if 'darwin' in sys . platform : _install_mac () elif 'linux' in sys . platform : _install_linux () finally : system ( 'sudo rm -f .installing' )","title":"install_quarto()"},{"location":"nbdev_api/nbdev/quarto/#nbdev.quarto.nbdev_docs","text":"Create Quarto docs and README.md Source code in nbdev/quarto.py @call_parse @delegates ( _nbglob_docs ) def nbdev_docs ( path : str = None , # Path to notebooks n_workers : int = defaults . cpus , # Number of workers ** kwargs ): \"Create Quarto docs and README.md\" cache , cfg , path = _pre_docs ( path , n_workers = n_workers , ** kwargs ) nbdev_readme . __wrapped__ ( path = path , chk_time = True ) _sprun ( f 'cd \" { cache } \" && quarto render --no-cache' ) shutil . rmtree ( cfg . doc_path , ignore_errors = True ) move ( cache / cfg . doc_path . name , cfg . config_path )","title":"nbdev_docs()"},{"location":"nbdev_api/nbdev/quarto/#nbdev.quarto.nbdev_preview","text":"Preview docs locally Source code in nbdev/quarto.py @call_parse @delegates ( _nbglob_docs ) def nbdev_preview ( path : str = None , # Path to notebooks port : int = None , # The port on which to run preview host : str = None , # The host on which to run preview n_workers : int = defaults . cpus , # Number of workers ** kwargs ): \"Preview docs locally\" os . environ [ 'QUARTO_PREVIEW' ] = '1' cache , cfg , path = _pre_docs ( path , n_workers = n_workers , ** kwargs ) xtra = [] if port : xtra += [ '--port' , str ( port )] if host : xtra += [ '--host' , host ] def _f ( e ): res = _proc_file ( Path ( e . src_path ), cache , path ) if res : try : serve_drv . main ( res ) except : traceback . print_exc () os . chdir ( cache ) xtra = xtra or [] with fs_watchdog ( _f , path ): subprocess . run ([ 'quarto' , 'preview' ] + xtra )","title":"nbdev_preview()"},{"location":"nbdev_api/nbdev/quarto/#nbdev.quarto.nbdev_proc_nbs","text":"Process notebooks in path for docs rendering Source code in nbdev/quarto.py @call_parse @delegates ( proc_nbs ) def nbdev_proc_nbs ( ** kwargs ): \"Process notebooks in `path` for docs rendering\" _pre_docs ( ** kwargs )[ 0 ]","title":"nbdev_proc_nbs()"},{"location":"nbdev_api/nbdev/quarto/#nbdev.quarto.nbdev_sidebar","text":"Create sidebar.yml Source code in nbdev/quarto.py @call_parse @delegates ( _nbglob_docs ) def nbdev_sidebar ( path : str = None , # Path to notebooks printit : bool = False , # Print YAML for debugging force : bool = False , # Create sidebar even if settings.ini custom_sidebar=False skip_folder_re : str = '(?:^[_.]|^www\\$)' , # Skip folders matching regex ** kwargs ): \"Create sidebar.yml\" if not force and get_config () . custom_sidebar : return path = get_config () . nbs_path if not path else Path ( path ) def _f ( a , b ): return Path ( a ), b files = nbglob ( path , func = _f , skip_folder_re = skip_folder_re , ** kwargs ) . sorted ( key = _sort ) lastd , res = Path (),[] for dabs , name in files : drel = dabs . relative_to ( path ) d = Path () for p in drel . parts : d /= p if d == lastd : continue title = re . sub ( '^\\d+_' , '' , d . name ) res . append ( _pre ( d . parent ) + f 'section: { title } ' ) res . append ( _pre ( d . parent , False ) + 'contents:' ) lastd = d res . append ( f ' { _pre ( d ) }{ d . joinpath ( name ) } ' ) yml_path = path / 'sidebar.yml' yml = \"website: \\n sidebar: \\n contents: \\n \" yml += ' \\n ' . join ( f ' { o } ' for o in res ) + ' \\n ' if printit : return print ( yml ) yml_path . write_text ( yml )","title":"nbdev_sidebar()"},{"location":"nbdev_api/nbdev/quarto/#nbdev.quarto.prepare","text":"Export, test, and clean notebooks, and render README if needed Source code in nbdev/quarto.py @call_parse def prepare (): \"Export, test, and clean notebooks, and render README if needed\" import nbdev.test , nbdev.clean nbdev_export . __wrapped__ () nbdev . test . nbdev_test . __wrapped__ () nbdev . clean . nbdev_clean . __wrapped__ () refresh_quarto_yml () nbdev_readme . __wrapped__ ( chk_time = True )","title":"prepare()"},{"location":"nbdev_api/nbdev/quarto/#nbdev.quarto.refresh_quarto_yml","text":"Generate _quarto.yml from settings.ini . Source code in nbdev/quarto.py def refresh_quarto_yml (): \"Generate `_quarto.yml` from `settings.ini`.\" cfg = get_config () ny = cfg . nbs_path / 'nbdev.yml' vals = { k : cfg [ k ] for k in [ 'title' , 'description' , 'branch' , 'git_url' , 'doc_host' , 'doc_baseurl' ]} vals [ 'doc_path' ] = cfg . doc_path . name if 'title' not in vals : vals [ 'title' ] = vals [ 'lib_name' ] ny . write_text ( _nbdev_yml . format ( ** vals )) qy = cfg . nbs_path / '_quarto.yml' if 'custom_quarto_yml' in cfg . d : print ( \"NB: `_quarto.yml` is no longer auto-updated. Remove `custom_quarto_yml` from `settings.ini`\" ) if qy . exists () and not str2bool ( cfg . get ( 'custom_quarto_yml' , True )): qy . unlink () if not qy . exists (): qy . write_text ( _quarto_yml )","title":"refresh_quarto_yml()"},{"location":"nbdev_api/nbdev/release/","text":"Release \u00a4 Source code in nbdev/release.py class Release : def __init__ ( self , owner = None , repo = None , token = None , ** groups ): \"Create CHANGELOG.md from GitHub issues\" self . cfg = _find_config () self . changefile = self . cfg . config_path / 'CHANGELOG.md' if not groups : default_groups = dict ( breaking = \"Breaking Changes\" , enhancement = \"New Features\" , bug = \"Bugs Squashed\" ) groups = _load_json ( self . cfg , 'label_groups' ) if 'label_groups' in self . cfg else default_groups os . chdir ( self . cfg . config_path ) owner , repo = owner or self . cfg . user , repo or self . cfg . repo token = ifnone ( token , os . getenv ( 'NBDEV_TOKEN' , None )) if not token and Path ( 'token' ) . exists (): token = Path ( 'token' ) . read_text () . strip () token = ifnone ( token , os . getenv ( 'GITHUB_TOKEN' , None )) if not token : raise Exception ( 'Failed to find token' ) self . gh = GhApi ( owner , repo , token ) self . groups = groups def _issues ( self , label ): return self . gh . issues . list_for_repo ( state = 'closed' , sort = 'created' , filter = 'all' , since = self . commit_date , labels = label ) def _issue_groups ( self ): return parallel ( self . _issues , self . groups . keys (), progress = False ) __init__ ( self , owner = None , repo = None , token = None , ** groups ) special \u00a4 Create CHANGELOG.md from GitHub issues Source code in nbdev/release.py def __init__ ( self , owner = None , repo = None , token = None , ** groups ): \"Create CHANGELOG.md from GitHub issues\" self . cfg = _find_config () self . changefile = self . cfg . config_path / 'CHANGELOG.md' if not groups : default_groups = dict ( breaking = \"Breaking Changes\" , enhancement = \"New Features\" , bug = \"Bugs Squashed\" ) groups = _load_json ( self . cfg , 'label_groups' ) if 'label_groups' in self . cfg else default_groups os . chdir ( self . cfg . config_path ) owner , repo = owner or self . cfg . user , repo or self . cfg . repo token = ifnone ( token , os . getenv ( 'NBDEV_TOKEN' , None )) if not token and Path ( 'token' ) . exists (): token = Path ( 'token' ) . read_text () . strip () token = ifnone ( token , os . getenv ( 'GITHUB_TOKEN' , None )) if not token : raise Exception ( 'Failed to find token' ) self . gh = GhApi ( owner , repo , token ) self . groups = groups changelog ( self , debug = False ) \u00a4 Create the CHANGELOG.md file, or return the proposed text if debug is True Source code in nbdev/release.py @patch def changelog ( self : Release , debug = False ): # Just print the latest changes, instead of updating file \"Create the CHANGELOG.md file, or return the proposed text if `debug` is `True`\" if not self . changefile . exists (): self . changefile . write_text ( \"# Release notes \\n\\n <!-- do not remove --> \\n \" ) marker = '<!-- do not remove --> \\n ' try : self . commit_date = self . gh . repos . get_latest_release () . published_at except HTTP404NotFoundError : self . commit_date = '2000-01-01T00:00:004Z' res = f \" \\n ## { self . cfg . version } \\n \" issues = self . _issue_groups () res += ' \\n ' . join ( _issues_txt ( * o ) for o in zip ( issues , self . groups . values ())) if debug : return res res = self . changefile . read_text () . replace ( marker , marker + res + \" \\n \" ) shutil . copy ( self . changefile , self . changefile . with_suffix ( \".bak\" )) self . changefile . write_text ( res ) run ( f 'git add { self . changefile } ' ) latest_notes ( self ) \u00a4 Latest CHANGELOG entry Source code in nbdev/release.py @patch def latest_notes ( self : Release ): \"Latest CHANGELOG entry\" if not self . changefile . exists (): return '' its = re . split ( r '^## ' , self . changefile . read_text (), flags = re . MULTILINE ) if not len ( its ) > 0 : return '' return ' \\n ' . join ( its [ 1 ] . splitlines ()[ 1 :]) . strip () release ( self ) \u00a4 Tag and create a release in GitHub for the current version Source code in nbdev/release.py @patch def release ( self : Release ): \"Tag and create a release in GitHub for the current version\" ver = self . cfg . version notes = self . latest_notes () self . gh . create_release ( ver , branch = self . cfg . branch , body = notes ) return ver anaconda_upload ( name , loc = None , user = None , token = None , env_token = None ) \u00a4 Upload name to anaconda Source code in nbdev/release.py def anaconda_upload ( name , loc = None , user = None , token = None , env_token = None ): \"Upload `name` to anaconda\" user = f '-u { user } ' if user else '' if env_token : token = os . getenv ( env_token ) token = f '-t { token } ' if token else '' if not loc : loc = conda_output_path ( name ) if not loc : raise Exception ( \"Failed to find output\" ) return _run ( f 'anaconda { token } upload { user } { loc } --skip-existing' ) changelog ( debug = False , repo = None ) \u00a4 Create a CHANGELOG.md file from closed and labeled GitHub issues Source code in nbdev/release.py @call_parse def changelog ( debug : store_true = False , # Print info to be added to CHANGELOG, instead of updating file repo : str = None , # repo to use instead of `lib_name` from `settings.ini` ): \"Create a CHANGELOG.md file from closed and labeled GitHub issues\" res = Release ( repo = repo ) . changelog ( debug = debug ) if debug : print ( res ) chk_conda_rel ( nm , apkg = None , channel = 'fastai' , force = False ) \u00a4 Prints GitHub tag only if a newer release exists on Pypi compared to an Anaconda Repo. Source code in nbdev/release.py def chk_conda_rel ( nm : str , # Package name on pypi apkg : str = None , # Anaconda Package (defaults to {nm}) channel : str = 'fastai' , # Anaconda Channel force : store_true = False # Always return github tag ): \"Prints GitHub tag only if a newer release exists on Pypi compared to an Anaconda Repo.\" if not apkg : apkg = nm condavs = L ( loads ( run ( f 'mamba repoquery search { apkg } -c { channel } --json' ))[ 'result' ][ 'pkgs' ]) condatag = condavs . attrgot ( 'version' ) . map ( parse ) pypitag = latest_pypi ( nm ) if force or not condatag or pypitag > max ( condatag ): return f ' { pypitag } ' conda_output_path ( name , build = 'build' ) \u00a4 Output path for conda build Source code in nbdev/release.py def conda_output_path ( name , build = 'build' ): \"Output path for conda build\" return run ( f 'conda { build } --output { name } ' ) . strip () . replace ( ' \\\\ ' , '/' ) latest_pypi ( name ) \u00a4 Latest version of name on pypi Source code in nbdev/release.py def latest_pypi ( name ): \"Latest version of `name` on pypi\" return max ( parse ( r ) for r , o in pypi_json ( name )[ 'releases' ] . items () if not parse ( r ) . is_prerelease and not nested_idx ( o , 0 , 'yanked' )) nbdev_bump_version ( part = 2 , unbump = False ) \u00a4 Increment version in settings.ini by one Source code in nbdev/release.py @call_parse def nbdev_bump_version ( part : int = 2 , # Part of version to bump unbump : bool = False ): # Reduce version instead of increasing it \"Increment version in settings.ini by one\" cfg = get_config () print ( f 'Old version: { cfg . version } ' ) cfg . d [ 'version' ] = bump_version ( get_config () . version , part , unbump = unbump ) cfg . save () update_version () nbdev_export . __wrapped__ () print ( f 'New version: { cfg . version } ' ) pypi_details ( name ) \u00a4 Version, URL, and SHA256 for name from pypi Source code in nbdev/release.py def pypi_details ( name ): \"Version, URL, and SHA256 for `name` from pypi\" ver = str ( latest_pypi ( name )) pypi = pypi_json ( f ' { name } / { ver } ' ) rel = [ o for o in pypi [ 'urls' ] if o [ 'packagetype' ] == 'sdist' ][ 0 ] return ver , rel [ 'url' ], rel [ 'digests' ][ 'sha256' ] pypi_json ( s ) \u00a4 Dictionary decoded JSON for PYPI path s Source code in nbdev/release.py def pypi_json ( s ): \"Dictionary decoded JSON for PYPI path `s`\" return urljson ( f ' { _PYPI_URL }{ s } /json' ) release_both ( path = 'conda' , do_build = True , build_args = '' , skip_upload = False , mambabuild = False , upload_user = None , repository = 'pypi' ) \u00a4 Release both conda and PyPI packages Source code in nbdev/release.py @call_parse def release_both ( path : str = 'conda' , # Path where package will be created do_build : bool_arg = True , # Run `conda build` step build_args : str = '' , # Additional args (as str) to send to `conda build` skip_upload : store_true = False , # Skip `anaconda upload` step mambabuild : store_true = False , # Use `mambabuild` (requires `boa`) upload_user : str = None , # Optional user to upload package to repository : str = \"pypi\" # Pypi respository to upload to (defined in ~/.pypirc) ): \"Release both conda and PyPI packages\" release_pypi . __wrapped__ ( repository ) release_conda . __wrapped__ ( path , do_build = do_build , build_args = build_args , skip_upload = skip_upload , mambabuild = mambabuild , upload_user = upload_user ) nbdev_bump_version . __wrapped__ () release_conda ( path = 'conda' , do_build = True , build_args = '' , skip_upload = False , mambabuild = False , upload_user = None ) \u00a4 Create a meta.yaml file ready to be built into a package, and optionally build and upload it Source code in nbdev/release.py @call_parse def release_conda ( path : str = 'conda' , # Path where package will be created do_build : bool_arg = True , # Run `conda build` step build_args : str = '' , # Additional args (as str) to send to `conda build` skip_upload : store_true = False , # Skip `anaconda upload` step mambabuild : store_true = False , # Use `mambabuild` (requires `boa`) upload_user : str = None # Optional user to upload package to ): \"Create a `meta.yaml` file ready to be built into a package, and optionally build and upload it\" name = get_config () . lib_name write_conda_meta ( path ) out = f \"Done. Next steps: \\n ``` \\n cd { path } \\n \"\"\" os . chdir ( path ) build = 'mambabuild' if mambabuild else 'build' if not do_build : return print ( f \" { out } conda { build } { name } \" ) cmd = f \"conda { build } --output-folder out --no-anaconda-upload { build_args } { name } \" print ( cmd ) res = _run ( cmd ) outs = globtastic ( 'out' , file_glob = '*.tar.bz2' ) assert len ( outs ) == 1 loc = outs [ 0 ] if skip_upload : return print ( loc ) if not upload_user : upload_user = get_config () . conda_user if not upload_user : return print ( \"`conda_user` not in settings.ini and no `upload_user` passed. Cannot upload\" ) if 'anaconda upload' not in res : return print ( f \" { res } \\n \\Failed. Check auto-upload not set in .condarc. Try `--do_build False`.\" ) return anaconda_upload ( name , loc ) release_gh ( token = None ) \u00a4 Calls nbdev_changelog , lets you edit the result, then pushes to git and calls nbdev_release_git Source code in nbdev/release.py @call_parse def release_gh ( token : str = None # Optional GitHub token (otherwise `token` file is used) ): \"Calls `nbdev_changelog`, lets you edit the result, then pushes to git and calls `nbdev_release_git`\" cfg = _find_config () Release () . changelog () subprocess . run ([ os . environ . get ( 'EDITOR' , 'nano' ), cfg . config_path / 'CHANGELOG.md' ]) if not input ( \"Make release now? (y/n) \" ) . lower () . startswith ( 'y' ): sys . exit ( 1 ) run ( 'git commit -am release' ) run ( 'git push' ) ver = Release ( token = token ) . release () print ( f \"Released { ver } \" ) release_git ( token = None ) \u00a4 Tag and create a release in GitHub for the current version Source code in nbdev/release.py @call_parse def release_git ( token : str = None # Optional GitHub token (otherwise `token` file is used) ): \"Tag and create a release in GitHub for the current version\" ver = Release ( token = token ) . release () print ( f \"Released { ver } \" ) release_pypi ( repository = 'pypi' ) \u00a4 Create and upload Python package to PyPI Source code in nbdev/release.py @call_parse def release_pypi ( repository : str = \"pypi\" # Respository to upload to (defined in ~/.pypirc) ): \"Create and upload Python package to PyPI\" _dir = get_config () . lib_path . parent system ( f 'cd { _dir } && rm -rf dist && python setup.py sdist bdist_wheel' ) system ( f 'twine upload --repository { repository } { _dir } /dist/*' ) write_conda_meta ( path = 'conda' ) \u00a4 Writes a meta.yaml file to the conda directory of the current directory Source code in nbdev/release.py def write_conda_meta ( path = 'conda' ): \"Writes a `meta.yaml` file to the `conda` directory of the current directory\" _write_yaml ( path , * _get_conda_meta ()) write_requirements ( directory = None ) \u00a4 Writes a requirements.txt file to directory based on settings.ini. Source code in nbdev/release.py def write_requirements ( directory = None ): \"Writes a `requirements.txt` file to `directory` based on settings.ini.\" cfg = get_config () d = Path ( directory ) if directory else cfg . config_path req = ' \\n ' . join ([ cfg . get ( k , '' ) . replace ( ' ' , ' \\n ' ) for k in [ 'requirements' , 'pip_requirements' ]]) ( d / 'requirements.txt' ) . mk_write ( req )","title":"nbdev.release"},{"location":"nbdev_api/nbdev/release/#nbdev.release.Release","text":"Source code in nbdev/release.py class Release : def __init__ ( self , owner = None , repo = None , token = None , ** groups ): \"Create CHANGELOG.md from GitHub issues\" self . cfg = _find_config () self . changefile = self . cfg . config_path / 'CHANGELOG.md' if not groups : default_groups = dict ( breaking = \"Breaking Changes\" , enhancement = \"New Features\" , bug = \"Bugs Squashed\" ) groups = _load_json ( self . cfg , 'label_groups' ) if 'label_groups' in self . cfg else default_groups os . chdir ( self . cfg . config_path ) owner , repo = owner or self . cfg . user , repo or self . cfg . repo token = ifnone ( token , os . getenv ( 'NBDEV_TOKEN' , None )) if not token and Path ( 'token' ) . exists (): token = Path ( 'token' ) . read_text () . strip () token = ifnone ( token , os . getenv ( 'GITHUB_TOKEN' , None )) if not token : raise Exception ( 'Failed to find token' ) self . gh = GhApi ( owner , repo , token ) self . groups = groups def _issues ( self , label ): return self . gh . issues . list_for_repo ( state = 'closed' , sort = 'created' , filter = 'all' , since = self . commit_date , labels = label ) def _issue_groups ( self ): return parallel ( self . _issues , self . groups . keys (), progress = False )","title":"Release"},{"location":"nbdev_api/nbdev/release/#nbdev.release.Release.__init__","text":"Create CHANGELOG.md from GitHub issues Source code in nbdev/release.py def __init__ ( self , owner = None , repo = None , token = None , ** groups ): \"Create CHANGELOG.md from GitHub issues\" self . cfg = _find_config () self . changefile = self . cfg . config_path / 'CHANGELOG.md' if not groups : default_groups = dict ( breaking = \"Breaking Changes\" , enhancement = \"New Features\" , bug = \"Bugs Squashed\" ) groups = _load_json ( self . cfg , 'label_groups' ) if 'label_groups' in self . cfg else default_groups os . chdir ( self . cfg . config_path ) owner , repo = owner or self . cfg . user , repo or self . cfg . repo token = ifnone ( token , os . getenv ( 'NBDEV_TOKEN' , None )) if not token and Path ( 'token' ) . exists (): token = Path ( 'token' ) . read_text () . strip () token = ifnone ( token , os . getenv ( 'GITHUB_TOKEN' , None )) if not token : raise Exception ( 'Failed to find token' ) self . gh = GhApi ( owner , repo , token ) self . groups = groups","title":"__init__()"},{"location":"nbdev_api/nbdev/release/#nbdev.release.Release.changelog","text":"Create the CHANGELOG.md file, or return the proposed text if debug is True Source code in nbdev/release.py @patch def changelog ( self : Release , debug = False ): # Just print the latest changes, instead of updating file \"Create the CHANGELOG.md file, or return the proposed text if `debug` is `True`\" if not self . changefile . exists (): self . changefile . write_text ( \"# Release notes \\n\\n <!-- do not remove --> \\n \" ) marker = '<!-- do not remove --> \\n ' try : self . commit_date = self . gh . repos . get_latest_release () . published_at except HTTP404NotFoundError : self . commit_date = '2000-01-01T00:00:004Z' res = f \" \\n ## { self . cfg . version } \\n \" issues = self . _issue_groups () res += ' \\n ' . join ( _issues_txt ( * o ) for o in zip ( issues , self . groups . values ())) if debug : return res res = self . changefile . read_text () . replace ( marker , marker + res + \" \\n \" ) shutil . copy ( self . changefile , self . changefile . with_suffix ( \".bak\" )) self . changefile . write_text ( res ) run ( f 'git add { self . changefile } ' )","title":"changelog()"},{"location":"nbdev_api/nbdev/release/#nbdev.release.Release.latest_notes","text":"Latest CHANGELOG entry Source code in nbdev/release.py @patch def latest_notes ( self : Release ): \"Latest CHANGELOG entry\" if not self . changefile . exists (): return '' its = re . split ( r '^## ' , self . changefile . read_text (), flags = re . MULTILINE ) if not len ( its ) > 0 : return '' return ' \\n ' . join ( its [ 1 ] . splitlines ()[ 1 :]) . strip ()","title":"latest_notes()"},{"location":"nbdev_api/nbdev/release/#nbdev.release.Release.release","text":"Tag and create a release in GitHub for the current version Source code in nbdev/release.py @patch def release ( self : Release ): \"Tag and create a release in GitHub for the current version\" ver = self . cfg . version notes = self . latest_notes () self . gh . create_release ( ver , branch = self . cfg . branch , body = notes ) return ver","title":"release()"},{"location":"nbdev_api/nbdev/release/#nbdev.release.anaconda_upload","text":"Upload name to anaconda Source code in nbdev/release.py def anaconda_upload ( name , loc = None , user = None , token = None , env_token = None ): \"Upload `name` to anaconda\" user = f '-u { user } ' if user else '' if env_token : token = os . getenv ( env_token ) token = f '-t { token } ' if token else '' if not loc : loc = conda_output_path ( name ) if not loc : raise Exception ( \"Failed to find output\" ) return _run ( f 'anaconda { token } upload { user } { loc } --skip-existing' )","title":"anaconda_upload()"},{"location":"nbdev_api/nbdev/release/#nbdev.release.changelog","text":"Create a CHANGELOG.md file from closed and labeled GitHub issues Source code in nbdev/release.py @call_parse def changelog ( debug : store_true = False , # Print info to be added to CHANGELOG, instead of updating file repo : str = None , # repo to use instead of `lib_name` from `settings.ini` ): \"Create a CHANGELOG.md file from closed and labeled GitHub issues\" res = Release ( repo = repo ) . changelog ( debug = debug ) if debug : print ( res )","title":"changelog()"},{"location":"nbdev_api/nbdev/release/#nbdev.release.chk_conda_rel","text":"Prints GitHub tag only if a newer release exists on Pypi compared to an Anaconda Repo. Source code in nbdev/release.py def chk_conda_rel ( nm : str , # Package name on pypi apkg : str = None , # Anaconda Package (defaults to {nm}) channel : str = 'fastai' , # Anaconda Channel force : store_true = False # Always return github tag ): \"Prints GitHub tag only if a newer release exists on Pypi compared to an Anaconda Repo.\" if not apkg : apkg = nm condavs = L ( loads ( run ( f 'mamba repoquery search { apkg } -c { channel } --json' ))[ 'result' ][ 'pkgs' ]) condatag = condavs . attrgot ( 'version' ) . map ( parse ) pypitag = latest_pypi ( nm ) if force or not condatag or pypitag > max ( condatag ): return f ' { pypitag } '","title":"chk_conda_rel()"},{"location":"nbdev_api/nbdev/release/#nbdev.release.conda_output_path","text":"Output path for conda build Source code in nbdev/release.py def conda_output_path ( name , build = 'build' ): \"Output path for conda build\" return run ( f 'conda { build } --output { name } ' ) . strip () . replace ( ' \\\\ ' , '/' )","title":"conda_output_path()"},{"location":"nbdev_api/nbdev/release/#nbdev.release.latest_pypi","text":"Latest version of name on pypi Source code in nbdev/release.py def latest_pypi ( name ): \"Latest version of `name` on pypi\" return max ( parse ( r ) for r , o in pypi_json ( name )[ 'releases' ] . items () if not parse ( r ) . is_prerelease and not nested_idx ( o , 0 , 'yanked' ))","title":"latest_pypi()"},{"location":"nbdev_api/nbdev/release/#nbdev.release.nbdev_bump_version","text":"Increment version in settings.ini by one Source code in nbdev/release.py @call_parse def nbdev_bump_version ( part : int = 2 , # Part of version to bump unbump : bool = False ): # Reduce version instead of increasing it \"Increment version in settings.ini by one\" cfg = get_config () print ( f 'Old version: { cfg . version } ' ) cfg . d [ 'version' ] = bump_version ( get_config () . version , part , unbump = unbump ) cfg . save () update_version () nbdev_export . __wrapped__ () print ( f 'New version: { cfg . version } ' )","title":"nbdev_bump_version()"},{"location":"nbdev_api/nbdev/release/#nbdev.release.pypi_details","text":"Version, URL, and SHA256 for name from pypi Source code in nbdev/release.py def pypi_details ( name ): \"Version, URL, and SHA256 for `name` from pypi\" ver = str ( latest_pypi ( name )) pypi = pypi_json ( f ' { name } / { ver } ' ) rel = [ o for o in pypi [ 'urls' ] if o [ 'packagetype' ] == 'sdist' ][ 0 ] return ver , rel [ 'url' ], rel [ 'digests' ][ 'sha256' ]","title":"pypi_details()"},{"location":"nbdev_api/nbdev/release/#nbdev.release.pypi_json","text":"Dictionary decoded JSON for PYPI path s Source code in nbdev/release.py def pypi_json ( s ): \"Dictionary decoded JSON for PYPI path `s`\" return urljson ( f ' { _PYPI_URL }{ s } /json' )","title":"pypi_json()"},{"location":"nbdev_api/nbdev/release/#nbdev.release.release_both","text":"Release both conda and PyPI packages Source code in nbdev/release.py @call_parse def release_both ( path : str = 'conda' , # Path where package will be created do_build : bool_arg = True , # Run `conda build` step build_args : str = '' , # Additional args (as str) to send to `conda build` skip_upload : store_true = False , # Skip `anaconda upload` step mambabuild : store_true = False , # Use `mambabuild` (requires `boa`) upload_user : str = None , # Optional user to upload package to repository : str = \"pypi\" # Pypi respository to upload to (defined in ~/.pypirc) ): \"Release both conda and PyPI packages\" release_pypi . __wrapped__ ( repository ) release_conda . __wrapped__ ( path , do_build = do_build , build_args = build_args , skip_upload = skip_upload , mambabuild = mambabuild , upload_user = upload_user ) nbdev_bump_version . __wrapped__ ()","title":"release_both()"},{"location":"nbdev_api/nbdev/release/#nbdev.release.release_conda","text":"Create a meta.yaml file ready to be built into a package, and optionally build and upload it Source code in nbdev/release.py @call_parse def release_conda ( path : str = 'conda' , # Path where package will be created do_build : bool_arg = True , # Run `conda build` step build_args : str = '' , # Additional args (as str) to send to `conda build` skip_upload : store_true = False , # Skip `anaconda upload` step mambabuild : store_true = False , # Use `mambabuild` (requires `boa`) upload_user : str = None # Optional user to upload package to ): \"Create a `meta.yaml` file ready to be built into a package, and optionally build and upload it\" name = get_config () . lib_name write_conda_meta ( path ) out = f \"Done. Next steps: \\n ``` \\n cd { path } \\n \"\"\" os . chdir ( path ) build = 'mambabuild' if mambabuild else 'build' if not do_build : return print ( f \" { out } conda { build } { name } \" ) cmd = f \"conda { build } --output-folder out --no-anaconda-upload { build_args } { name } \" print ( cmd ) res = _run ( cmd ) outs = globtastic ( 'out' , file_glob = '*.tar.bz2' ) assert len ( outs ) == 1 loc = outs [ 0 ] if skip_upload : return print ( loc ) if not upload_user : upload_user = get_config () . conda_user if not upload_user : return print ( \"`conda_user` not in settings.ini and no `upload_user` passed. Cannot upload\" ) if 'anaconda upload' not in res : return print ( f \" { res } \\n \\Failed. Check auto-upload not set in .condarc. Try `--do_build False`.\" ) return anaconda_upload ( name , loc )","title":"release_conda()"},{"location":"nbdev_api/nbdev/release/#nbdev.release.release_gh","text":"Calls nbdev_changelog , lets you edit the result, then pushes to git and calls nbdev_release_git Source code in nbdev/release.py @call_parse def release_gh ( token : str = None # Optional GitHub token (otherwise `token` file is used) ): \"Calls `nbdev_changelog`, lets you edit the result, then pushes to git and calls `nbdev_release_git`\" cfg = _find_config () Release () . changelog () subprocess . run ([ os . environ . get ( 'EDITOR' , 'nano' ), cfg . config_path / 'CHANGELOG.md' ]) if not input ( \"Make release now? (y/n) \" ) . lower () . startswith ( 'y' ): sys . exit ( 1 ) run ( 'git commit -am release' ) run ( 'git push' ) ver = Release ( token = token ) . release () print ( f \"Released { ver } \" )","title":"release_gh()"},{"location":"nbdev_api/nbdev/release/#nbdev.release.release_git","text":"Tag and create a release in GitHub for the current version Source code in nbdev/release.py @call_parse def release_git ( token : str = None # Optional GitHub token (otherwise `token` file is used) ): \"Tag and create a release in GitHub for the current version\" ver = Release ( token = token ) . release () print ( f \"Released { ver } \" )","title":"release_git()"},{"location":"nbdev_api/nbdev/release/#nbdev.release.release_pypi","text":"Create and upload Python package to PyPI Source code in nbdev/release.py @call_parse def release_pypi ( repository : str = \"pypi\" # Respository to upload to (defined in ~/.pypirc) ): \"Create and upload Python package to PyPI\" _dir = get_config () . lib_path . parent system ( f 'cd { _dir } && rm -rf dist && python setup.py sdist bdist_wheel' ) system ( f 'twine upload --repository { repository } { _dir } /dist/*' )","title":"release_pypi()"},{"location":"nbdev_api/nbdev/release/#nbdev.release.write_conda_meta","text":"Writes a meta.yaml file to the conda directory of the current directory Source code in nbdev/release.py def write_conda_meta ( path = 'conda' ): \"Writes a `meta.yaml` file to the `conda` directory of the current directory\" _write_yaml ( path , * _get_conda_meta ())","title":"write_conda_meta()"},{"location":"nbdev_api/nbdev/release/#nbdev.release.write_requirements","text":"Writes a requirements.txt file to directory based on settings.ini. Source code in nbdev/release.py def write_requirements ( directory = None ): \"Writes a `requirements.txt` file to `directory` based on settings.ini.\" cfg = get_config () d = Path ( directory ) if directory else cfg . config_path req = ' \\n ' . join ([ cfg . get ( k , '' ) . replace ( ' ' , ' \\n ' ) for k in [ 'requirements' , 'pip_requirements' ]]) ( d / 'requirements.txt' ) . mk_write ( req )","title":"write_requirements()"},{"location":"nbdev_api/nbdev/serve/","text":"proc_nbs ( path = '' , n_workers = 2 , force = False , file_glob = '' , file_re = '' , * , symlinks = False , folder_re = None , skip_file_glob = None , skip_file_re = '^[_.]' , skip_folder_re = '^[_.]' ) \u00a4 Process notebooks in path for docs rendering Source code in nbdev/serve.py @delegates ( nbglob_cli ) def proc_nbs ( path : str = '' , # Path to notebooks n_workers : int = defaults . cpus , # Number of workers force : bool = False , # Ignore cache and build all file_glob : str = '' , # Only include files matching glob file_re : str = '' , # Only include files matching glob ** kwargs ): \"Process notebooks in `path` for docs rendering\" cfg = get_config () cache = cfg . config_path / '_proc' path = Path ( path or cfg . nbs_path ) files = nbglob ( path , func = Path , file_glob = '' , file_re = '' , ** kwargs ) if ( path / '_quarto.yml' ) . exists (): files . append ( path / '_quarto.yml' ) # If settings.ini or filter script newer than cache folder modified, delete cache chk_mtime = max ( cfg . config_file . stat () . st_mtime , Path ( __file__ ) . stat () . st_mtime ) cache . mkdir ( parents = True , exist_ok = True ) cache_mtime = cache . stat () . st_mtime if force or ( cache . exists and cache_mtime < chk_mtime ): rmtree ( cache ) files = files . map ( _proc_file , mtime = cache_mtime , cache = cache , path = path ) . filter () kw = {} if IN_NOTEBOOK else { 'method' : 'spawn' } parallel ( nbdev . serve_drv . main , files , n_workers = n_workers , pause = 0.01 , ** kw ) if cache . exists (): cache . touch () return cache","title":"nbdev.serve"},{"location":"nbdev_api/nbdev/serve/#nbdev.serve.proc_nbs","text":"Process notebooks in path for docs rendering Source code in nbdev/serve.py @delegates ( nbglob_cli ) def proc_nbs ( path : str = '' , # Path to notebooks n_workers : int = defaults . cpus , # Number of workers force : bool = False , # Ignore cache and build all file_glob : str = '' , # Only include files matching glob file_re : str = '' , # Only include files matching glob ** kwargs ): \"Process notebooks in `path` for docs rendering\" cfg = get_config () cache = cfg . config_path / '_proc' path = Path ( path or cfg . nbs_path ) files = nbglob ( path , func = Path , file_glob = '' , file_re = '' , ** kwargs ) if ( path / '_quarto.yml' ) . exists (): files . append ( path / '_quarto.yml' ) # If settings.ini or filter script newer than cache folder modified, delete cache chk_mtime = max ( cfg . config_file . stat () . st_mtime , Path ( __file__ ) . stat () . st_mtime ) cache . mkdir ( parents = True , exist_ok = True ) cache_mtime = cache . stat () . st_mtime if force or ( cache . exists and cache_mtime < chk_mtime ): rmtree ( cache ) files = files . map ( _proc_file , mtime = cache_mtime , cache = cache , path = path ) . filter () kw = {} if IN_NOTEBOOK else { 'method' : 'spawn' } parallel ( nbdev . serve_drv . main , files , n_workers = n_workers , pause = 0.01 , ** kw ) if cache . exists (): cache . touch () return cache","title":"proc_nbs()"},{"location":"nbdev_api/nbdev/serve_drv/","text":"","title":"nbdev.serve_drv"},{"location":"nbdev_api/nbdev/showdoc/","text":"BasicHtmlRenderer ( ShowDocRenderer ) \u00a4 Simple HTML renderer for show_doc Source code in nbdev/showdoc.py class BasicHtmlRenderer ( ShowDocRenderer ): \"Simple HTML renderer for `show_doc`\" def _repr_html_ ( self ): doc = '<hr/> \\n ' doc += f '<h { self . title_level } > { self . nm } </h { self . title_level } > \\n ' doc += f '<blockquote><pre><code> { self . nm }{ _fmt_sig ( self . sig ) } </code></pre></blockquote>' if self . docs : doc += f \"<p> { self . docs } </p>\" return doc def doc ( self ): \"Show `show_doc` info along with link to docs\" from IPython.display import display , HTML res = self . _repr_html_ () docs = NbdevLookup () . doc ( self . fn ) if docs is not None : res += ' \\n <p>' + _html_link ( docs , \"Show in docs\" ) + '</p>' display ( HTML ( res )) doc ( self ) \u00a4 Show show_doc info along with link to docs Source code in nbdev/showdoc.py def doc ( self ): \"Show `show_doc` info along with link to docs\" from IPython.display import display , HTML res = self . _repr_html_ () docs = NbdevLookup () . doc ( self . fn ) if docs is not None : res += ' \\n <p>' + _html_link ( docs , \"Show in docs\" ) + '</p>' display ( HTML ( res )) BasicMarkdownRenderer ( ShowDocRenderer ) \u00a4 Markdown renderer for show_doc Source code in nbdev/showdoc.py class BasicMarkdownRenderer ( ShowDocRenderer ): \"Markdown renderer for `show_doc`\" def _repr_markdown_ ( self ): doc = '--- \\n\\n ' src = NbdevLookup () . code ( self . fn ) if src : doc += _ext_link ( src , 'source' , 'style=\"float:right; font-size:smaller\"' ) + ' \\n\\n ' h = '#' * self . title_level doc += f ' { h } { self . nm } \\n\\n ' sig = _wrap_sig ( f \" { self . nm } { _fmt_sig ( self . sig ) } \" ) if self . sig else '' doc += f ' { sig } ' if self . docs : doc += f \" \\n\\n { self . docs } \" if self . dm . has_docment : doc += f \" \\n\\n { self . dm } \" return doc __repr__ = __str__ = _repr_markdown_ DocmentTbl \u00a4 Source code in nbdev/showdoc.py class DocmentTbl : # this is the column order we want these items to appear _map = OrderedDict ({ 'anno' : 'Type' , 'default' : 'Default' , 'docment' : 'Details' }) def __init__ ( self , obj , verbose = True , returns = True ): \"Compute the docment table string\" self . verbose = verbose self . returns = False if isdataclass ( obj ) else returns try : self . params = L ( signature_ex ( obj , eval_str = True ) . parameters . keys ()) except ( ValueError , TypeError ): self . params = [] try : _dm = docments ( obj , full = True , returns = returns ) except : _dm = {} if 'self' in _dm : del _dm [ 'self' ] for d in _dm . values (): d [ 'docment' ] = ifnone ( d [ 'docment' ], inspect . _empty ) self . dm = _dm @property def _columns ( self ): \"Compute the set of fields that have at least one non-empty value so we don't show tables empty columns\" cols = set ( flatten ( L ( self . dm . values ()) . filter () . map ( _non_empty_keys ))) candidates = self . _map if self . verbose else { 'docment' : 'Details' } return OrderedDict ({ k : v for k , v in candidates . items () if k in cols }) @property def has_docment ( self ): return 'docment' in self . _columns and self . _row_list @property def has_return ( self ): return self . returns and bool ( _non_empty_keys ( self . dm . get ( 'return' , {}))) def _row ( self , nm , props ): \"unpack data for single row to correspond with column names.\" return [ nm ] + [ props [ c ] for c in self . _columns ] @property def _row_list ( self ): \"unpack data for all rows.\" ordered_params = [( p , self . dm [ p ]) for p in self . params if p != 'self' and p in self . dm ] return L ([ self . _row ( nm , props ) for nm , props in ordered_params ]) @property def _hdr_list ( self ): return [ ' ' ] + [ _bold ( l ) for l in L ( self . _columns . values ())] @property def hdr_str ( self ): \"The markdown string for the header portion of the table\" md = _list2row ( self . _hdr_list ) return md + ' \\n ' + _list2row ([ '-' * len ( l ) for l in self . _hdr_list ]) @property def params_str ( self ): \"The markdown string for the parameters portion of the table.\" return ' \\n ' . join ( self . _row_list . map ( _list2row )) @property def return_str ( self ): \"The markdown string for the returns portion of the table.\" return _list2row ([ '**Returns**' ] + [ _bold ( _maybe_nm ( self . dm [ 'return' ][ c ])) for c in self . _columns ]) def _repr_markdown_ ( self ): if not self . has_docment : return '' _tbl = [ self . hdr_str , self . params_str ] if self . has_return : _tbl . append ( self . return_str ) return ' \\n ' . join ( _tbl ) def __eq__ ( self , other ): return self . __str__ () == str ( other ) . strip () __str__ = _repr_markdown_ __repr__ = basic_repr () hdr_str property readonly \u00a4 The markdown string for the header portion of the table params_str property readonly \u00a4 The markdown string for the parameters portion of the table. return_str property readonly \u00a4 The markdown string for the returns portion of the table. __init__ ( self , obj , verbose = True , returns = True ) special \u00a4 Compute the docment table string Source code in nbdev/showdoc.py def __init__ ( self , obj , verbose = True , returns = True ): \"Compute the docment table string\" self . verbose = verbose self . returns = False if isdataclass ( obj ) else returns try : self . params = L ( signature_ex ( obj , eval_str = True ) . parameters . keys ()) except ( ValueError , TypeError ): self . params = [] try : _dm = docments ( obj , full = True , returns = returns ) except : _dm = {} if 'self' in _dm : del _dm [ 'self' ] for d in _dm . values (): d [ 'docment' ] = ifnone ( d [ 'docment' ], inspect . _empty ) self . dm = _dm ShowDocRenderer \u00a4 Source code in nbdev/showdoc.py class ShowDocRenderer : def __init__ ( self , sym , name : str | None = None , title_level : int = 3 ): \"Show documentation for `sym`\" sym = getattr ( sym , '__wrapped__' , sym ) sym = getattr ( sym , 'fget' , None ) or getattr ( sym , 'fset' , None ) or sym store_attr () self . nm = name or qual_name ( sym ) self . isfunc = inspect . isfunction ( sym ) try : self . sig = signature_ex ( sym , eval_str = True ) except ( ValueError , TypeError ): self . sig = None self . docs = _docstring ( sym ) self . dm = DocmentTbl ( sym ) self . fn = _fullname ( sym ) __repr__ = basic_repr () __init__ ( self , sym , name = None , title_level = 3 ) special \u00a4 Show documentation for sym Source code in nbdev/showdoc.py def __init__ ( self , sym , name : str | None = None , title_level : int = 3 ): \"Show documentation for `sym`\" sym = getattr ( sym , '__wrapped__' , sym ) sym = getattr ( sym , 'fget' , None ) or getattr ( sym , 'fset' , None ) or sym store_attr () self . nm = name or qual_name ( sym ) self . isfunc = inspect . isfunction ( sym ) try : self . sig = signature_ex ( sym , eval_str = True ) except ( ValueError , TypeError ): self . sig = None self . docs = _docstring ( sym ) self . dm = DocmentTbl ( sym ) self . fn = _fullname ( sym ) colab_link ( path ) \u00a4 Get a link to the notebook at path on Colab Source code in nbdev/showdoc.py def colab_link ( path ): \"Get a link to the notebook at `path` on Colab\" from IPython.display import Markdown cfg = get_config () pre = 'https://colab.research.google.com/github/' res = f ' { pre }{ cfg . user } / { cfg . lib_name } /blob/ { cfg . branch } / { cfg . nbs_path . name } / { path } .ipynb' display ( Markdown ( f '[Open ` { path } ` in Colab]( { res } )' )) doc ( elt ) \u00a4 Show show_doc info along with link to docs Source code in nbdev/showdoc.py def doc ( elt ): \"Show `show_doc` info along with link to docs\" BasicHtmlRenderer ( elt ) . doc () show_doc ( sym , renderer = None , name = None , title_level = 3 ) \u00a4 Show signature and docstring for sym Source code in nbdev/showdoc.py def show_doc ( sym , # Symbol to document renderer = None , # Optional renderer (defaults to markdown) name : str | None = None , # Optionally override displayed name of `sym` title_level : int = 3 ): # Heading level to use for symbol name \"Show signature and docstring for `sym`\" if renderer is None : renderer = get_config () . get ( 'renderer' , None ) if renderer is None : renderer = BasicMarkdownRenderer elif isinstance ( renderer , str ): p , m = renderer . rsplit ( '.' , 1 ) renderer = getattr ( import_module ( p ), m ) if isinstance ( sym , TypeDispatch ): pass else : return renderer ( sym or show_doc , name = name , title_level = title_level ) showdoc_nm ( tree ) \u00a4 Get the fully qualified name for showdoc. Source code in nbdev/showdoc.py def showdoc_nm ( tree ): \"Get the fully qualified name for showdoc.\" return ifnone ( patch_name ( tree ), tree . name )","title":"nbdev.showdoc"},{"location":"nbdev_api/nbdev/showdoc/#nbdev.showdoc.BasicHtmlRenderer","text":"Simple HTML renderer for show_doc Source code in nbdev/showdoc.py class BasicHtmlRenderer ( ShowDocRenderer ): \"Simple HTML renderer for `show_doc`\" def _repr_html_ ( self ): doc = '<hr/> \\n ' doc += f '<h { self . title_level } > { self . nm } </h { self . title_level } > \\n ' doc += f '<blockquote><pre><code> { self . nm }{ _fmt_sig ( self . sig ) } </code></pre></blockquote>' if self . docs : doc += f \"<p> { self . docs } </p>\" return doc def doc ( self ): \"Show `show_doc` info along with link to docs\" from IPython.display import display , HTML res = self . _repr_html_ () docs = NbdevLookup () . doc ( self . fn ) if docs is not None : res += ' \\n <p>' + _html_link ( docs , \"Show in docs\" ) + '</p>' display ( HTML ( res ))","title":"BasicHtmlRenderer"},{"location":"nbdev_api/nbdev/showdoc/#nbdev.showdoc.BasicHtmlRenderer.doc","text":"Show show_doc info along with link to docs Source code in nbdev/showdoc.py def doc ( self ): \"Show `show_doc` info along with link to docs\" from IPython.display import display , HTML res = self . _repr_html_ () docs = NbdevLookup () . doc ( self . fn ) if docs is not None : res += ' \\n <p>' + _html_link ( docs , \"Show in docs\" ) + '</p>' display ( HTML ( res ))","title":"doc()"},{"location":"nbdev_api/nbdev/showdoc/#nbdev.showdoc.BasicMarkdownRenderer","text":"Markdown renderer for show_doc Source code in nbdev/showdoc.py class BasicMarkdownRenderer ( ShowDocRenderer ): \"Markdown renderer for `show_doc`\" def _repr_markdown_ ( self ): doc = '--- \\n\\n ' src = NbdevLookup () . code ( self . fn ) if src : doc += _ext_link ( src , 'source' , 'style=\"float:right; font-size:smaller\"' ) + ' \\n\\n ' h = '#' * self . title_level doc += f ' { h } { self . nm } \\n\\n ' sig = _wrap_sig ( f \" { self . nm } { _fmt_sig ( self . sig ) } \" ) if self . sig else '' doc += f ' { sig } ' if self . docs : doc += f \" \\n\\n { self . docs } \" if self . dm . has_docment : doc += f \" \\n\\n { self . dm } \" return doc __repr__ = __str__ = _repr_markdown_","title":"BasicMarkdownRenderer"},{"location":"nbdev_api/nbdev/showdoc/#nbdev.showdoc.DocmentTbl","text":"Source code in nbdev/showdoc.py class DocmentTbl : # this is the column order we want these items to appear _map = OrderedDict ({ 'anno' : 'Type' , 'default' : 'Default' , 'docment' : 'Details' }) def __init__ ( self , obj , verbose = True , returns = True ): \"Compute the docment table string\" self . verbose = verbose self . returns = False if isdataclass ( obj ) else returns try : self . params = L ( signature_ex ( obj , eval_str = True ) . parameters . keys ()) except ( ValueError , TypeError ): self . params = [] try : _dm = docments ( obj , full = True , returns = returns ) except : _dm = {} if 'self' in _dm : del _dm [ 'self' ] for d in _dm . values (): d [ 'docment' ] = ifnone ( d [ 'docment' ], inspect . _empty ) self . dm = _dm @property def _columns ( self ): \"Compute the set of fields that have at least one non-empty value so we don't show tables empty columns\" cols = set ( flatten ( L ( self . dm . values ()) . filter () . map ( _non_empty_keys ))) candidates = self . _map if self . verbose else { 'docment' : 'Details' } return OrderedDict ({ k : v for k , v in candidates . items () if k in cols }) @property def has_docment ( self ): return 'docment' in self . _columns and self . _row_list @property def has_return ( self ): return self . returns and bool ( _non_empty_keys ( self . dm . get ( 'return' , {}))) def _row ( self , nm , props ): \"unpack data for single row to correspond with column names.\" return [ nm ] + [ props [ c ] for c in self . _columns ] @property def _row_list ( self ): \"unpack data for all rows.\" ordered_params = [( p , self . dm [ p ]) for p in self . params if p != 'self' and p in self . dm ] return L ([ self . _row ( nm , props ) for nm , props in ordered_params ]) @property def _hdr_list ( self ): return [ ' ' ] + [ _bold ( l ) for l in L ( self . _columns . values ())] @property def hdr_str ( self ): \"The markdown string for the header portion of the table\" md = _list2row ( self . _hdr_list ) return md + ' \\n ' + _list2row ([ '-' * len ( l ) for l in self . _hdr_list ]) @property def params_str ( self ): \"The markdown string for the parameters portion of the table.\" return ' \\n ' . join ( self . _row_list . map ( _list2row )) @property def return_str ( self ): \"The markdown string for the returns portion of the table.\" return _list2row ([ '**Returns**' ] + [ _bold ( _maybe_nm ( self . dm [ 'return' ][ c ])) for c in self . _columns ]) def _repr_markdown_ ( self ): if not self . has_docment : return '' _tbl = [ self . hdr_str , self . params_str ] if self . has_return : _tbl . append ( self . return_str ) return ' \\n ' . join ( _tbl ) def __eq__ ( self , other ): return self . __str__ () == str ( other ) . strip () __str__ = _repr_markdown_ __repr__ = basic_repr ()","title":"DocmentTbl"},{"location":"nbdev_api/nbdev/showdoc/#nbdev.showdoc.DocmentTbl.hdr_str","text":"The markdown string for the header portion of the table","title":"hdr_str"},{"location":"nbdev_api/nbdev/showdoc/#nbdev.showdoc.DocmentTbl.params_str","text":"The markdown string for the parameters portion of the table.","title":"params_str"},{"location":"nbdev_api/nbdev/showdoc/#nbdev.showdoc.DocmentTbl.return_str","text":"The markdown string for the returns portion of the table.","title":"return_str"},{"location":"nbdev_api/nbdev/showdoc/#nbdev.showdoc.DocmentTbl.__init__","text":"Compute the docment table string Source code in nbdev/showdoc.py def __init__ ( self , obj , verbose = True , returns = True ): \"Compute the docment table string\" self . verbose = verbose self . returns = False if isdataclass ( obj ) else returns try : self . params = L ( signature_ex ( obj , eval_str = True ) . parameters . keys ()) except ( ValueError , TypeError ): self . params = [] try : _dm = docments ( obj , full = True , returns = returns ) except : _dm = {} if 'self' in _dm : del _dm [ 'self' ] for d in _dm . values (): d [ 'docment' ] = ifnone ( d [ 'docment' ], inspect . _empty ) self . dm = _dm","title":"__init__()"},{"location":"nbdev_api/nbdev/showdoc/#nbdev.showdoc.ShowDocRenderer","text":"Source code in nbdev/showdoc.py class ShowDocRenderer : def __init__ ( self , sym , name : str | None = None , title_level : int = 3 ): \"Show documentation for `sym`\" sym = getattr ( sym , '__wrapped__' , sym ) sym = getattr ( sym , 'fget' , None ) or getattr ( sym , 'fset' , None ) or sym store_attr () self . nm = name or qual_name ( sym ) self . isfunc = inspect . isfunction ( sym ) try : self . sig = signature_ex ( sym , eval_str = True ) except ( ValueError , TypeError ): self . sig = None self . docs = _docstring ( sym ) self . dm = DocmentTbl ( sym ) self . fn = _fullname ( sym ) __repr__ = basic_repr ()","title":"ShowDocRenderer"},{"location":"nbdev_api/nbdev/showdoc/#nbdev.showdoc.ShowDocRenderer.__init__","text":"Show documentation for sym Source code in nbdev/showdoc.py def __init__ ( self , sym , name : str | None = None , title_level : int = 3 ): \"Show documentation for `sym`\" sym = getattr ( sym , '__wrapped__' , sym ) sym = getattr ( sym , 'fget' , None ) or getattr ( sym , 'fset' , None ) or sym store_attr () self . nm = name or qual_name ( sym ) self . isfunc = inspect . isfunction ( sym ) try : self . sig = signature_ex ( sym , eval_str = True ) except ( ValueError , TypeError ): self . sig = None self . docs = _docstring ( sym ) self . dm = DocmentTbl ( sym ) self . fn = _fullname ( sym )","title":"__init__()"},{"location":"nbdev_api/nbdev/showdoc/#nbdev.showdoc.colab_link","text":"Get a link to the notebook at path on Colab Source code in nbdev/showdoc.py def colab_link ( path ): \"Get a link to the notebook at `path` on Colab\" from IPython.display import Markdown cfg = get_config () pre = 'https://colab.research.google.com/github/' res = f ' { pre }{ cfg . user } / { cfg . lib_name } /blob/ { cfg . branch } / { cfg . nbs_path . name } / { path } .ipynb' display ( Markdown ( f '[Open ` { path } ` in Colab]( { res } )' ))","title":"colab_link()"},{"location":"nbdev_api/nbdev/showdoc/#nbdev.showdoc.doc","text":"Show show_doc info along with link to docs Source code in nbdev/showdoc.py def doc ( elt ): \"Show `show_doc` info along with link to docs\" BasicHtmlRenderer ( elt ) . doc ()","title":"doc()"},{"location":"nbdev_api/nbdev/showdoc/#nbdev.showdoc.show_doc","text":"Show signature and docstring for sym Source code in nbdev/showdoc.py def show_doc ( sym , # Symbol to document renderer = None , # Optional renderer (defaults to markdown) name : str | None = None , # Optionally override displayed name of `sym` title_level : int = 3 ): # Heading level to use for symbol name \"Show signature and docstring for `sym`\" if renderer is None : renderer = get_config () . get ( 'renderer' , None ) if renderer is None : renderer = BasicMarkdownRenderer elif isinstance ( renderer , str ): p , m = renderer . rsplit ( '.' , 1 ) renderer = getattr ( import_module ( p ), m ) if isinstance ( sym , TypeDispatch ): pass else : return renderer ( sym or show_doc , name = name , title_level = title_level )","title":"show_doc()"},{"location":"nbdev_api/nbdev/showdoc/#nbdev.showdoc.showdoc_nm","text":"Get the fully qualified name for showdoc. Source code in nbdev/showdoc.py def showdoc_nm ( tree ): \"Get the fully qualified name for showdoc.\" return ifnone ( patch_name ( tree ), tree . name )","title":"showdoc_nm()"},{"location":"nbdev_api/nbdev/sync/","text":"absolute_import ( name , fname , level ) \u00a4 Unwarps a relative import in name according to fname Source code in nbdev/sync.py def absolute_import ( name , fname , level ): \"Unwarps a relative import in `name` according to `fname`\" if not level : return name mods = fname . split ( os . path . sep ) if not name : return '.' . join ( mods ) return '.' . join ( mods [: len ( mods ) - level + 1 ]) + f \". { name } \" nbdev_update ( fname = None ) \u00a4 Propagate change in modules matching fname to notebooks that created them Source code in nbdev/sync.py @call_parse def nbdev_update ( fname : str = None ): # A Python file name to update \"Propagate change in modules matching `fname` to notebooks that created them\" if fname and fname . endswith ( '.ipynb' ): raise ValueError ( \"`nbdev_update` operates on .py files. If you wish to convert notebooks instead, see `nbdev_export`.\" ) if os . environ . get ( 'IN_TEST' , 0 ): return cfg = get_config () fname = Path ( fname or cfg . lib_path ) lib_dir = cfg . lib_path . parent files = globtastic ( fname , file_glob = '*.py' , skip_folder_re = '^[_.]' ) . filter ( lambda x : str ( Path ( x ) . absolute () . relative_to ( lib_dir ) in _mod_files ())) files . map ( _update_mod , lib_dir = lib_dir )","title":"nbdev.sync"},{"location":"nbdev_api/nbdev/sync/#nbdev.sync.absolute_import","text":"Unwarps a relative import in name according to fname Source code in nbdev/sync.py def absolute_import ( name , fname , level ): \"Unwarps a relative import in `name` according to `fname`\" if not level : return name mods = fname . split ( os . path . sep ) if not name : return '.' . join ( mods ) return '.' . join ( mods [: len ( mods ) - level + 1 ]) + f \". { name } \"","title":"absolute_import()"},{"location":"nbdev_api/nbdev/sync/#nbdev.sync.nbdev_update","text":"Propagate change in modules matching fname to notebooks that created them Source code in nbdev/sync.py @call_parse def nbdev_update ( fname : str = None ): # A Python file name to update \"Propagate change in modules matching `fname` to notebooks that created them\" if fname and fname . endswith ( '.ipynb' ): raise ValueError ( \"`nbdev_update` operates on .py files. If you wish to convert notebooks instead, see `nbdev_export`.\" ) if os . environ . get ( 'IN_TEST' , 0 ): return cfg = get_config () fname = Path ( fname or cfg . lib_path ) lib_dir = cfg . lib_path . parent files = globtastic ( fname , file_glob = '*.py' , skip_folder_re = '^[_.]' ) . filter ( lambda x : str ( Path ( x ) . absolute () . relative_to ( lib_dir ) in _mod_files ())) files . map ( _update_mod , lib_dir = lib_dir )","title":"nbdev_update()"},{"location":"nbdev_api/nbdev/test/","text":"nbdev_test ( path = None , flags = '' , n_workers = None , timing = False , do_print = False , pause = 0.01 , ignore_fname = '.notest' , * , symlinks = False , file_glob = '*.ipynb' , file_re = None , folder_re = None , skip_file_glob = None , skip_file_re = '^[_.]' , skip_folder_re = '^[_.]' ) \u00a4 Test in parallel notebooks matching path , passing along flags Source code in nbdev/test.py @call_parse @delegates ( nbglob_cli ) def nbdev_test ( path : str = None , # A notebook name or glob to test flags : str = '' , # Space separated list of test flags to run that are normally ignored n_workers : int = None , # Number of workers timing : bool = False , # Time each notebook to see which are slow do_print : bool = False , # Print start and end of each notebook pause : float = 0.01 , # Pause time (in seconds) between notebooks to avoid race conditions ignore_fname : str = '.notest' , # Filename that will result in siblings being ignored ** kwargs ): \"Test in parallel notebooks matching `path`, passing along `flags`\" skip_flags = get_config () . tst_flags . split () force_flags = flags . split () files = nbglob ( path , as_path = True , ** kwargs ) files = [ f . absolute () for f in sorted ( files ) if _keep_file ( f , ignore_fname )] if len ( files ) == 0 : return print ( 'No files were eligible for testing' ) if n_workers is None : n_workers = 0 if len ( files ) == 1 else min ( num_cpus (), 8 ) if IN_NOTEBOOK : kw = { 'method' : 'spawn' } if os . name == 'nt' else { 'method' : 'forkserver' } else : kw = {} with working_directory ( get_config () . nbs_path ): results = parallel ( test_nb , files , skip_flags = skip_flags , force_flags = force_flags , n_workers = n_workers , basepath = get_config () . config_path , pause = pause , do_print = do_print , ** kw ) passed , times = zip ( * results ) if all ( passed ): print ( \"Success.\" ) else : _fence = '=' * 50 failed = ' \\n\\t ' . join ( f . name for p , f in zip ( passed , files ) if not p ) sys . stderr . write ( f \" \\n nbdev Tests Failed On The Following Notebooks: \\n { _fence } \\n\\t { failed } \\n \" ) sys . exit ( 1 ) if timing : for i , t in sorted ( enumerate ( times ), key = lambda o : o [ 1 ], reverse = True ): print ( f \" { files [ i ] . name } : { int ( t ) } secs\" ) test_nb ( fn , skip_flags = None , force_flags = None , do_print = False , showerr = True , basepath = None ) \u00a4 Execute tests in notebook in fn except those with skip_flags Source code in nbdev/test.py def test_nb ( fn , # file name of notebook to test skip_flags = None , # list of flags marking cells to skip force_flags = None , # list of flags marking cells to always run do_print = False , # print completion? showerr = True , # print errors to stderr? basepath = None ): # path to add to sys.path \"Execute tests in notebook in `fn` except those with `skip_flags`\" if basepath : sys . path . insert ( 0 , str ( basepath )) if not IN_NOTEBOOK : os . environ [ \"IN_TEST\" ] = '1' flags = set ( L ( skip_flags )) - set ( L ( force_flags )) nb = NBProcessor ( fn , procs = FrontmatterProc , process = True ) . nb fm = getattr ( nb , 'frontmatter_' , {}) if str2bool ( fm . get ( 'skip_exec' , False )) or nb_lang ( nb ) != 'python' : return True , 0 def _no_eval ( cell ): if cell . cell_type != 'code' : return True if 'nbdev_export' + '(' in cell . source : return True direc = getattr ( cell , 'directives_' , {}) or {} if direc . get ( 'eval:' , [ '' ])[ 0 ] . lower () == 'false' : return True return flags & direc . keys () start = time . time () k = CaptureShell ( fn ) if do_print : print ( f 'Starting { fn } ' ) try : with working_directory ( fn . parent ): k . run_all ( nb , exc_stop = True , preproc = _no_eval ) res = True except : if showerr : sys . stderr . write ( k . prettytb ( fname = fn ) + ' \\n ' ) res = False if do_print : print ( f '- Completed { fn } ' ) return res , time . time () - start","title":"nbdev.test"},{"location":"nbdev_api/nbdev/test/#nbdev.test.nbdev_test","text":"Test in parallel notebooks matching path , passing along flags Source code in nbdev/test.py @call_parse @delegates ( nbglob_cli ) def nbdev_test ( path : str = None , # A notebook name or glob to test flags : str = '' , # Space separated list of test flags to run that are normally ignored n_workers : int = None , # Number of workers timing : bool = False , # Time each notebook to see which are slow do_print : bool = False , # Print start and end of each notebook pause : float = 0.01 , # Pause time (in seconds) between notebooks to avoid race conditions ignore_fname : str = '.notest' , # Filename that will result in siblings being ignored ** kwargs ): \"Test in parallel notebooks matching `path`, passing along `flags`\" skip_flags = get_config () . tst_flags . split () force_flags = flags . split () files = nbglob ( path , as_path = True , ** kwargs ) files = [ f . absolute () for f in sorted ( files ) if _keep_file ( f , ignore_fname )] if len ( files ) == 0 : return print ( 'No files were eligible for testing' ) if n_workers is None : n_workers = 0 if len ( files ) == 1 else min ( num_cpus (), 8 ) if IN_NOTEBOOK : kw = { 'method' : 'spawn' } if os . name == 'nt' else { 'method' : 'forkserver' } else : kw = {} with working_directory ( get_config () . nbs_path ): results = parallel ( test_nb , files , skip_flags = skip_flags , force_flags = force_flags , n_workers = n_workers , basepath = get_config () . config_path , pause = pause , do_print = do_print , ** kw ) passed , times = zip ( * results ) if all ( passed ): print ( \"Success.\" ) else : _fence = '=' * 50 failed = ' \\n\\t ' . join ( f . name for p , f in zip ( passed , files ) if not p ) sys . stderr . write ( f \" \\n nbdev Tests Failed On The Following Notebooks: \\n { _fence } \\n\\t { failed } \\n \" ) sys . exit ( 1 ) if timing : for i , t in sorted ( enumerate ( times ), key = lambda o : o [ 1 ], reverse = True ): print ( f \" { files [ i ] . name } : { int ( t ) } secs\" )","title":"nbdev_test()"},{"location":"nbdev_api/nbdev/test/#nbdev.test.test_nb","text":"Execute tests in notebook in fn except those with skip_flags Source code in nbdev/test.py def test_nb ( fn , # file name of notebook to test skip_flags = None , # list of flags marking cells to skip force_flags = None , # list of flags marking cells to always run do_print = False , # print completion? showerr = True , # print errors to stderr? basepath = None ): # path to add to sys.path \"Execute tests in notebook in `fn` except those with `skip_flags`\" if basepath : sys . path . insert ( 0 , str ( basepath )) if not IN_NOTEBOOK : os . environ [ \"IN_TEST\" ] = '1' flags = set ( L ( skip_flags )) - set ( L ( force_flags )) nb = NBProcessor ( fn , procs = FrontmatterProc , process = True ) . nb fm = getattr ( nb , 'frontmatter_' , {}) if str2bool ( fm . get ( 'skip_exec' , False )) or nb_lang ( nb ) != 'python' : return True , 0 def _no_eval ( cell ): if cell . cell_type != 'code' : return True if 'nbdev_export' + '(' in cell . source : return True direc = getattr ( cell , 'directives_' , {}) or {} if direc . get ( 'eval:' , [ '' ])[ 0 ] . lower () == 'false' : return True return flags & direc . keys () start = time . time () k = CaptureShell ( fn ) if do_print : print ( f 'Starting { fn } ' ) try : with working_directory ( fn . parent ): k . run_all ( nb , exc_stop = True , preproc = _no_eval ) res = True except : if showerr : sys . stderr . write ( k . prettytb ( fname = fn ) + ' \\n ' ) res = False if do_print : print ( f '- Completed { fn } ' ) return res , time . time () - start","title":"test_nb()"},{"location":"nbdev_cli/nbdev_bump_version/","text":"usage: nbdev_bump_version [-h] [--part PART] [--unbump] Increment version in settings.ini by one optional arguments: -h, --help show this help message and exit --part PART Part of version to bump (default: 2) --unbump Reduce version instead of increasing it (default: False)","title":"nbdev_bump_version"},{"location":"nbdev_cli/nbdev_changelog/","text":"usage: nbdev_changelog [-h] [--debug] [--repo REPO] Create a CHANGELOG.md file from closed and labeled GitHub issues optional arguments: -h, --help show this help message and exit --debug Print info to be added to CHANGELOG, instead of updating file (default: False) --repo REPO repo to use instead of `lib_name` from `settings.ini`","title":"nbdev_changelog"},{"location":"nbdev_cli/nbdev_clean/","text":"usage: nbdev_clean [-h] [--fname FNAME] [--clear_all] [--disp] [--stdin] Clean all notebooks in `fname` to avoid merge conflicts optional arguments: -h, --help show this help message and exit --fname FNAME A notebook name or glob to clean --clear_all Remove all cell metadata and cell outputs? (default: False) --disp Print the cleaned outputs (default: False) --stdin Read notebook from input stream (default: False)","title":"nbdev_clean"},{"location":"nbdev_cli/nbdev_conda/","text":"usage: nbdev_conda [-h] [--path PATH] [--do_build DO_BUILD] [--build_args BUILD_ARGS] [--skip_upload] [--mambabuild] [--upload_user UPLOAD_USER] Create a `meta.yaml` file ready to be built into a package, and optionally build and upload it optional arguments: -h, --help show this help message and exit --path PATH Path where package will be created (default: conda) --do_build DO_BUILD Run `conda build` step (default: True) --build_args BUILD_ARGS Additional args (as str) to send to `conda build` (default: ) --skip_upload Skip `anaconda upload` step (default: False) --mambabuild Use `mambabuild` (requires `boa`) (default: False) --upload_user UPLOAD_USER Optional user to upload package to","title":"nbdev_conda"},{"location":"nbdev_cli/nbdev_create_config/","text":"usage: nbdev_create_config [-h] [--lib_name LIB_NAME] [--git_url GIT_URL] [--custom_sidebar CUSTOM_SIDEBAR] [--nbs_path NBS_PATH] [--lib_path LIB_PATH] [--doc_path DOC_PATH] [--tst_flags TST_FLAGS] [--version VERSION] [--doc_host DOC_HOST] [--doc_baseurl DOC_BASEURL] [--keywords KEYWORDS] [--license LICENSE] [--copyright COPYRIGHT] [--status STATUS] [--min_python MIN_PYTHON] [--audience AUDIENCE] [--language LANGUAGE] [--recursive RECURSIVE] [--black_formatting BLACK_FORMATTING] [--readme_nb README_NB] [--title TITLE] [--allowed_metadata_keys ALLOWED_METADATA_KEYS] [--allowed_cell_metadata_keys ALLOWED_CELL_METADATA_KEYS] [--jupyter_hooks JUPYTER_HOOKS] [--clean_ids CLEAN_IDS] [--clear_all CLEAR_ALL] [--put_version_in_init PUT_VERSION_IN_INIT] [--repo REPO] [--branch BRANCH] [--user USER] [--author AUTHOR] [--author_email AUTHOR_EMAIL] [--description DESCRIPTION] [--path PATH] [--cfg_name CFG_NAME] Create a config file. optional arguments: -h, --help show this help message and exit --lib_name LIB_NAME Package name (default: %(repo)s) --git_url GIT_URL Repo URL (default: https://github.com/%(user)s/%(repo)s) --custom_sidebar CUSTOM_SIDEBAR Use a custom sidebar.yml? (default: False) --nbs_path NBS_PATH Path to notebooks (default: nbs) --lib_path LIB_PATH Path to package root (default: `repo` with `-` replaced by `_`) --doc_path DOC_PATH Path to rendered docs (default: _docs) --tst_flags TST_FLAGS Test flags (default: notest) --version VERSION Version of this release (default: 0.0.1) --doc_host DOC_HOST Hostname for docs (default: https://%(user)s.github.io) --doc_baseurl DOC_BASEURL Base URL for docs (default: /%(repo)s) --keywords KEYWORDS Package keywords (default: nbdev jupyter notebook python) --license LICENSE License for the package (default: apache2) --copyright COPYRIGHT Copyright for the package, defaults to '`current_year` onwards, `author`' --status STATUS Development status PyPI classifier (default: 3) --min_python MIN_PYTHON Minimum Python version PyPI classifier (default: 3.7) --audience AUDIENCE Intended audience PyPI classifier (default: Developers) --language LANGUAGE Language PyPI classifier (default: English) --recursive RECURSIVE Include subfolders in notebook globs? (default: True) --black_formatting BLACK_FORMATTING Format libraries with black? (default: False) --readme_nb README_NB Notebook to export as repo readme (default: index.ipynb) --title TITLE Quarto website title (default: %(lib_name)s) --allowed_metadata_keys ALLOWED_METADATA_KEYS Preserve the list of keys in the main notebook metadata (default: ) --allowed_cell_metadata_keys ALLOWED_CELL_METADATA_KEYS Preserve the list of keys in cell level metadata (default: ) --jupyter_hooks JUPYTER_HOOKS Run Jupyter hooks? (default: True) --clean_ids CLEAN_IDS Remove ids from plaintext reprs? (default: True) --clear_all CLEAR_ALL Remove all cell metadata and cell outputs? (default: False) --put_version_in_init PUT_VERSION_IN_INIT Add the version to the main __init__.py in nbdev_export (default: True) --repo REPO Repo name --branch BRANCH Repo default branch --user USER Repo username --author AUTHOR Package author's name --author_email AUTHOR_EMAIL Package author's email address --description DESCRIPTION Short summary of the package --path PATH Path to create config file (default: .) --cfg_name CFG_NAME Name of config file to create (default: settings.ini)","title":"nbdev_create_config"},{"location":"nbdev_cli/nbdev_docs/","text":"usage: nbdev_docs [-h] [--path PATH] [--symlinks] [--file_glob FILE_GLOB] [--file_re FILE_RE] [--folder_re FOLDER_RE] [--skip_file_glob SKIP_FILE_GLOB] [--skip_file_re SKIP_FILE_RE] [--skip_folder_re SKIP_FOLDER_RE] [--n_workers N_WORKERS] Create Quarto docs and README.md optional arguments: -h, --help show this help message and exit --path PATH Path to notebooks --symlinks Follow symlinks? (default: False) --file_glob FILE_GLOB Only include files matching glob --file_re FILE_RE Only include files matching regex (default: \\.(?:ipynb|qmd|html)$) --folder_re FOLDER_RE Only enter folders matching regex --skip_file_glob SKIP_FILE_GLOB Skip files matching glob --skip_file_re SKIP_FILE_RE Skip files matching regex (default: ^[_.]) --skip_folder_re SKIP_FOLDER_RE Skip folders matching regex (default: ^[_.]) --n_workers N_WORKERS Number of workers (default: 2)","title":"nbdev_docs"},{"location":"nbdev_cli/nbdev_export/","text":"usage: nbdev_export [-h] [--path PATH] [--symlinks] [--file_glob FILE_GLOB] [--file_re FILE_RE] [--folder_re FOLDER_RE] [--skip_file_glob SKIP_FILE_GLOB] [--skip_file_re SKIP_FILE_RE] [--skip_folder_re SKIP_FOLDER_RE] Export notebooks in `path` to Python modules optional arguments: -h, --help show this help message and exit --path PATH Path or filename --symlinks Follow symlinks? (default: False) --file_glob FILE_GLOB Only include files matching glob (default: *.ipynb) --file_re FILE_RE Only include files matching regex --folder_re FOLDER_RE Only enter folders matching regex --skip_file_glob SKIP_FILE_GLOB Skip files matching glob --skip_file_re SKIP_FILE_RE Skip files matching regex (default: ^[_.]) --skip_folder_re SKIP_FOLDER_RE Skip folders matching regex (default: ^[_.])","title":"nbdev_export"},{"location":"nbdev_cli/nbdev_filter/","text":"usage: nbdev_filter [-h] [--nb_txt NB_TXT] [--fname FNAME] [--printit PRINTIT] A notebook filter for Quarto optional arguments: -h, --help show this help message and exit --nb_txt NB_TXT Notebook text (uses stdin if not provided) --fname FNAME Notebook to read (uses `nb_txt` if not provided) --printit PRINTIT Print to stdout? (default: True)","title":"nbdev_filter"},{"location":"nbdev_cli/nbdev_fix/","text":"usage: nbdev_fix [-h] [--outname OUTNAME] [--nobackup NOBACKUP] [--theirs] [--noprint] nbname Create working notebook from conflicted notebook `nbname` positional arguments: nbname Notebook filename to fix optional arguments: -h, --help show this help message and exit --outname OUTNAME Filename of output notebook (defaults to `nbname`) --nobackup NOBACKUP Do not backup `nbname` to `nbname`.bak if `outname` not provided (default: True) --theirs Use their outputs and metadata instead of ours (default: False) --noprint Do not print info about whether conflicts are found (default: False)","title":"nbdev_fix"},{"location":"nbdev_cli/nbdev_help/","text":"usage: nbdev_help [-h] Show help for all console scripts optional arguments: -h, --help show this help message and exit","title":"nbdev_help"},{"location":"nbdev_cli/nbdev_install/","text":"usage: nbdev_install [-h] Install Quarto and the current library optional arguments: -h, --help show this help message and exit","title":"nbdev_install"},{"location":"nbdev_cli/nbdev_install_hooks/","text":"usage: nbdev_install_hooks [-h] Install Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks optional arguments: -h, --help show this help message and exit","title":"nbdev_install_hooks"},{"location":"nbdev_cli/nbdev_install_quarto/","text":"usage: nbdev_install_quarto [-h] Install latest Quarto on macOS or Linux, prints instructions for Windows optional arguments: -h, --help show this help message and exit","title":"nbdev_install_quarto"},{"location":"nbdev_cli/nbdev_merge/","text":"usage: nbdev_merge [-h] base ours theirs path Git merge driver for notebooks positional arguments: base ours theirs path optional arguments: -h, --help show this help message and exit","title":"nbdev_merge"},{"location":"nbdev_cli/nbdev_migrate/","text":"usage: nbdev_migrate [-h] [--path PATH] [--no_skip] Convert all markdown and notebook files in `path` from v1 to v2 optional arguments: -h, --help show this help message and exit --path PATH A path or glob containing notebooks and markdown files to migrate --no_skip Do not skip directories beginning with an underscore (default: False)","title":"nbdev_migrate"},{"location":"nbdev_cli/nbdev_new/","text":"usage: nbdev_new [-h] [--lib_name LIB_NAME] [--git_url GIT_URL] [--custom_sidebar CUSTOM_SIDEBAR] [--nbs_path NBS_PATH] [--lib_path LIB_PATH] [--doc_path DOC_PATH] [--tst_flags TST_FLAGS] [--version VERSION] [--doc_host DOC_HOST] [--doc_baseurl DOC_BASEURL] [--keywords KEYWORDS] [--license LICENSE] [--copyright COPYRIGHT] [--status STATUS] [--min_python MIN_PYTHON] [--audience AUDIENCE] [--language LANGUAGE] [--recursive RECURSIVE] [--black_formatting BLACK_FORMATTING] [--readme_nb README_NB] [--title TITLE] [--allowed_metadata_keys ALLOWED_METADATA_KEYS] [--allowed_cell_metadata_keys ALLOWED_CELL_METADATA_KEYS] [--jupyter_hooks JUPYTER_HOOKS] [--clean_ids CLEAN_IDS] [--clear_all CLEAR_ALL] [--put_version_in_init PUT_VERSION_IN_INIT] [--repo REPO] [--branch BRANCH] [--user USER] [--author AUTHOR] [--author_email AUTHOR_EMAIL] [--description DESCRIPTION] [--path PATH] [--cfg_name CFG_NAME] Create an nbdev project. optional arguments: -h, --help show this help message and exit --lib_name LIB_NAME Package name (default: %(repo)s) --git_url GIT_URL Repo URL (default: https://github.com/%(user)s/%(repo)s) --custom_sidebar CUSTOM_SIDEBAR Use a custom sidebar.yml? (default: False) --nbs_path NBS_PATH Path to notebooks (default: nbs) --lib_path LIB_PATH Path to package root (default: `repo` with `-` replaced by `_`) --doc_path DOC_PATH Path to rendered docs (default: _docs) --tst_flags TST_FLAGS Test flags (default: notest) --version VERSION Version of this release (default: 0.0.1) --doc_host DOC_HOST Hostname for docs (default: https://%(user)s.github.io) --doc_baseurl DOC_BASEURL Base URL for docs (default: /%(repo)s) --keywords KEYWORDS Package keywords (default: nbdev jupyter notebook python) --license LICENSE License for the package (default: apache2) --copyright COPYRIGHT Copyright for the package, defaults to '`current_year` onwards, `author`' --status STATUS Development status PyPI classifier (default: 3) --min_python MIN_PYTHON Minimum Python version PyPI classifier (default: 3.7) --audience AUDIENCE Intended audience PyPI classifier (default: Developers) --language LANGUAGE Language PyPI classifier (default: English) --recursive RECURSIVE Include subfolders in notebook globs? (default: True) --black_formatting BLACK_FORMATTING Format libraries with black? (default: False) --readme_nb README_NB Notebook to export as repo readme (default: index.ipynb) --title TITLE Quarto website title (default: %(lib_name)s) --allowed_metadata_keys ALLOWED_METADATA_KEYS Preserve the list of keys in the main notebook metadata (default: ) --allowed_cell_metadata_keys ALLOWED_CELL_METADATA_KEYS Preserve the list of keys in cell level metadata (default: ) --jupyter_hooks JUPYTER_HOOKS Run Jupyter hooks? (default: True) --clean_ids CLEAN_IDS Remove ids from plaintext reprs? (default: True) --clear_all CLEAR_ALL Remove all cell metadata and cell outputs? (default: False) --put_version_in_init PUT_VERSION_IN_INIT Add the version to the main __init__.py in nbdev_export (default: True) --repo REPO Repo name --branch BRANCH Repo default branch --user USER Repo username --author AUTHOR Package author's name --author_email AUTHOR_EMAIL Package author's email address --description DESCRIPTION Short summary of the package --path PATH Path to create config file (default: .) --cfg_name CFG_NAME Name of config file to create (default: settings.ini)","title":"nbdev_new"},{"location":"nbdev_cli/nbdev_prepare/","text":"usage: nbdev_prepare [-h] Export, test, and clean notebooks, and render README if needed optional arguments: -h, --help show this help message and exit","title":"nbdev_prepare"},{"location":"nbdev_cli/nbdev_preview/","text":"usage: nbdev_preview [-h] [--path PATH] [--symlinks] [--file_glob FILE_GLOB] [--file_re FILE_RE] [--folder_re FOLDER_RE] [--skip_file_glob SKIP_FILE_GLOB] [--skip_file_re SKIP_FILE_RE] [--skip_folder_re SKIP_FOLDER_RE] [--port PORT] [--host HOST] [--n_workers N_WORKERS] Preview docs locally optional arguments: -h, --help show this help message and exit --path PATH Path to notebooks --symlinks Follow symlinks? (default: False) --file_glob FILE_GLOB Only include files matching glob --file_re FILE_RE Only include files matching regex (default: \\.(?:ipynb|qmd|html)$) --folder_re FOLDER_RE Only enter folders matching regex --skip_file_glob SKIP_FILE_GLOB Skip files matching glob --skip_file_re SKIP_FILE_RE Skip files matching regex (default: ^[_.]) --skip_folder_re SKIP_FOLDER_RE Skip folders matching regex (default: ^[_.]) --port PORT The port on which to run preview --host HOST The host on which to run preview --n_workers N_WORKERS Number of workers (default: 2)","title":"nbdev_preview"},{"location":"nbdev_cli/nbdev_proc_nbs/","text":"usage: nbdev_proc_nbs [-h] [--path PATH] [--symlinks] [--file_glob FILE_GLOB] [--file_re FILE_RE] [--folder_re FOLDER_RE] [--skip_file_glob SKIP_FILE_GLOB] [--skip_file_re SKIP_FILE_RE] [--skip_folder_re SKIP_FOLDER_RE] [--n_workers N_WORKERS] [--force] Process notebooks in `path` for docs rendering optional arguments: -h, --help show this help message and exit --path PATH Path to notebooks (default: ) --symlinks Follow symlinks? (default: False) --file_glob FILE_GLOB Only include files matching glob (default: ) --file_re FILE_RE Only include files matching glob (default: ) --folder_re FOLDER_RE Only enter folders matching regex --skip_file_glob SKIP_FILE_GLOB Skip files matching glob --skip_file_re SKIP_FILE_RE Skip files matching regex (default: ^[_.]) --skip_folder_re SKIP_FOLDER_RE Skip folders matching regex (default: ^[_.]) --n_workers N_WORKERS Number of workers (default: 2) --force Ignore cache and build all (default: False)","title":"nbdev_proc_nbs"},{"location":"nbdev_cli/nbdev_pypi/","text":"usage: nbdev_pypi [-h] [--repository REPOSITORY] Create and upload Python package to PyPI optional arguments: -h, --help show this help message and exit --repository REPOSITORY Respository to upload to (defined in ~/.pypirc) (default: pypi)","title":"nbdev_pypi"},{"location":"nbdev_cli/nbdev_readme/","text":"usage: nbdev_readme [-h] [--path PATH] [--chk_time] optional arguments: -h, --help show this help message and exit --path PATH Path to notebooks --chk_time Only build if out of date (default: False)","title":"nbdev_readme"},{"location":"nbdev_cli/nbdev_release_both/","text":"usage: nbdev_release_both [-h] [--path PATH] [--do_build DO_BUILD] [--build_args BUILD_ARGS] [--skip_upload] [--mambabuild] [--upload_user UPLOAD_USER] [--repository REPOSITORY] Release both conda and PyPI packages optional arguments: -h, --help show this help message and exit --path PATH Path where package will be created (default: conda) --do_build DO_BUILD Run `conda build` step (default: True) --build_args BUILD_ARGS Additional args (as str) to send to `conda build` (default: ) --skip_upload Skip `anaconda upload` step (default: False) --mambabuild Use `mambabuild` (requires `boa`) (default: False) --upload_user UPLOAD_USER Optional user to upload package to --repository REPOSITORY Pypi respository to upload to (defined in ~/.pypirc) (default: pypi)","title":"nbdev_release_both"},{"location":"nbdev_cli/nbdev_release_gh/","text":"usage: nbdev_release_gh [-h] [--token TOKEN] Calls `nbdev_changelog`, lets you edit the result, then pushes to git and calls `nbdev_release_git` optional arguments: -h, --help show this help message and exit --token TOKEN Optional GitHub token (otherwise `token` file is used)","title":"nbdev_release_gh"},{"location":"nbdev_cli/nbdev_release_git/","text":"usage: nbdev_release_git [-h] [--token TOKEN] Tag and create a release in GitHub for the current version optional arguments: -h, --help show this help message and exit --token TOKEN Optional GitHub token (otherwise `token` file is used)","title":"nbdev_release_git"},{"location":"nbdev_cli/nbdev_sidebar/","text":"usage: nbdev_sidebar [-h] [--path PATH] [--symlinks] [--file_glob FILE_GLOB] [--file_re FILE_RE] [--folder_re FOLDER_RE] [--skip_file_glob SKIP_FILE_GLOB] [--skip_file_re SKIP_FILE_RE] [--skip_folder_re SKIP_FOLDER_RE] [--printit] [--force] Create sidebar.yml optional arguments: -h, --help show this help message and exit --path PATH Path to notebooks --symlinks Follow symlinks? (default: False) --file_glob FILE_GLOB Only include files matching glob --file_re FILE_RE Only include files matching regex (default: \\.(?:ipynb|qmd|html)$) --folder_re FOLDER_RE Only enter folders matching regex --skip_file_glob SKIP_FILE_GLOB Skip files matching glob --skip_file_re SKIP_FILE_RE Skip files matching regex (default: ^[_.]) --skip_folder_re SKIP_FOLDER_RE Skip folders matching regex (default: (?:^[_.]|^www\\$)) --printit Print YAML for debugging (default: False) --force Create sidebar even if settings.ini custom_sidebar=False (default: False)","title":"nbdev_sidebar"},{"location":"nbdev_cli/nbdev_test/","text":"usage: nbdev_test [-h] [--path PATH] [--symlinks] [--file_glob FILE_GLOB] [--file_re FILE_RE] [--folder_re FOLDER_RE] [--skip_file_glob SKIP_FILE_GLOB] [--skip_file_re SKIP_FILE_RE] [--skip_folder_re SKIP_FOLDER_RE] [--flags FLAGS] [--n_workers N_WORKERS] [--timing] [--do_print] [--pause PAUSE] [--ignore_fname IGNORE_FNAME] Test in parallel notebooks matching `path`, passing along `flags` optional arguments: -h, --help show this help message and exit --path PATH A notebook name or glob to test --symlinks Follow symlinks? (default: False) --file_glob FILE_GLOB Only include files matching glob (default: *.ipynb) --file_re FILE_RE Only include files matching regex --folder_re FOLDER_RE Only enter folders matching regex --skip_file_glob SKIP_FILE_GLOB Skip files matching glob --skip_file_re SKIP_FILE_RE Skip files matching regex (default: ^[_.]) --skip_folder_re SKIP_FOLDER_RE Skip folders matching regex (default: ^[_.]) --flags FLAGS Space separated list of test flags to run that are normally ignored (default: ) --n_workers N_WORKERS Number of workers --timing Time each notebook to see which are slow (default: False) --do_print Print start and end of each notebook (default: False) --pause PAUSE Pause time (in seconds) between notebooks to avoid race conditions (default: 0.01) --ignore_fname IGNORE_FNAME Filename that will result in siblings being ignored (default: .notest)","title":"nbdev_test"},{"location":"nbdev_cli/nbdev_trust/","text":"usage: nbdev_trust [-h] [--fname FNAME] [--force_all] Trust notebooks matching `fname` optional arguments: -h, --help show this help message and exit --fname FNAME A notebook name or glob to trust --force_all Also trust notebooks that haven't changed (default: False)","title":"nbdev_trust"},{"location":"nbdev_cli/nbdev_update/","text":"usage: nbdev_update [-h] [--fname FNAME] Propagate change in modules matching `fname` to notebooks that created them optional arguments: -h, --help show this help message and exit --fname FNAME A Python file name to update","title":"nbdev_update"},{"location":"tutorials/","text":"Tutorials \u00a4 Click through to any of these tutorials to get started with nbdev\u2019s features.","title":"Tutorials"},{"location":"tutorials/#tutorials","text":"Click through to any of these tutorials to get started with nbdev\u2019s features.","title":"Tutorials"},{"location":"tutorials/best_practices/","text":"Notebook Best Practices \u00a4 The flexibility offered by notebooks can be overwhelming. While there are industry standards for writing Python packages\u2014like numpy and sphinx docstrings, and pytest and unittest testing frameworks\u2014they weren\u2019t designed for notebooks. This article walks you through the practices we\u2019ve learned to leverage the full power of notebooks with nbdev[^1]. Our approach weaves code, tests, and docs into a single interactive context that invites experimentation. If you prefer to learn by example, you might want to start with the annotated example and branch out from there. Marie Curie\u2019s research notebook dated 19-21 January 1900 ( source ). Know which form of notebook you\u2019re writing \u00a4 First of all, decide which form of notebook you\u2019re writing. We\u2019re fans of the Di\u00e1taxis system which classifies documentation into four forms: tutorials, how-to guides, explanations, and references. They\u2019ve laid this out beautifully in the following diagram: Start with a great title and subtitle \u00a4 Start with a markdown cell at the top of your notebook with its title in an H1 header, and subtitle in a blockquote. For example: # Great title > And an even better subtitle The title will also be used to reference your page in the sidebar. You can also optionally add frontmatter to this cell to customize nbdev and Quarto. Introduce your notebook \u00a4 Introduce your notebook with markdown cells below the title. We recommend a slightly different approach depending on the form of documentation : Reference: Start with a brief description of the technical component, and an overview that links to the main symbols in the page (you might want to use doclinks ) Tutorials and how-to guides: Describe what the reader will learn and how. Keep it short and get to the subject matter quickly Explanations: Since these are typically very focused, a short description of the topic is often sufficient. Use lots of code examples, pictures, plots, and videos \u00a4 Take advantage of the richness of notebooks by including code examples, pictures, plots, and videos. Here are a few examples to get you started: fastai\u2019s documentation makes extensive use of code examples, plots, images, and tables, for example, the computer vision intro nbdev.release opens with a terminal screencast demo in SVG format created with asciinema and svg-term-cli The documentation explanation describes a complex data pipeline using a Mermaid diagram The directives explanation showcases all of nbdev\u2019s directives with executable examples in call-out cards (and makes great use of emojis too!) RDKit renders beautiful molecule diagrams Keep docstrings short; elaborate in separate cells \u00a4 While nbdev renders docstrings as markdown, they aren\u2019t rendered correctly when using symbol? or help(symbol) and they can\u2019t include executed code. By splitting longer docstrings across separate code and markdown cells you can use code examples, pictures, plots, and videos . We find a single-line summary sufficient for most docstrings. Document parameters with docments \u00a4 fastcore.docments is a concise way to document parameters that is beautifully rendered by nbdev. For example, this function: def draw_n ( n : int , # Number of cards to draw replace : bool = True # Draw with replacement? ) -> list : # List of cards \"Draw `n` cards.\" \u2026would include the following table as part of its documentation: | | **Type** | **Default** | **Details** | |-------------|----------|-------------|-------------------------| | n | int | | Number of cards to draw | | replace | bool | True | Draw with replacement? | | **Returns** | **list** | | **List of cards** | nbdev also supports some numpy docstring sections. For example, this code snippet would produce the same table (there\u2019s no need to include types like in the docstring if you already have annotations): def draw_n ( n : int , replace : bool = True ) -> Cards : \"\"\" Draw `n` cards. Parameters ---------- n Number of cards to draw replace Draw with replacement? Returns ------- cards List of cards \"\"\" > **Tip** > > You can render a symbol\u2019s parameters table directly with > [`DocmentTbl`](https://nbdev.fast.ai/api/showdoc.html#docmenttbl). In > fact, that\u2019s how we rendered the table above. Consider turning code examples into tests by adding assertions \u00a4 nbdev blurs the lines between code, docs, and tests. Every code cell is run as a test (unless it\u2019s explicitly marked otherwise), and any error in the cell fails the test. Consider turning your code examples into tests by adding assertions \u2013 if they would make valuable tests and if it doesn\u2019t hurt readability. fastcore.test provides a set of light wrappers around assert for better notebook tests (for example, they print both objects on error if they differ). Here\u2019s an example using fastcore.test.test_eq : def inc ( x ): return x + 1 test_eq ( inc ( 3 ), 4 ) Document error-cases as tests \u00a4 Docstring-driven approaches typically document the errors raised by an object using plaintext descriptions, for example, in a \u201craises\u201d section. In nbdev, we recommend documenting errors with actual failing code using fastcore.test.test_fail . For example: def divide ( x , y ): return x / y test_fail ( lambda : divide ( 1 , 0 ), contains = \"division by zero\" ) The first argument is a lambda since we need to allow test_fail to control its execution and catch any errors. Reference related symbols with doclinks \u00a4 If you surround a symbol with backticks, nbdev will automatically link to that symbol\u2019s reference page. We call these doclinks . Prefer fully qualified symbol paths, like package.module.symbol instead of symbol . It may be more verbose but it helps users know which module a symbol originates from, which is especially important for third-party packages. Any package created with nbdev will automatically support doclinks. Non-nbdev packages can be supported by creating a minimal nbdev-index package. nbdev-index is a collection of such packages, which already supports django, numpy, pandas, pytorch, scipy, sphinx, the Python standard library, and even other programming languages like APL! Add rich representations to your classes \u00a4 This is another way to take advantage of the rich display feature of notebooks . You can provide rich representations to your object by defining a _repr_markdown_ method that returns markdown text (which may also include HTML/CSS). Here\u2019s a simple example to get you started: class Color : def __init__ ( self , color ): self . color = color def _repr_markdown_ ( self ): style = f 'background-color: { self . color } ; width: 50px; height: 50px; margin: 10px' return f '<div style=\" { style } \"></div>' Color ( 'green' ) Color ( 'blue' ) Also see the earlier list of example projects that make use of beautiful visual representations. Document class methods with show_doc or fastcore.basics.patch \u00a4 nbdev automatically documents exported function and class definitions with show_doc . However, it\u2019s up to you to document class methods. There are two ways to do that: calling show_doc on the method, or defining the method with the fastcore.basics.patch decorator. ### Notebook (show_doc) If your class is defined in a single cell, use [`show_doc`](https://nbdev.fast.ai/api/showdoc.html#show_doc). Here\u2019s what your notebook might look like: #| export class Number : \"A number.\" def __init__ ( self , num ): self . num = num def __add__ ( self , other ): \"Sum of this and `other`.\" return Number ( self . num + other . num ) def __repr__ ( self ): return f 'Number( { self . num } )' For example, here is the number 5: Number ( 5 ) show_doc ( Number . __add__ ) For example: Number ( 3 ) + Number ( 4 ) ### Notebook (@patch) If you split your class definition across cells with [`fastcore.basics.patch`](https://fastcore.fast.ai/basics.html#patch), here\u2019s what your notebook might look like: #| export class Number : \"A number.\" def __init__ ( self , num ): self . num = num def __repr__ ( self ): return f 'Number( { self . num } )' For example, here is the number 5: Number ( 5 ) #| export @patch def __add__ ( self : Number , other ): \"Sum of this and `other`.\" return Number ( self . num + other . num ) For example: Number ( 3 ) + Number ( 4 ) ### Docs In either case, this is how the documentation would be rendered: ------------------------------------------------------------------------ ### Number > Number (num) A number. For example, here is the number 5: Number ( 5 ) Number(5) ------------------------------------------------------------------------ ### Number.\\_\\_add\\_\\_ > Number.__add__ (other) Sum of this and `other`. For example: Number ( 3 ) + Number ( 4 ) Number(7) Group symbols with H2 sections \u00a4 As your notebooks grow, consider grouping related symbols using markdown cells with level 2 headers. Since nbdev displays documented symbols as level 3 headers, this would group all symbols below your level 2 header. Here is the markdown syntax: ## Section title Split long explanations with H4 sections \u00a4 Similar to the previous section, as a symbol\u2019s explanation grows, consider grouping its cells using level 4 headers. This is the recommended way to structure your reference docs, for example, to achieve numpy-style structures with sections like notes, examples, methods, and so on. Here\u2019s the markdown syntax: #### Section title Putting it all together: an annotated example \u00a4 In this section, we\u2019ll guide you through a full example of writing a documented and tested function in a notebook using all of the principles described above. We\u2019ll use the numpy.all function since it follows the widely-known numpy-docstring standard for .py files. Below is the definition of the numpy.all function. Take note of how all of the information is included in the docstring. While this works well for .py files, it doesn\u2019t let us weave executable code with rich markdown as we can in notebooks: def all ( a , axis = None , out = None , keepdims = np . _NoValue , * , where = np . _NoValue ): \"\"\" Test whether all array elements along a given axis evaluate to True. Parameters ---------- a : array_like Input array or object that can be converted to an array. axis : None or int or tuple of ints, optional Axis or axes along which a logical AND reduction is performed. The default (``axis=None``) is to perform a logical AND over all the dimensions of the input array. `axis` may be negative, in which case it counts from the last to the first axis. .. versionadded:: 1.7.0 If this is a tuple of ints, a reduction is performed on multiple axes, instead of a single axis or all the axes as before. out : ndarray, optional Alternate output array in which to place the result. It must have the same shape as the expected output and its type is preserved (e.g., if ``dtype(out)`` is float, the result will consist of 0.0's and 1.0's). See :ref:`ufuncs-output-type` for more details. keepdims : bool, optional If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array. If the default value is passed, then `keepdims` will not be passed through to the `all` method of sub-classes of `ndarray`, however any non-default value will be. If the sub-class' method does not implement `keepdims` any exceptions will be raised. where : array_like of bool, optional Elements to include in checking for all `True` values. See `~numpy.ufunc.reduce` for details. .. versionadded:: 1.20.0 Returns ------- all : ndarray, bool A new boolean or array is returned unless `out` is specified, in which case a reference to `out` is returned. See Also -------- ndarray.all : equivalent method any : Test whether any element along a given axis evaluates to True. Notes ----- Not a Number (NaN), positive infinity and negative infinity evaluate to `True` because these are not equal to zero. Examples -------- >>> np.all([[True,False],[True,True]]) False >>> np.all([[True,False],[True,True]], axis=0) array([ True, False]) >>> np.all([-1, 4, 5]) True >>> np.all([1.0, np.nan]) True >>> np.all([[True, True], [False, True]], where=[[True], [False]]) True >>> o=np.array(False) >>> z=np.all([-1, 4, 5], out=o) >>> id(z), id(o), z (28293632, 28293632, array(True)) # may vary \"\"\" ... Alternatively, Here is how we\u2019d write numpy.all in a notebook using nbdev. The first step is to define the function: #| export def all ( a , # Input array or object that can be converted to an array. axis : int | tuple | None = None , # Axis or axes along which a logical AND reduction is performed (default: all). out : np . ndarray | None = None , # Alternate output array in which to place the result. keepdims : bool = np . _NoValue , # Leave reduced one-dimensional axes in the result? where = np . _NoValue , # Elements to include in reduction. See `numpy.ufunc.reduce` for details. New in version 1.20.0. ) -> np . ndarray | bool : # A new boolean or array, or a reference to `out` if its specified. \"Test whether all array elements along a given axis evaluate to `True`.\" ... We can observe the following differences between this code and numpy-docstrings: The definition uses simple type annotations, which will be rendered in the function\u2019s parameters table below Parameters are described with a short comment, called docments \u2013 a concise alternative to numpy and sphinx docstring formats (although nbdev does support numpy docstrings see this example ) The docstring and parameter descriptions are all short, single-line summaries. We prefer to keep docstrings short and instead elaborate in separate cells , where we can use markdown and real code examples. Note: the use of | syntax for unions e.g. int|tuple|None (equivalent to Union[int, tuple, None] ) requires using Python 3.10 or by treating all annotations as strings using from __future__ import annotations which is available from Python 3.7. Our function definition is automatically rendered in the docs like this. Note that parameter names, types, defaults, and details are all parsed from the definition which means you don\u2019t have to repeat yourself. ------------------------------------------------------------------------ ### all > all (a, axis:Union[int,tuple,NoneType]=None, > out:Optional[numpy.ndarray]=None, keepdims:bool= , > where= ) Test whether all array elements along a given axis evaluate to `True`. | | **Type** | **Default** | **Details** | |-------------|------------------------|-------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------| | a | | | Input array or object that can be converted to an array. | | axis | int \\| tuple \\| None | None | Axis or axes along which a logical AND reduction is performed (default: all). | | out | np.ndarray \\| None | None | Alternate output array in which to place the result. | | keepdims | bool | | Leave reduced one-dimensional axes in the result? | | where | \\_NoValueType | | Elements to include in reduction. See [`numpy.ufunc.reduce`](https://numpy.org/doc/stable/reference/generated/numpy.ufunc.reduce.html#numpy.ufunc.reduce) for details. New in version 1.20.0. | | **Returns** | **np.ndarray \\| bool** | | **A new boolean or array, or a reference to `out` if its specified.** | Next, describe how to use your function using markdown cells and lots of code examples . This is the biggest benefit to developing in notebooks: instead of copying and pasting code examples into plaintext, you can include real executeable code examples. We start with basic usage first: For example: x = [[ True , False ],[ True , True ]] test_eq ( np . all ( x ), False ) Our code examples use assertion functions from fastcore.test , so that they serve as both docs and tests. nbdev_test runs every code cell as a test (unless it\u2019s explicitly marked otherwise), and any error in the cell fails the test. Having described basic usage, we now elaborate on more advanced functionality for each parameter. This differs from numpy\u2019s approach which includes all parameter docs in the table and where not all parameters have code examples. With `axis`: test_eq ( np . all ( x , axis = 0 ), [ True , False ]) `axis` may be negative, in which case it counts from the last to the first axis: test_eq ( np . all ( x , axis =- 1 ), [ False , True ]) If `axis` is a tuple of ints, a reduction is performed on multiple axes, instead of a single axis or all the axes as before. test_eq ( np . all ( x , axis = ( 0 , 1 )), False ) Integers, floats, not a number (nan), and infinity all evaluate to `True` because they\u2019re not equal to zero: test_eq ( np . all ([ - 1 , 1 , - 1.0 , 1.0 , np . nan , np . inf , - np . inf ]), True ) You can use `where` to test specific elements. For example, this tests only the second column: test_eq ( np . all ( x , where = [[ False ],[ True ]]), True ) The output can be stored in an optional `out` array. If provided, a reference to `out` will be returned: o = np . array ( False ) z = np . all ([ - 1 , 4 , 5 ], out = o ) test_is ( z , o ) test_eq ( z , True ) `out` must have the same shape as the expected output and its type is preserved (e.g., if `dtype(out)` is float, the result will consist of 0.0\u2019s and 1.0\u2019s). See [Output type determination](https://numpy.org/doc/stable/user/basics.ufuncs.html#ufuncs-output-type) for more details. With `keepdims`, the result will broadcast correctly against the input array. test_eq ( np . all ( x , axis = 0 , keepdims = True ), [[ True , False ]]) # Note the nested list If the default value is passed, then `keepdims` will not be passed through to the `all` method of sub-classes of `ndarray`, however any non-default value will be. If the sub-class\u2019 method does not implement `keepdims` any exceptions will be raised. class MyArray ( np . ndarray ): def all ( self , axis = None , out = None ): ... y = MyArray (( 2 , 2 )) y [:] = x np . all ( y ) # No TypeError since `keepdims` isn't passed test_fail ( lambda : np . all ( y , keepdims = True ), contains = \"all() got an unexpected keyword argument 'keepdims'\" ) Since we prefer to document via code examples, we also document error-cases with assertions using fastcore.test.test_fail . This differs from docstring-based approaches which usually document error-cases in prose, usually in a \u201craises\u201d section of the docstring. Finally, we link to related symbols with doclinks (symbols surrounded in backticks are automatically linked) and describe their relation using code examples. The [`numpy.ndarray.all`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.all.html#numpy.ndarray.all) method is equivalent to calling [`numpy.all`](https://numpy.org/doc/stable/reference/generated/numpy.all.html#numpy.all) with the array: test_eq ( np . array ( x ) . all (), np . all ( x )) In contrast, [`numpy.any`](https://numpy.org/doc/stable/reference/generated/numpy.any.html#numpy.any) tests whether *any* element evaluates to `True` (rather than *all* elements): test_eq ( np . any ( x ), True ) Recap \u00a4 In summary, here is how the nbdev version of numpy.all differs from the numpy docstring. nbdev uses: Type annotations and docments instead of the numpy docstring format (although nbdev supports numpy docstrings too) Short parameter descriptions, with details in separate cells with markdown and code example Doclinks to related symbols instead of a \u201cSee also\u201d section Lots of code examples (which are also tests) mixed with prose to describe how to use the function Code examples with assertions to document error-cases instead of a \u201cRaises\u201d section. [^1]: We\u2019re always open to improving our workflows and don\u2019t like to be too prescriptive about style. If you have any ideas, please feel free to post them in the forum .","title":"Notebook Best Practices"},{"location":"tutorials/best_practices/#notebook-best-practices","text":"The flexibility offered by notebooks can be overwhelming. While there are industry standards for writing Python packages\u2014like numpy and sphinx docstrings, and pytest and unittest testing frameworks\u2014they weren\u2019t designed for notebooks. This article walks you through the practices we\u2019ve learned to leverage the full power of notebooks with nbdev[^1]. Our approach weaves code, tests, and docs into a single interactive context that invites experimentation. If you prefer to learn by example, you might want to start with the annotated example and branch out from there. Marie Curie\u2019s research notebook dated 19-21 January 1900 ( source ).","title":"Notebook Best Practices"},{"location":"tutorials/best_practices/#know-which-form-of-notebook-youre-writing","text":"First of all, decide which form of notebook you\u2019re writing. We\u2019re fans of the Di\u00e1taxis system which classifies documentation into four forms: tutorials, how-to guides, explanations, and references. They\u2019ve laid this out beautifully in the following diagram:","title":"Know which form of notebook you\u2019re writing"},{"location":"tutorials/best_practices/#start-with-a-great-title-and-subtitle","text":"Start with a markdown cell at the top of your notebook with its title in an H1 header, and subtitle in a blockquote. For example: # Great title > And an even better subtitle The title will also be used to reference your page in the sidebar. You can also optionally add frontmatter to this cell to customize nbdev and Quarto.","title":"Start with a great title and subtitle"},{"location":"tutorials/best_practices/#introduce-your-notebook","text":"Introduce your notebook with markdown cells below the title. We recommend a slightly different approach depending on the form of documentation : Reference: Start with a brief description of the technical component, and an overview that links to the main symbols in the page (you might want to use doclinks ) Tutorials and how-to guides: Describe what the reader will learn and how. Keep it short and get to the subject matter quickly Explanations: Since these are typically very focused, a short description of the topic is often sufficient.","title":"Introduce your notebook"},{"location":"tutorials/best_practices/#use-lots-of-code-examples-pictures-plots-and-videos","text":"Take advantage of the richness of notebooks by including code examples, pictures, plots, and videos. Here are a few examples to get you started: fastai\u2019s documentation makes extensive use of code examples, plots, images, and tables, for example, the computer vision intro nbdev.release opens with a terminal screencast demo in SVG format created with asciinema and svg-term-cli The documentation explanation describes a complex data pipeline using a Mermaid diagram The directives explanation showcases all of nbdev\u2019s directives with executable examples in call-out cards (and makes great use of emojis too!) RDKit renders beautiful molecule diagrams","title":"Use lots of code examples, pictures, plots, and videos"},{"location":"tutorials/best_practices/#keep-docstrings-short-elaborate-in-separate-cells","text":"While nbdev renders docstrings as markdown, they aren\u2019t rendered correctly when using symbol? or help(symbol) and they can\u2019t include executed code. By splitting longer docstrings across separate code and markdown cells you can use code examples, pictures, plots, and videos . We find a single-line summary sufficient for most docstrings.","title":"Keep docstrings short; elaborate in separate cells"},{"location":"tutorials/best_practices/#document-parameters-with-docments","text":"fastcore.docments is a concise way to document parameters that is beautifully rendered by nbdev. For example, this function: def draw_n ( n : int , # Number of cards to draw replace : bool = True # Draw with replacement? ) -> list : # List of cards \"Draw `n` cards.\" \u2026would include the following table as part of its documentation: | | **Type** | **Default** | **Details** | |-------------|----------|-------------|-------------------------| | n | int | | Number of cards to draw | | replace | bool | True | Draw with replacement? | | **Returns** | **list** | | **List of cards** | nbdev also supports some numpy docstring sections. For example, this code snippet would produce the same table (there\u2019s no need to include types like in the docstring if you already have annotations): def draw_n ( n : int , replace : bool = True ) -> Cards : \"\"\" Draw `n` cards. Parameters ---------- n Number of cards to draw replace Draw with replacement? Returns ------- cards List of cards \"\"\" > **Tip** > > You can render a symbol\u2019s parameters table directly with > [`DocmentTbl`](https://nbdev.fast.ai/api/showdoc.html#docmenttbl). In > fact, that\u2019s how we rendered the table above.","title":"Document parameters with docments"},{"location":"tutorials/best_practices/#consider-turning-code-examples-into-tests-by-adding-assertions","text":"nbdev blurs the lines between code, docs, and tests. Every code cell is run as a test (unless it\u2019s explicitly marked otherwise), and any error in the cell fails the test. Consider turning your code examples into tests by adding assertions \u2013 if they would make valuable tests and if it doesn\u2019t hurt readability. fastcore.test provides a set of light wrappers around assert for better notebook tests (for example, they print both objects on error if they differ). Here\u2019s an example using fastcore.test.test_eq : def inc ( x ): return x + 1 test_eq ( inc ( 3 ), 4 )","title":"Consider turning code examples into tests by adding assertions"},{"location":"tutorials/best_practices/#document-error-cases-as-tests","text":"Docstring-driven approaches typically document the errors raised by an object using plaintext descriptions, for example, in a \u201craises\u201d section. In nbdev, we recommend documenting errors with actual failing code using fastcore.test.test_fail . For example: def divide ( x , y ): return x / y test_fail ( lambda : divide ( 1 , 0 ), contains = \"division by zero\" ) The first argument is a lambda since we need to allow test_fail to control its execution and catch any errors.","title":"Document error-cases as tests"},{"location":"tutorials/best_practices/#reference-related-symbols-with-doclinks","text":"If you surround a symbol with backticks, nbdev will automatically link to that symbol\u2019s reference page. We call these doclinks . Prefer fully qualified symbol paths, like package.module.symbol instead of symbol . It may be more verbose but it helps users know which module a symbol originates from, which is especially important for third-party packages. Any package created with nbdev will automatically support doclinks. Non-nbdev packages can be supported by creating a minimal nbdev-index package. nbdev-index is a collection of such packages, which already supports django, numpy, pandas, pytorch, scipy, sphinx, the Python standard library, and even other programming languages like APL!","title":"Reference related symbols with doclinks"},{"location":"tutorials/best_practices/#add-rich-representations-to-your-classes","text":"This is another way to take advantage of the rich display feature of notebooks . You can provide rich representations to your object by defining a _repr_markdown_ method that returns markdown text (which may also include HTML/CSS). Here\u2019s a simple example to get you started: class Color : def __init__ ( self , color ): self . color = color def _repr_markdown_ ( self ): style = f 'background-color: { self . color } ; width: 50px; height: 50px; margin: 10px' return f '<div style=\" { style } \"></div>' Color ( 'green' ) Color ( 'blue' ) Also see the earlier list of example projects that make use of beautiful visual representations.","title":"Add rich representations to your classes"},{"location":"tutorials/best_practices/#document-class-methods-with-show_doc-or-fastcorebasicspatch","text":"nbdev automatically documents exported function and class definitions with show_doc . However, it\u2019s up to you to document class methods. There are two ways to do that: calling show_doc on the method, or defining the method with the fastcore.basics.patch decorator. ### Notebook (show_doc) If your class is defined in a single cell, use [`show_doc`](https://nbdev.fast.ai/api/showdoc.html#show_doc). Here\u2019s what your notebook might look like: #| export class Number : \"A number.\" def __init__ ( self , num ): self . num = num def __add__ ( self , other ): \"Sum of this and `other`.\" return Number ( self . num + other . num ) def __repr__ ( self ): return f 'Number( { self . num } )' For example, here is the number 5: Number ( 5 ) show_doc ( Number . __add__ ) For example: Number ( 3 ) + Number ( 4 ) ### Notebook (@patch) If you split your class definition across cells with [`fastcore.basics.patch`](https://fastcore.fast.ai/basics.html#patch), here\u2019s what your notebook might look like: #| export class Number : \"A number.\" def __init__ ( self , num ): self . num = num def __repr__ ( self ): return f 'Number( { self . num } )' For example, here is the number 5: Number ( 5 ) #| export @patch def __add__ ( self : Number , other ): \"Sum of this and `other`.\" return Number ( self . num + other . num ) For example: Number ( 3 ) + Number ( 4 ) ### Docs In either case, this is how the documentation would be rendered: ------------------------------------------------------------------------ ### Number > Number (num) A number. For example, here is the number 5: Number ( 5 ) Number(5) ------------------------------------------------------------------------ ### Number.\\_\\_add\\_\\_ > Number.__add__ (other) Sum of this and `other`. For example: Number ( 3 ) + Number ( 4 ) Number(7)","title":"Document class methods with show_doc or fastcore.basics.patch"},{"location":"tutorials/best_practices/#group-symbols-with-h2-sections","text":"As your notebooks grow, consider grouping related symbols using markdown cells with level 2 headers. Since nbdev displays documented symbols as level 3 headers, this would group all symbols below your level 2 header. Here is the markdown syntax: ## Section title","title":"Group symbols with H2 sections"},{"location":"tutorials/best_practices/#split-long-explanations-with-h4-sections","text":"Similar to the previous section, as a symbol\u2019s explanation grows, consider grouping its cells using level 4 headers. This is the recommended way to structure your reference docs, for example, to achieve numpy-style structures with sections like notes, examples, methods, and so on. Here\u2019s the markdown syntax: #### Section title","title":"Split long explanations with H4 sections"},{"location":"tutorials/best_practices/#putting-it-all-together-an-annotated-example","text":"In this section, we\u2019ll guide you through a full example of writing a documented and tested function in a notebook using all of the principles described above. We\u2019ll use the numpy.all function since it follows the widely-known numpy-docstring standard for .py files. Below is the definition of the numpy.all function. Take note of how all of the information is included in the docstring. While this works well for .py files, it doesn\u2019t let us weave executable code with rich markdown as we can in notebooks: def all ( a , axis = None , out = None , keepdims = np . _NoValue , * , where = np . _NoValue ): \"\"\" Test whether all array elements along a given axis evaluate to True. Parameters ---------- a : array_like Input array or object that can be converted to an array. axis : None or int or tuple of ints, optional Axis or axes along which a logical AND reduction is performed. The default (``axis=None``) is to perform a logical AND over all the dimensions of the input array. `axis` may be negative, in which case it counts from the last to the first axis. .. versionadded:: 1.7.0 If this is a tuple of ints, a reduction is performed on multiple axes, instead of a single axis or all the axes as before. out : ndarray, optional Alternate output array in which to place the result. It must have the same shape as the expected output and its type is preserved (e.g., if ``dtype(out)`` is float, the result will consist of 0.0's and 1.0's). See :ref:`ufuncs-output-type` for more details. keepdims : bool, optional If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array. If the default value is passed, then `keepdims` will not be passed through to the `all` method of sub-classes of `ndarray`, however any non-default value will be. If the sub-class' method does not implement `keepdims` any exceptions will be raised. where : array_like of bool, optional Elements to include in checking for all `True` values. See `~numpy.ufunc.reduce` for details. .. versionadded:: 1.20.0 Returns ------- all : ndarray, bool A new boolean or array is returned unless `out` is specified, in which case a reference to `out` is returned. See Also -------- ndarray.all : equivalent method any : Test whether any element along a given axis evaluates to True. Notes ----- Not a Number (NaN), positive infinity and negative infinity evaluate to `True` because these are not equal to zero. Examples -------- >>> np.all([[True,False],[True,True]]) False >>> np.all([[True,False],[True,True]], axis=0) array([ True, False]) >>> np.all([-1, 4, 5]) True >>> np.all([1.0, np.nan]) True >>> np.all([[True, True], [False, True]], where=[[True], [False]]) True >>> o=np.array(False) >>> z=np.all([-1, 4, 5], out=o) >>> id(z), id(o), z (28293632, 28293632, array(True)) # may vary \"\"\" ... Alternatively, Here is how we\u2019d write numpy.all in a notebook using nbdev. The first step is to define the function: #| export def all ( a , # Input array or object that can be converted to an array. axis : int | tuple | None = None , # Axis or axes along which a logical AND reduction is performed (default: all). out : np . ndarray | None = None , # Alternate output array in which to place the result. keepdims : bool = np . _NoValue , # Leave reduced one-dimensional axes in the result? where = np . _NoValue , # Elements to include in reduction. See `numpy.ufunc.reduce` for details. New in version 1.20.0. ) -> np . ndarray | bool : # A new boolean or array, or a reference to `out` if its specified. \"Test whether all array elements along a given axis evaluate to `True`.\" ... We can observe the following differences between this code and numpy-docstrings: The definition uses simple type annotations, which will be rendered in the function\u2019s parameters table below Parameters are described with a short comment, called docments \u2013 a concise alternative to numpy and sphinx docstring formats (although nbdev does support numpy docstrings see this example ) The docstring and parameter descriptions are all short, single-line summaries. We prefer to keep docstrings short and instead elaborate in separate cells , where we can use markdown and real code examples. Note: the use of | syntax for unions e.g. int|tuple|None (equivalent to Union[int, tuple, None] ) requires using Python 3.10 or by treating all annotations as strings using from __future__ import annotations which is available from Python 3.7. Our function definition is automatically rendered in the docs like this. Note that parameter names, types, defaults, and details are all parsed from the definition which means you don\u2019t have to repeat yourself. ------------------------------------------------------------------------ ### all > all (a, axis:Union[int,tuple,NoneType]=None, > out:Optional[numpy.ndarray]=None, keepdims:bool= , > where= ) Test whether all array elements along a given axis evaluate to `True`. | | **Type** | **Default** | **Details** | |-------------|------------------------|-------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------| | a | | | Input array or object that can be converted to an array. | | axis | int \\| tuple \\| None | None | Axis or axes along which a logical AND reduction is performed (default: all). | | out | np.ndarray \\| None | None | Alternate output array in which to place the result. | | keepdims | bool | | Leave reduced one-dimensional axes in the result? | | where | \\_NoValueType | | Elements to include in reduction. See [`numpy.ufunc.reduce`](https://numpy.org/doc/stable/reference/generated/numpy.ufunc.reduce.html#numpy.ufunc.reduce) for details. New in version 1.20.0. | | **Returns** | **np.ndarray \\| bool** | | **A new boolean or array, or a reference to `out` if its specified.** | Next, describe how to use your function using markdown cells and lots of code examples . This is the biggest benefit to developing in notebooks: instead of copying and pasting code examples into plaintext, you can include real executeable code examples. We start with basic usage first: For example: x = [[ True , False ],[ True , True ]] test_eq ( np . all ( x ), False ) Our code examples use assertion functions from fastcore.test , so that they serve as both docs and tests. nbdev_test runs every code cell as a test (unless it\u2019s explicitly marked otherwise), and any error in the cell fails the test. Having described basic usage, we now elaborate on more advanced functionality for each parameter. This differs from numpy\u2019s approach which includes all parameter docs in the table and where not all parameters have code examples. With `axis`: test_eq ( np . all ( x , axis = 0 ), [ True , False ]) `axis` may be negative, in which case it counts from the last to the first axis: test_eq ( np . all ( x , axis =- 1 ), [ False , True ]) If `axis` is a tuple of ints, a reduction is performed on multiple axes, instead of a single axis or all the axes as before. test_eq ( np . all ( x , axis = ( 0 , 1 )), False ) Integers, floats, not a number (nan), and infinity all evaluate to `True` because they\u2019re not equal to zero: test_eq ( np . all ([ - 1 , 1 , - 1.0 , 1.0 , np . nan , np . inf , - np . inf ]), True ) You can use `where` to test specific elements. For example, this tests only the second column: test_eq ( np . all ( x , where = [[ False ],[ True ]]), True ) The output can be stored in an optional `out` array. If provided, a reference to `out` will be returned: o = np . array ( False ) z = np . all ([ - 1 , 4 , 5 ], out = o ) test_is ( z , o ) test_eq ( z , True ) `out` must have the same shape as the expected output and its type is preserved (e.g., if `dtype(out)` is float, the result will consist of 0.0\u2019s and 1.0\u2019s). See [Output type determination](https://numpy.org/doc/stable/user/basics.ufuncs.html#ufuncs-output-type) for more details. With `keepdims`, the result will broadcast correctly against the input array. test_eq ( np . all ( x , axis = 0 , keepdims = True ), [[ True , False ]]) # Note the nested list If the default value is passed, then `keepdims` will not be passed through to the `all` method of sub-classes of `ndarray`, however any non-default value will be. If the sub-class\u2019 method does not implement `keepdims` any exceptions will be raised. class MyArray ( np . ndarray ): def all ( self , axis = None , out = None ): ... y = MyArray (( 2 , 2 )) y [:] = x np . all ( y ) # No TypeError since `keepdims` isn't passed test_fail ( lambda : np . all ( y , keepdims = True ), contains = \"all() got an unexpected keyword argument 'keepdims'\" ) Since we prefer to document via code examples, we also document error-cases with assertions using fastcore.test.test_fail . This differs from docstring-based approaches which usually document error-cases in prose, usually in a \u201craises\u201d section of the docstring. Finally, we link to related symbols with doclinks (symbols surrounded in backticks are automatically linked) and describe their relation using code examples. The [`numpy.ndarray.all`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.all.html#numpy.ndarray.all) method is equivalent to calling [`numpy.all`](https://numpy.org/doc/stable/reference/generated/numpy.all.html#numpy.all) with the array: test_eq ( np . array ( x ) . all (), np . all ( x )) In contrast, [`numpy.any`](https://numpy.org/doc/stable/reference/generated/numpy.any.html#numpy.any) tests whether *any* element evaluates to `True` (rather than *all* elements): test_eq ( np . any ( x ), True )","title":"Putting it all together: an annotated example"},{"location":"tutorials/best_practices/#recap","text":"In summary, here is how the nbdev version of numpy.all differs from the numpy docstring. nbdev uses: Type annotations and docments instead of the numpy docstring format (although nbdev supports numpy docstrings too) Short parameter descriptions, with details in separate cells with markdown and code example Doclinks to related symbols instead of a \u201cSee also\u201d section Lots of code examples (which are also tests) mixed with prose to describe how to use the function Code examples with assertions to document error-cases instead of a \u201cRaises\u201d section. [^1]: We\u2019re always open to improving our workflows and don\u2019t like to be too prescriptive about style. If you have any ideas, please feel free to post them in the forum .","title":"Recap"},{"location":"tutorials/blogging/","text":"Blogging \u00a4 Background \u00a4 Blogging with notebooks can offer a dramatic quality of life improvement over writing in Markdown, especially for blog posts that contain code. Previously, there were no static site generators that supported Jupyter Notebooks as a first-class authoring medium. This previously led us to create fastpages (now deprecated), which extended Jekyll to enable blogging directly with Jupyter. Enter Quarto \u00a4 However, there now exists Quarto , a wonderful publishing system with rich support for authoring via Jupyter Notebooks. Some helpful resources on getting started with Quarto: The Quarto Homepage Creating A Blog With Quarto : This page helps you get started with creating a blog. A Gallery of Quarto Sites : Good reference examples of using Quarto. The Quarto Website : The Quarto website is built with Quarto and they use some of its advanced functionality. It is instructive to look through this project to understand how Quarto works. > **You don\u2019t need nbdev to blog with notebooks** > > You do not need to use nbdev to create a blog with notebooks. However, > you may wish to: > > - Incorporate a blog in your nbdev project\u2019s website > - Use some nbdev functionality in your blog (testing, exporting etc) > > We will discuss these subjects in this article. Migrating from fastpages \u00a4 If you previously had a fastpages site, we offer some utilities to help migrate you to Quarto. The migration is not holistic: you will likely have to manually correct some things that we are not able to automate. Instructions: Install Quarto Create a new repo or directory to migrate your blog to In this new repo, create a quarto blog and install required extensions with the following terminal commands. This will create a minimal project structure for you: quarto create-project --type website:blog . quarto install extension quarto-ext/video Your new repo will have a posts/ directory. This is where you will copy all of your notebook and markdown posts from fastpages. For example, let\u2019s say your fastpages blog repo is in a sibling directory located at ../blog/ , you would copy all the relevant posts like this: > **Important** > > Make sure you are in root of your quarto directory before executing > the below commands. Furthermore, change the commands as appropriate > depending on the location of your fastpages repo relative to your > current directory. cp -r ../blog/_notebooks/* posts cp -r ../blog/_posts/* posts Copy all images associated with your posts into the posts/ directory. We have to get our images from several places (due to the way Jekyll and fastpages work): cp ../blog/images/* posts cp -r ../blog/images/copied_from_nb/* posts/ Make your posts Quarto compatible with the following command: nbdev_migrate --path posts > **What does > [`nbdev_migrate`](https://nbdev.fast.ai/api/migrate.html#nbdev_migrate) > do?** > > [`nbdev_migrate`](https://nbdev.fast.ai/api/migrate.html#nbdev_migrate) > does the following things: > > #### For notebooks > > - Migrates markdown front matter to raw cell front matter [as > described here](../api/migrate.ipynb#migrateproc). > - nbdev v1 directives are automatically converted to [Quarto > directives](../explanations/directives.ipynb). Note that we convert > everything to Quarto directives (nbdev-specific directives are not > relevant for this context) > - Markdown shortcut for embedding youtube videos and callouts are > automatically converted to work with Quarto. > > #### For markdown and notebooks > > - Automatically creates [link > aliases](https://quarto.org/docs/reference/formats/html.html#website) > so that old links will not break. Jekyll automatically generates > URLs differently than Quarto, so this ensures that the Jekyll way is > aliased. > - Automatically corrects image paths > - Makes front matter compatible with Quarto by changing field names > and values where necessary Update the following files: ./.gitignore : we suggest adding _site/ as well as dot files .* ./about.qmd : Add some information about yourself. ./profile.jpg : optionally change the profile picture. Preview your site with the command quarto preview , and make any necessary adjustments and fix for broken links or Jekyll shortcodes (things with {% ... %} ) that need to be converted to Quarto. Search the the Quarto documentation if you need help locating specific Quarto features. Configuration options: fastpages vs. Quarto \u00a4 fastpages (which is based on Jekyll) and Quarto offer different options and configurations for individual posts and at a site level. The tables below enumerate some of the most important features of fastpages and how they map to Quarto. Each link in the last column is specific to the relevant feature. Post-level options \u00a4 Jekyll Front Matter Quarto Notes toc: false Same There are more options in the Quarto docs badges: true n/a No support yet comments: true see notes Quarto docs categories: [fastpages, jupyter] Same Quarto docs image: images/some_folder/your_image.png Same Quarto docs hide: false draft: true Quarto docs search_exclude: true see notes Quarto docs title Same description Same sticky_rank Not supported Quarto docs Site-level options \u00a4 Jekyll site config Quarto Notes title see notes Quarto docs description see notes Quarto docs github_repo see notes Quarto docs url n/a Don\u2019t need this baseurl n/a Don\u2019t need this twitter_username search page in notes for \u201ctwitter\u201d Quarto docs use_math see notes Quarto docs google_analytics website: google-analytics: \u201cUA-XXXXXXXX\u201d Quarto docs show_image n/a Quarto docs show_tags see title-block-categories of page in notes Quarto docs pagination website: page-navigation: true Quarto docs annotations comments: hypothesis: \u2026 Quarto docs Publishing your blog \u00a4 > **Warning** > > *This section is for stand-alone blogs that are not part of a nbdev > documentation site. If you want to create a blog within a nbdev > documentation site, see [this > section](#creating-a-blog-within-a-nbdev-project).* You can publish your site with the quarto publish command. See the docs for more details. > **GitHub Pages** > > If using GitHub Pages, commit your files to GitHub before publish your > site. **No GitHub Actions are needed**, you can use `quarto publish` > instead. If you want to automate your workflow with GitHub Actions, > you can follow [these > instructions](https://quarto.org/docs/publishing/quarto-pub.html#github-action) Creating a blog within a nbdev project \u00a4 In addition to a stand-alone blog that you might build with Quarto, you might want to include a blogging site in your nbdev project. This website has a blog as well! The easiest way to implement a blog is to emulate the directory structure of this folder . The general steps are: Create a blog/ directory in your notebooks folder. Create a index.qmd file in the root of the blog/ directory. Here is an example . The frontmatter the index.qmd file signals to Quarto that you intend to create a blog. For example, here is our front matter : --- title : nbdev Blog subtitle : News, tips, and commentary about all things nbdev listing : sort : \"date desc\" contents : \"posts\" sort-ui : false filter-ui : false categories : true feed : true page-layout : full --- The listing: field specifies how you want to structure your blog. Feel free to copy ours as-is, but we encourage you to consult the documentation for additional options. Create a link to your blog on your site\u2019s navbar so people can find it : To add a link to your blog on your site\u2019s navbar, you must edit the navbar section of _quarto.yml to include a link to your blog\u2019s listing page, which is blog/index.qmd in our example. For nbdev, the relevant part of our _quarto.yml file looks like this: The yaml snippet shown below is an abbreviated version of nbdev\u2019s _quarto.yml file. website : navbar : left : - text : \"Blog\" href : blog/index.qmd You can read more about the navbar in the Quarto docs . Create a folder for each blog post : This is not strictly required, but we recommend this as a way to keep your blog posts and related assets (pictures, videos etc) organized. Create your first blog post : You can emulate our example or create your own. In each folder, create a index.qmd or index.ipynb file. You can also put images and related assets in the same folder. Folder structure \u00a4 Below is an overview of the general folder structure for a blog within a nbdev site: nbs/blog \u251c\u2500\u2500 index.qmd \u2514\u2500\u2500 posts \u251c\u2500\u2500 2022-07-28-nbdev2 \u2502 \u251c\u2500\u2500 cover.png \u2502 \u251c\u2500\u2500 index.qmd \u2502 \u251c\u2500\u2500 ... \u2514\u2500\u2500 2022-08-25-jupyter-git \u251c\u2500\u2500 friendly-conflict.png \u251c\u2500\u2500 index.qmd \u2514\u2500\u2500 ... ... nbs/blog : this is the folder inside your notebook folder that contains the blog. index.qmd : this is at the root of your blog folder and is the listings page for your blog. posts/ : this a subdirectory for each blog post. YYYY-MM-DD-.../index.{qmd,ipynb} : this is where you author the content of each individual blog post. Special considerations for nbdev blogs \u00a4 In contrast to standalone Quarto blogs, when you embed a blog in a nbdev website there are the following differences: You can use all nbdev directives in addition to Quarto ones. All nbdev features will be available in your nbdev blog in the same way they work for other pages. Your site will automatically deploy with GitHub Actions or whatever deployment mechanism you have for your nbdev site, so you do not have to use quarto publish . Using nbdev features in blogs outside nbdev projects \u00a4 > **Warning** > > *This section is for stand-alone blogs that are not part of a nbdev > documentation site. If you create a blog within a nbdev documentation > site, all nbdev features will automatically work.* If you create a standalone blog with Quarto, a limited number of nbdev features can still assist you. For example, we recommend installing Jupyter git hooks . A list of nbdev features available to you are listed in this article . Creating A New Blog Site From Scratch \u00a4 You can use the quarto CLI to setup a new blog project called myblog with the following command: quarto create-project myblog --type website:blog You can then preview your blog project with quarto preview . You can also publish your blog using the quarto publish command. > **Adding a notebook blog post** > > To add a notebook blog post to a blog project created with the above > commands, you can add an additional folder under `posts/` and name the > notebook `index.ipynb`. You will see existing example blog posts that > are `index.qmd` files in sibling folders you can look at for examples. > You will need to add [yaml front > matter](https://quarto.org/docs/tools/jupyter-lab.html#yaml-front-matter) > to the first cell of your notebook in the form of a raw cell. For more information about creating a blog with Quarto, see this guide . FAQ \u00a4 Do I need to migrate from fastpages? No you do not. However we will not be actively supporting fastpages going forward. Will migrating from fastpages to Quarto take lots of manual effort? You will have to do some manual work to make sure everything looks and works the same, including converting Jekyll shortcodes to equivalent Quarto commands. However, we have automated the biggest aspects for you. Please see Migrating from fastpages for instructions. I cannot find something in Quarto that does what #collapse_output did in fastpages Correct, this is a feature that isn\u2019t supported in Quarto yet. Why am I seeing {% twitter ...%} and {% fn_detail ... %} and other {%...%} commands in my Quarto blog posts? These are Jekyll shortcodes that you will have to manually migrate to Quarto. For example with the twitter embeds, you can insert the appropriate HTML as recommended by Twitter . For footnotes, you can see these docs . For other items, you should search the Quarto docs for how to enable your desired result. I created a new blog post and used #| hide but the cell is still showing. What is wrong? You must use Quarto directives, not nbdev-specific ones. See the difference between the two in these docs . This is because you are blogging with Quarto, not nbdev. The exception to this is you have a blog site in your nbdev project \u2013 in that case, nbdev-specific directives will work. How do I enable comments on my blog posts? In general, Quarto offers all of the same features and much more than fastpages did, including comments. If you search the Quarto docs for comments, you will see a page for enabling comments . How do I sort and hide posts? What about the publishing date since that\u2019s not in the filename? See the Quarto docs on creating a blog as well as listing pages . How do I customize my site? See the Quarto docs How do I do set up RSS Feeds and add particular features to my site? See the Quarto docs What does nbdev have to do with Quarto? . For just blogging, nothing! You can use Quarto for blogging without worrying about nbdev. In the past, we maintained a nbdev related project called fastpages , and are recommending that people migrate to Quarto if possible. Furthermore, nbdev is built on top of Quarto which means much of the functionality is similar. Finally, you can incorporate blogs into a nbdev project site, which we discuss in this section . For stand alone blogs, why are you directing us to Quarto, can I just use nbdev? nbdev is built on top of Quarto. For the purposes of blogging, adding nbdev is of little additional benefit if all you want to do is to blog. We decided to keep things simple and let people use Quarto directly instead of trying to abstract aspects of Quarto for blogging. Furthermore, having some knowledge of Quarto can be very helpful in using nbdev!. Lastly, you can still use some nbdev features in your blog, which are listed in this article .","title":"Blogging"},{"location":"tutorials/blogging/#blogging","text":"","title":"Blogging"},{"location":"tutorials/blogging/#background","text":"Blogging with notebooks can offer a dramatic quality of life improvement over writing in Markdown, especially for blog posts that contain code. Previously, there were no static site generators that supported Jupyter Notebooks as a first-class authoring medium. This previously led us to create fastpages (now deprecated), which extended Jekyll to enable blogging directly with Jupyter.","title":"Background"},{"location":"tutorials/blogging/#enter-quarto","text":"However, there now exists Quarto , a wonderful publishing system with rich support for authoring via Jupyter Notebooks. Some helpful resources on getting started with Quarto: The Quarto Homepage Creating A Blog With Quarto : This page helps you get started with creating a blog. A Gallery of Quarto Sites : Good reference examples of using Quarto. The Quarto Website : The Quarto website is built with Quarto and they use some of its advanced functionality. It is instructive to look through this project to understand how Quarto works. > **You don\u2019t need nbdev to blog with notebooks** > > You do not need to use nbdev to create a blog with notebooks. However, > you may wish to: > > - Incorporate a blog in your nbdev project\u2019s website > - Use some nbdev functionality in your blog (testing, exporting etc) > > We will discuss these subjects in this article.","title":"Enter Quarto"},{"location":"tutorials/blogging/#migrating-from-fastpages","text":"If you previously had a fastpages site, we offer some utilities to help migrate you to Quarto. The migration is not holistic: you will likely have to manually correct some things that we are not able to automate. Instructions: Install Quarto Create a new repo or directory to migrate your blog to In this new repo, create a quarto blog and install required extensions with the following terminal commands. This will create a minimal project structure for you: quarto create-project --type website:blog . quarto install extension quarto-ext/video Your new repo will have a posts/ directory. This is where you will copy all of your notebook and markdown posts from fastpages. For example, let\u2019s say your fastpages blog repo is in a sibling directory located at ../blog/ , you would copy all the relevant posts like this: > **Important** > > Make sure you are in root of your quarto directory before executing > the below commands. Furthermore, change the commands as appropriate > depending on the location of your fastpages repo relative to your > current directory. cp -r ../blog/_notebooks/* posts cp -r ../blog/_posts/* posts Copy all images associated with your posts into the posts/ directory. We have to get our images from several places (due to the way Jekyll and fastpages work): cp ../blog/images/* posts cp -r ../blog/images/copied_from_nb/* posts/ Make your posts Quarto compatible with the following command: nbdev_migrate --path posts > **What does > [`nbdev_migrate`](https://nbdev.fast.ai/api/migrate.html#nbdev_migrate) > do?** > > [`nbdev_migrate`](https://nbdev.fast.ai/api/migrate.html#nbdev_migrate) > does the following things: > > #### For notebooks > > - Migrates markdown front matter to raw cell front matter [as > described here](../api/migrate.ipynb#migrateproc). > - nbdev v1 directives are automatically converted to [Quarto > directives](../explanations/directives.ipynb). Note that we convert > everything to Quarto directives (nbdev-specific directives are not > relevant for this context) > - Markdown shortcut for embedding youtube videos and callouts are > automatically converted to work with Quarto. > > #### For markdown and notebooks > > - Automatically creates [link > aliases](https://quarto.org/docs/reference/formats/html.html#website) > so that old links will not break. Jekyll automatically generates > URLs differently than Quarto, so this ensures that the Jekyll way is > aliased. > - Automatically corrects image paths > - Makes front matter compatible with Quarto by changing field names > and values where necessary Update the following files: ./.gitignore : we suggest adding _site/ as well as dot files .* ./about.qmd : Add some information about yourself. ./profile.jpg : optionally change the profile picture. Preview your site with the command quarto preview , and make any necessary adjustments and fix for broken links or Jekyll shortcodes (things with {% ... %} ) that need to be converted to Quarto. Search the the Quarto documentation if you need help locating specific Quarto features.","title":"Migrating from fastpages"},{"location":"tutorials/blogging/#configuration-options-fastpages-vs-quarto","text":"fastpages (which is based on Jekyll) and Quarto offer different options and configurations for individual posts and at a site level. The tables below enumerate some of the most important features of fastpages and how they map to Quarto. Each link in the last column is specific to the relevant feature.","title":"Configuration options: fastpages vs.\u00a0Quarto"},{"location":"tutorials/blogging/#post-level-options","text":"Jekyll Front Matter Quarto Notes toc: false Same There are more options in the Quarto docs badges: true n/a No support yet comments: true see notes Quarto docs categories: [fastpages, jupyter] Same Quarto docs image: images/some_folder/your_image.png Same Quarto docs hide: false draft: true Quarto docs search_exclude: true see notes Quarto docs title Same description Same sticky_rank Not supported Quarto docs","title":"Post-level options"},{"location":"tutorials/blogging/#site-level-options","text":"Jekyll site config Quarto Notes title see notes Quarto docs description see notes Quarto docs github_repo see notes Quarto docs url n/a Don\u2019t need this baseurl n/a Don\u2019t need this twitter_username search page in notes for \u201ctwitter\u201d Quarto docs use_math see notes Quarto docs google_analytics website: google-analytics: \u201cUA-XXXXXXXX\u201d Quarto docs show_image n/a Quarto docs show_tags see title-block-categories of page in notes Quarto docs pagination website: page-navigation: true Quarto docs annotations comments: hypothesis: \u2026 Quarto docs","title":"Site-level options"},{"location":"tutorials/blogging/#publishing-your-blog","text":"> **Warning** > > *This section is for stand-alone blogs that are not part of a nbdev > documentation site. If you want to create a blog within a nbdev > documentation site, see [this > section](#creating-a-blog-within-a-nbdev-project).* You can publish your site with the quarto publish command. See the docs for more details. > **GitHub Pages** > > If using GitHub Pages, commit your files to GitHub before publish your > site. **No GitHub Actions are needed**, you can use `quarto publish` > instead. If you want to automate your workflow with GitHub Actions, > you can follow [these > instructions](https://quarto.org/docs/publishing/quarto-pub.html#github-action)","title":"Publishing your blog"},{"location":"tutorials/blogging/#creating-a-blog-within-a-nbdev-project","text":"In addition to a stand-alone blog that you might build with Quarto, you might want to include a blogging site in your nbdev project. This website has a blog as well! The easiest way to implement a blog is to emulate the directory structure of this folder . The general steps are: Create a blog/ directory in your notebooks folder. Create a index.qmd file in the root of the blog/ directory. Here is an example . The frontmatter the index.qmd file signals to Quarto that you intend to create a blog. For example, here is our front matter : --- title : nbdev Blog subtitle : News, tips, and commentary about all things nbdev listing : sort : \"date desc\" contents : \"posts\" sort-ui : false filter-ui : false categories : true feed : true page-layout : full --- The listing: field specifies how you want to structure your blog. Feel free to copy ours as-is, but we encourage you to consult the documentation for additional options. Create a link to your blog on your site\u2019s navbar so people can find it : To add a link to your blog on your site\u2019s navbar, you must edit the navbar section of _quarto.yml to include a link to your blog\u2019s listing page, which is blog/index.qmd in our example. For nbdev, the relevant part of our _quarto.yml file looks like this: The yaml snippet shown below is an abbreviated version of nbdev\u2019s _quarto.yml file. website : navbar : left : - text : \"Blog\" href : blog/index.qmd You can read more about the navbar in the Quarto docs . Create a folder for each blog post : This is not strictly required, but we recommend this as a way to keep your blog posts and related assets (pictures, videos etc) organized. Create your first blog post : You can emulate our example or create your own. In each folder, create a index.qmd or index.ipynb file. You can also put images and related assets in the same folder.","title":"Creating a blog within a nbdev project"},{"location":"tutorials/blogging/#folder-structure","text":"Below is an overview of the general folder structure for a blog within a nbdev site: nbs/blog \u251c\u2500\u2500 index.qmd \u2514\u2500\u2500 posts \u251c\u2500\u2500 2022-07-28-nbdev2 \u2502 \u251c\u2500\u2500 cover.png \u2502 \u251c\u2500\u2500 index.qmd \u2502 \u251c\u2500\u2500 ... \u2514\u2500\u2500 2022-08-25-jupyter-git \u251c\u2500\u2500 friendly-conflict.png \u251c\u2500\u2500 index.qmd \u2514\u2500\u2500 ... ... nbs/blog : this is the folder inside your notebook folder that contains the blog. index.qmd : this is at the root of your blog folder and is the listings page for your blog. posts/ : this a subdirectory for each blog post. YYYY-MM-DD-.../index.{qmd,ipynb} : this is where you author the content of each individual blog post.","title":"Folder structure"},{"location":"tutorials/blogging/#special-considerations-for-nbdev-blogs","text":"In contrast to standalone Quarto blogs, when you embed a blog in a nbdev website there are the following differences: You can use all nbdev directives in addition to Quarto ones. All nbdev features will be available in your nbdev blog in the same way they work for other pages. Your site will automatically deploy with GitHub Actions or whatever deployment mechanism you have for your nbdev site, so you do not have to use quarto publish .","title":"Special considerations for nbdev blogs"},{"location":"tutorials/blogging/#using-nbdev-features-in-blogs-outside-nbdev-projects","text":"> **Warning** > > *This section is for stand-alone blogs that are not part of a nbdev > documentation site. If you create a blog within a nbdev documentation > site, all nbdev features will automatically work.* If you create a standalone blog with Quarto, a limited number of nbdev features can still assist you. For example, we recommend installing Jupyter git hooks . A list of nbdev features available to you are listed in this article .","title":"Using nbdev features in blogs outside nbdev projects"},{"location":"tutorials/blogging/#creating-a-new-blog-site-from-scratch","text":"You can use the quarto CLI to setup a new blog project called myblog with the following command: quarto create-project myblog --type website:blog You can then preview your blog project with quarto preview . You can also publish your blog using the quarto publish command. > **Adding a notebook blog post** > > To add a notebook blog post to a blog project created with the above > commands, you can add an additional folder under `posts/` and name the > notebook `index.ipynb`. You will see existing example blog posts that > are `index.qmd` files in sibling folders you can look at for examples. > You will need to add [yaml front > matter](https://quarto.org/docs/tools/jupyter-lab.html#yaml-front-matter) > to the first cell of your notebook in the form of a raw cell. For more information about creating a blog with Quarto, see this guide .","title":"Creating A New Blog Site From Scratch"},{"location":"tutorials/blogging/#faq","text":"Do I need to migrate from fastpages? No you do not. However we will not be actively supporting fastpages going forward. Will migrating from fastpages to Quarto take lots of manual effort? You will have to do some manual work to make sure everything looks and works the same, including converting Jekyll shortcodes to equivalent Quarto commands. However, we have automated the biggest aspects for you. Please see Migrating from fastpages for instructions. I cannot find something in Quarto that does what #collapse_output did in fastpages Correct, this is a feature that isn\u2019t supported in Quarto yet. Why am I seeing {% twitter ...%} and {% fn_detail ... %} and other {%...%} commands in my Quarto blog posts? These are Jekyll shortcodes that you will have to manually migrate to Quarto. For example with the twitter embeds, you can insert the appropriate HTML as recommended by Twitter . For footnotes, you can see these docs . For other items, you should search the Quarto docs for how to enable your desired result. I created a new blog post and used #| hide but the cell is still showing. What is wrong? You must use Quarto directives, not nbdev-specific ones. See the difference between the two in these docs . This is because you are blogging with Quarto, not nbdev. The exception to this is you have a blog site in your nbdev project \u2013 in that case, nbdev-specific directives will work. How do I enable comments on my blog posts? In general, Quarto offers all of the same features and much more than fastpages did, including comments. If you search the Quarto docs for comments, you will see a page for enabling comments . How do I sort and hide posts? What about the publishing date since that\u2019s not in the filename? See the Quarto docs on creating a blog as well as listing pages . How do I customize my site? See the Quarto docs How do I do set up RSS Feeds and add particular features to my site? See the Quarto docs What does nbdev have to do with Quarto? . For just blogging, nothing! You can use Quarto for blogging without worrying about nbdev. In the past, we maintained a nbdev related project called fastpages , and are recommending that people migrate to Quarto if possible. Furthermore, nbdev is built on top of Quarto which means much of the functionality is similar. Finally, you can incorporate blogs into a nbdev project site, which we discuss in this section . For stand alone blogs, why are you directing us to Quarto, can I just use nbdev? nbdev is built on top of Quarto. For the purposes of blogging, adding nbdev is of little additional benefit if all you want to do is to blog. We decided to keep things simple and let people use Quarto directly instead of trying to abstract aspects of Quarto for blogging. Furthermore, having some knowledge of Quarto can be very helpful in using nbdev!. Lastly, you can still use some nbdev features in your blog, which are listed in this article .","title":"FAQ"},{"location":"tutorials/docs_only/","text":"Documentation Only Sites \u00a4 Background \u00a4 While nbdev is great for authoring software, you may wish to utilize the power of nbdev for the purposes of documenting existing code, or use various utilities of nbdev without having to write a python library . For example, you can use the following features of nbdev without creating a python package: Custom nbdev directives such as #|hide_line . Testing with nbdev_test . Automated entity linking with doclinks . Rendering API documentation with docments and show_doc . Setup \u00a4 To setup a documentation only site, you can follow these steps: Create a nbdev repo the usual way, using nbdev_new Remove library files rm setup.py .github/workflows/test.yaml nbs/00_core.ipynb Remove your library folder (this will be the lib_path field in settings.ini ): rm -rf <lib_path> Usage \u00a4 After setting up your project, you can use various nbdev utilities per usual: nbdev_preview for previewing your site nbdev_test for testing your docs locally Custom nbdev directives will be available to you (but you must be careful not to use irrelevant ones like #|export ). If you created your nbdev docs site on GitHub, GitHub Actions will publish your docs for you automatically as described here . You can publish your docs on other platforms as described here . Demo \u00a4 A minimal example of a documentation-only site is located here .","title":"Documentation Only Sites"},{"location":"tutorials/docs_only/#documentation-only-sites","text":"","title":"Documentation Only Sites"},{"location":"tutorials/docs_only/#background","text":"While nbdev is great for authoring software, you may wish to utilize the power of nbdev for the purposes of documenting existing code, or use various utilities of nbdev without having to write a python library . For example, you can use the following features of nbdev without creating a python package: Custom nbdev directives such as #|hide_line . Testing with nbdev_test . Automated entity linking with doclinks . Rendering API documentation with docments and show_doc .","title":"Background"},{"location":"tutorials/docs_only/#setup","text":"To setup a documentation only site, you can follow these steps: Create a nbdev repo the usual way, using nbdev_new Remove library files rm setup.py .github/workflows/test.yaml nbs/00_core.ipynb Remove your library folder (this will be the lib_path field in settings.ini ): rm -rf <lib_path>","title":"Setup"},{"location":"tutorials/docs_only/#usage","text":"After setting up your project, you can use various nbdev utilities per usual: nbdev_preview for previewing your site nbdev_test for testing your docs locally Custom nbdev directives will be available to you (but you must be careful not to use irrelevant ones like #|export ). If you created your nbdev docs site on GitHub, GitHub Actions will publish your docs for you automatically as described here . You can publish your docs on other platforms as described here .","title":"Usage"},{"location":"tutorials/docs_only/#demo","text":"A minimal example of a documentation-only site is located here .","title":"Demo"},{"location":"tutorials/git_friendly_jupyter/","text":"Git-Friendly Jupyter \u00a4 Version control is essential to developing software, yet Jupyter notebooks don\u2019t work with version control by default. nbdev solves this problem! It provides a set of hooks which enable git-friendly Jupyter notebooks in any git repo, including those that don\u2019t use the broader nbdev system. To get started, install nbdev: #### pip pip install -U nbdev #### conda conda install -c fastai nbdev then install hooks: nbdev_install_hooks That\u2019s it! Read on if you\u2019re stuck or if you\u2019d like to learn more about nbdev hooks and how to customise them. Check out our related blog post if you\u2019re curious about how this feature was developed and how it works under the hood. > **Note** > > The [clean hook](#nbdev_clean-on-saving-notebooks-in-jupyter) > currently only supports Jupyter Notebook and Jupyter Lab. If you\u2019re > using another notebook editor, like VSCode or PyCharm, you might want > to use [nbdev\u2019s pre-commit hooks](/tutorials/pre_commit.ipynb). Quickstart: Install nbdev hooks for a repo \u00a4 To start with, change directory to your current project and double-check. Don\u2019t worry about the strange path, that\u2019s because we\u2019re using a temporary directory for this tutorial: pwd /private/var/folders/ft/0gnvc3ts5jz4ddqtttp6tjvm0000gn/T/tmpez8nec5v/repo Install nbdev: pip install -Uqq nbdev Install nbdev hooks: nbdev_install_hooks Not in a git repository, git hooks cannot be installed. You\u2019ll see the above error if you\u2019re not in a git repo. If so, initialise a git repository: git init Initialized empty Git repository in /private/var/folders/ft/0gnvc3ts5jz4ddqtttp6tjvm0000gn/T/tmpez8nec5v/repo/.git/ Then try installing nbdev hooks again: nbdev_install_hooks Hooks are installed. If you already have a pre-save hook set in your Jupyter config file we won\u2019t be able to safely install a new one automatically. Instead, you\u2019ll encounter an error and will need to follow its instructions for a manual installation. Jupyter hooks will now be installed in your user\u2019s Jupyter config directory, and will work for all repos by default. Git hooks will only be installed in the current repo; you will need to rerun nbdev_install_hooks for each of your git repos . See configuring nbdev hooks if you\u2019d like to customise hook behaviour, for example, to opt out of hooks in certain repos. What are nbdev hooks? \u00a4 nbdev provides three hooks to ease Jupyter-git integration. nbdev_merge on merging notebooks with git \u00a4 One of the biggest complaints when working with Jupyter is that merge conflicts break notebooks. This is particularly problematic in projects with many collaborators. Jupyter notebook shows the above error when opening a notebook with merge conflicts. Oftentimes these conflicts are on metadata like cell execution counts that we don\u2019t really care about. nbdev comes with a custom git merge driver that automatically fixes conflicting outputs and metadata, and that leaves remaining conflicts in a state that still works with Jupyter. It works in all git commands that use merge under the hood, including merge , pull , rebase , and stash . Here\u2019s what the conflict looks like in Jupyter with nbdev\u2019s merge driver: nbdev_clean on saving notebooks in Jupyter \u00a4 Jupyter notebooks store a variety of metadata (including execution counts and notebook extension info) that aren\u2019t conducive to collaborative version control systems like git. These pollute diffs in pull requests and git histories (which can make debugging harder), and tend to cause merge conflicts. For example: { \"cell_type\": \"code\", - \"execution_count\": 1, + \"execution_count\": 2, \"metadata\": { \"hide_input\": false } Python\u2019s default repr is another example, since it includes a memory address which we usually aren\u2019t interested in: -<matplotlib.axes._subplots.AxesSubplot at 0x7fbc11508950> +<matplotlib.axes._subplots.AxesSubplot at 0x7fbc113dbe90> nbdev install a Jupyter hook which runs nbdev_clean to automatically clean unwanted metadata and outputs from your notebooks, including ids from default Python reprs! With nbdev hooks, the examples above would become: { \"cell_type\" : \"code\" , \"execution_count\" : null , \"metadata\" : {} } and <matplotlib.axes._subplots.AxesSubplot> nbdev_trust after merging notebooks with git \u00a4 A side-effect of Jupyter\u2019s security model is that widgets don\u2019t work in collaborative repos, unless you manually \u201ctrust\u201d notebooks after each git pull . There is a good reason behind this: since Jupyter notebooks contain HTML and JavaScript, the trust system avoids running malicious code when you open a notebook and don\u2019t explicitly run any cells. See the official documentation for more. Manually trusting notebooks each time is a pain. A more natural workflow would be trust a repo once-off, and all notebooks and changes thereafter. nbdev includes a git post-merge hook which runs nbdev_trust in your repo to do exactly this. Configuring nbdev hooks \u00a4 The most up-to-date reference of nbdev\u2019s settings is in the nbdev_create_config docs. In addition, this section will guide you through a few common configurations. Control whether Jupyter hooks are run: Globally enable Jupyter hooks: set jupyter_hooks = True in user settings Globally disable Jupyter hooks: set jupyter_hooks = False in user settings (at ~/.config/nbdev/settings.ini ) Enable Jupyter hooks only for selected repos: set jupyter_hooks = False in user settings and jupyter_hooks = True in selected repo settings Customise notebook cleaning with the following settings: Clean all outputs and metadata: clear_all Preserve certain metadata by key: allowed_metadata_keys and allowed_cell_metadata_keys Clean id s from default Python repr s: clean_ids All of the above can be customised per-user and per-repo. Control whether git hooks are run: Since git hooks are installed per-repo they\u2019ll only run in repos where you manually nbdev_install_hooks . If you change your mind later, you can uninstall git hooks by following the instructions in the .gitconfig file created in your repo.","title":"Git-Friendly Jupyter"},{"location":"tutorials/git_friendly_jupyter/#git-friendly-jupyter","text":"Version control is essential to developing software, yet Jupyter notebooks don\u2019t work with version control by default. nbdev solves this problem! It provides a set of hooks which enable git-friendly Jupyter notebooks in any git repo, including those that don\u2019t use the broader nbdev system. To get started, install nbdev: #### pip pip install -U nbdev #### conda conda install -c fastai nbdev then install hooks: nbdev_install_hooks That\u2019s it! Read on if you\u2019re stuck or if you\u2019d like to learn more about nbdev hooks and how to customise them. Check out our related blog post if you\u2019re curious about how this feature was developed and how it works under the hood. > **Note** > > The [clean hook](#nbdev_clean-on-saving-notebooks-in-jupyter) > currently only supports Jupyter Notebook and Jupyter Lab. If you\u2019re > using another notebook editor, like VSCode or PyCharm, you might want > to use [nbdev\u2019s pre-commit hooks](/tutorials/pre_commit.ipynb).","title":"Git-Friendly Jupyter"},{"location":"tutorials/git_friendly_jupyter/#quickstart-install-nbdev-hooks-for-a-repo","text":"To start with, change directory to your current project and double-check. Don\u2019t worry about the strange path, that\u2019s because we\u2019re using a temporary directory for this tutorial: pwd /private/var/folders/ft/0gnvc3ts5jz4ddqtttp6tjvm0000gn/T/tmpez8nec5v/repo Install nbdev: pip install -Uqq nbdev Install nbdev hooks: nbdev_install_hooks Not in a git repository, git hooks cannot be installed. You\u2019ll see the above error if you\u2019re not in a git repo. If so, initialise a git repository: git init Initialized empty Git repository in /private/var/folders/ft/0gnvc3ts5jz4ddqtttp6tjvm0000gn/T/tmpez8nec5v/repo/.git/ Then try installing nbdev hooks again: nbdev_install_hooks Hooks are installed. If you already have a pre-save hook set in your Jupyter config file we won\u2019t be able to safely install a new one automatically. Instead, you\u2019ll encounter an error and will need to follow its instructions for a manual installation. Jupyter hooks will now be installed in your user\u2019s Jupyter config directory, and will work for all repos by default. Git hooks will only be installed in the current repo; you will need to rerun nbdev_install_hooks for each of your git repos . See configuring nbdev hooks if you\u2019d like to customise hook behaviour, for example, to opt out of hooks in certain repos.","title":"Quickstart: Install nbdev hooks for a repo"},{"location":"tutorials/git_friendly_jupyter/#what-are-nbdev-hooks","text":"nbdev provides three hooks to ease Jupyter-git integration.","title":"What are nbdev hooks?"},{"location":"tutorials/git_friendly_jupyter/#nbdev_merge-on-merging-notebooks-with-git","text":"One of the biggest complaints when working with Jupyter is that merge conflicts break notebooks. This is particularly problematic in projects with many collaborators. Jupyter notebook shows the above error when opening a notebook with merge conflicts. Oftentimes these conflicts are on metadata like cell execution counts that we don\u2019t really care about. nbdev comes with a custom git merge driver that automatically fixes conflicting outputs and metadata, and that leaves remaining conflicts in a state that still works with Jupyter. It works in all git commands that use merge under the hood, including merge , pull , rebase , and stash . Here\u2019s what the conflict looks like in Jupyter with nbdev\u2019s merge driver:","title":"nbdev_merge on merging notebooks with git"},{"location":"tutorials/git_friendly_jupyter/#nbdev_clean-on-saving-notebooks-in-jupyter","text":"Jupyter notebooks store a variety of metadata (including execution counts and notebook extension info) that aren\u2019t conducive to collaborative version control systems like git. These pollute diffs in pull requests and git histories (which can make debugging harder), and tend to cause merge conflicts. For example: { \"cell_type\": \"code\", - \"execution_count\": 1, + \"execution_count\": 2, \"metadata\": { \"hide_input\": false } Python\u2019s default repr is another example, since it includes a memory address which we usually aren\u2019t interested in: -<matplotlib.axes._subplots.AxesSubplot at 0x7fbc11508950> +<matplotlib.axes._subplots.AxesSubplot at 0x7fbc113dbe90> nbdev install a Jupyter hook which runs nbdev_clean to automatically clean unwanted metadata and outputs from your notebooks, including ids from default Python reprs! With nbdev hooks, the examples above would become: { \"cell_type\" : \"code\" , \"execution_count\" : null , \"metadata\" : {} } and <matplotlib.axes._subplots.AxesSubplot>","title":"nbdev_clean on saving notebooks in Jupyter"},{"location":"tutorials/git_friendly_jupyter/#nbdev_trust-after-merging-notebooks-with-git","text":"A side-effect of Jupyter\u2019s security model is that widgets don\u2019t work in collaborative repos, unless you manually \u201ctrust\u201d notebooks after each git pull . There is a good reason behind this: since Jupyter notebooks contain HTML and JavaScript, the trust system avoids running malicious code when you open a notebook and don\u2019t explicitly run any cells. See the official documentation for more. Manually trusting notebooks each time is a pain. A more natural workflow would be trust a repo once-off, and all notebooks and changes thereafter. nbdev includes a git post-merge hook which runs nbdev_trust in your repo to do exactly this.","title":"nbdev_trust after merging notebooks with git"},{"location":"tutorials/git_friendly_jupyter/#configuring-nbdev-hooks","text":"The most up-to-date reference of nbdev\u2019s settings is in the nbdev_create_config docs. In addition, this section will guide you through a few common configurations. Control whether Jupyter hooks are run: Globally enable Jupyter hooks: set jupyter_hooks = True in user settings Globally disable Jupyter hooks: set jupyter_hooks = False in user settings (at ~/.config/nbdev/settings.ini ) Enable Jupyter hooks only for selected repos: set jupyter_hooks = False in user settings and jupyter_hooks = True in selected repo settings Customise notebook cleaning with the following settings: Clean all outputs and metadata: clear_all Preserve certain metadata by key: allowed_metadata_keys and allowed_cell_metadata_keys Clean id s from default Python repr s: clean_ids All of the above can be customised per-user and per-repo. Control whether git hooks are run: Since git hooks are installed per-repo they\u2019ll only run in repos where you manually nbdev_install_hooks . If you change your mind later, you can uninstall git hooks by following the instructions in the .gitconfig file created in your repo.","title":"Configuring nbdev hooks"},{"location":"tutorials/modular_nbdev/","text":"Modular nbdev \u00a4 While nbdev_new gets you started with everything you need to create a delightful Python package, you can also use each of nbdev\u2019s components listed below on their own . You might find this useful if you\u2019re porting a large system over to nbdev, documenting an existing code base, or if you\u2019d like to customize the nbdev workflow for your own project. Note that all of the commands below work without a settings.ini file unless otherwise noted. Document existing code: show_doc \u00a4 nbdev allows you to document existing code, even code that is not written in nbdev! nbdev.showdoc.show_doc allows you to render beautiful API documentation in notebooks and on Quarto sites. For example, you can render API documentation for numpy.all like this: from nbdev.showdoc import show_doc from numpy import all show_doc ( all ) ------------------------------------------------------------------------ ### all > all (a, axis=None, out=None, keepdims= , where= ) Test whether all array elements along a given axis evaluate to True. | | **Type** | **Default** | **Details** | |-------------|-------------------|-------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------| | a | array_like | | Input array or object that can be converted to an array. | | axis | NoneType | None | Axis or axes along which a logical AND reduction is performed. The default (`axis=None`) is to perform a logical AND over all the dimensions of the input array. `axis` may be negative, in which case it counts from the last to the first axis. .. versionadded:: 1.7.0 If this is a tuple of ints, a reduction is performed on multiple axes, instead of a single axis or all the axes as before. | | out | NoneType | None | Alternate output array in which to place the result. It must have the same shape as the expected output and its type is preserved (e.g., if `dtype(out)` is float, the result will consist of 0.0\u2019s and 1.0\u2019s). See :ref:`ufuncs-output-type` for more details. | | keepdims | \\_NoValueType | | If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array. If the default value is passed, then `keepdims` will not be passed through to the `all` method of sub-classes of `ndarray`, however any non-default value will be. If the sub-class\u2019 method does not implement `keepdims` any exceptions will be raised. | | where | \\_NoValueType | | Elements to include in checking for all `True` values. See `~numpy.ufunc.reduce` for details. .. versionadded:: 1.20.0 | | **Returns** | **ndarray, bool** | | **A new boolean or array is returned unless `out` is specified, in which case a reference to `out` is returned.** | > **Note** > > [`show_doc`](https://nbdev.fast.ai/api/showdoc.html#show_doc) > automatically parses docstrings that are written in the numpy style. > For more information [read > here](../api/showdoc.ipynb#numpy-docstrings). Testing notebooks: nbdev_test \u00a4 Testing notebooks can be very useful outside of nbdev, especially if you are documenting an existing code base and want to incorporate tests for your docs. The nbdev_test CLI utility allows you to accomplish this: You can test an individual notebook with the terminal command: nbdev_test --path notebook.ipynb \u2026or a folder of notebooks: nbdev_test --path tests/ Export code to modules: nb_export \u00a4 You can export a notebook to a module with the Python function: nb_export ( 'notebook.ipynb' , 'pkg' ) \u2026provided the notebook specifies a default_exp directive at the top, and export directives above each cell to be exported. We recommend including this in a code cell at the bottom of your notebook for convenience. Jupyter-git integration \u00a4 Jupyter and Git don\u2019t normally play well together, especially for things like merge conflicts. We have outlined all of these problems, and our solutions in this blog post . You can install our merge driver and hooks with the following command: nbdev_install_hooks We describe what nbdev_install_hooks does in detail on this page . You can also directly use any of its underlying commands, for example, to implement your own hooks or extensions: nbdev_clean nbdev_fix nbdev_merge nbdev_trust To configure your own hooks, Check out the pre-commit hooks tutorial . Python packaging \u00a4 nbdev.release provides utlities for easy packaging on PyPI, conda, and GitHub. Check out the nbdev.release docs for more information. Note that this functionality requires a settings.ini file.","title":"Modular nbdev"},{"location":"tutorials/modular_nbdev/#modular-nbdev","text":"While nbdev_new gets you started with everything you need to create a delightful Python package, you can also use each of nbdev\u2019s components listed below on their own . You might find this useful if you\u2019re porting a large system over to nbdev, documenting an existing code base, or if you\u2019d like to customize the nbdev workflow for your own project. Note that all of the commands below work without a settings.ini file unless otherwise noted.","title":"Modular nbdev"},{"location":"tutorials/modular_nbdev/#document-existing-code-show_doc","text":"nbdev allows you to document existing code, even code that is not written in nbdev! nbdev.showdoc.show_doc allows you to render beautiful API documentation in notebooks and on Quarto sites. For example, you can render API documentation for numpy.all like this: from nbdev.showdoc import show_doc from numpy import all show_doc ( all ) ------------------------------------------------------------------------ ### all > all (a, axis=None, out=None, keepdims= , where= ) Test whether all array elements along a given axis evaluate to True. | | **Type** | **Default** | **Details** | |-------------|-------------------|-------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------| | a | array_like | | Input array or object that can be converted to an array. | | axis | NoneType | None | Axis or axes along which a logical AND reduction is performed. The default (`axis=None`) is to perform a logical AND over all the dimensions of the input array. `axis` may be negative, in which case it counts from the last to the first axis. .. versionadded:: 1.7.0 If this is a tuple of ints, a reduction is performed on multiple axes, instead of a single axis or all the axes as before. | | out | NoneType | None | Alternate output array in which to place the result. It must have the same shape as the expected output and its type is preserved (e.g., if `dtype(out)` is float, the result will consist of 0.0\u2019s and 1.0\u2019s). See :ref:`ufuncs-output-type` for more details. | | keepdims | \\_NoValueType | | If this is set to True, the axes which are reduced are left in the result as dimensions with size one. With this option, the result will broadcast correctly against the input array. If the default value is passed, then `keepdims` will not be passed through to the `all` method of sub-classes of `ndarray`, however any non-default value will be. If the sub-class\u2019 method does not implement `keepdims` any exceptions will be raised. | | where | \\_NoValueType | | Elements to include in checking for all `True` values. See `~numpy.ufunc.reduce` for details. .. versionadded:: 1.20.0 | | **Returns** | **ndarray, bool** | | **A new boolean or array is returned unless `out` is specified, in which case a reference to `out` is returned.** | > **Note** > > [`show_doc`](https://nbdev.fast.ai/api/showdoc.html#show_doc) > automatically parses docstrings that are written in the numpy style. > For more information [read > here](../api/showdoc.ipynb#numpy-docstrings).","title":"Document existing code: show_doc"},{"location":"tutorials/modular_nbdev/#testing-notebooks-nbdev_test","text":"Testing notebooks can be very useful outside of nbdev, especially if you are documenting an existing code base and want to incorporate tests for your docs. The nbdev_test CLI utility allows you to accomplish this: You can test an individual notebook with the terminal command: nbdev_test --path notebook.ipynb \u2026or a folder of notebooks: nbdev_test --path tests/","title":"Testing notebooks: nbdev_test"},{"location":"tutorials/modular_nbdev/#export-code-to-modules-nb_export","text":"You can export a notebook to a module with the Python function: nb_export ( 'notebook.ipynb' , 'pkg' ) \u2026provided the notebook specifies a default_exp directive at the top, and export directives above each cell to be exported. We recommend including this in a code cell at the bottom of your notebook for convenience.","title":"Export code to modules: nb_export"},{"location":"tutorials/modular_nbdev/#jupyter-git-integration","text":"Jupyter and Git don\u2019t normally play well together, especially for things like merge conflicts. We have outlined all of these problems, and our solutions in this blog post . You can install our merge driver and hooks with the following command: nbdev_install_hooks We describe what nbdev_install_hooks does in detail on this page . You can also directly use any of its underlying commands, for example, to implement your own hooks or extensions: nbdev_clean nbdev_fix nbdev_merge nbdev_trust To configure your own hooks, Check out the pre-commit hooks tutorial .","title":"Jupyter-git integration"},{"location":"tutorials/modular_nbdev/#python-packaging","text":"nbdev.release provides utlities for easy packaging on PyPI, conda, and GitHub. Check out the nbdev.release docs for more information. Note that this functionality requires a settings.ini file.","title":"Python packaging"},{"location":"tutorials/pre_commit/","text":"Pre-Commit Hooks \u00a4 We provide hooks for the pre-commit framework to catch and fix uncleaned and unexported notebooks, locally, without having to wait for continuous integration pipelines to run. They might also be useful as an alternative to the Jupyter clean hook if you\u2019re using a notebook editor that isn\u2019t yet supported (e.g. VSCode). Install nbdev and pre-commit \u00a4 To get started, install nbdev: #### pip pip install -U nbdev #### conda conda install -c fastai nbdev \u2026then install pre-commit (check their latest instructions if you have any difficulty with these commands): #### pip pip install pre-commit #### conda conda install -c conda-forge pre-commit #### homebrew (macOS) brew install pre-commit Configure pre-commit for your repo \u00a4 Create a file named .pre-commit-config.yaml in the root of your repo, with the following contents: repos : - repo : https://github.com/fastai/nbdev rev : 2.2.10 hooks : - id : nbdev_clean - id : nbdev_export Include only the hook(s) you\u2019d like to run, as well as any other supported hooks . > **Tip** > > If you expect all collaborators to use pre-commit, add the > `.pre-commit-config.yaml` file to your repo. Otherwise, add it to your > `.gitignore`. Install pre-commit hooks into your repo: pre-commit install Make a commit and enjoy pre-commit in action \u00a4 When you do a git commit in a repo that has pre-commit hooks installed, your new workflow will be as follows: pre-commit runs each hook on your staged changes (as in, changes that you git add ed) If a hook changes files \u2013 for example, if a commited notebook wasn\u2019t cleaned \u2013 pre-commit stops the commit, leaving those changes as unstaged You can now stage those changes and make any edits required to get pre-commit to pass Redo the git commit , and if it succeeds, your commit will be created. Using it in practice isn\u2019t as complicated as it might sound. The best way to figure out if it works for you is to give it a try. How to override pre-commit if you get stuck \u00a4 If you struggle to get pre-commit to pass a commit that you absolutely think is correct, you can temporarily disable a hook like this: SKIP = hook git commit \u2026where hook refers to a valid hook in your configuration, for example, to disable the nbdev_export hook: SKIP = nbdev_export git commit You can also disable pre-commit entirely with the --no-verify flag: git commit --no-verify Finally, if you decide it\u2019s not for you, you can completely remove pre-commit hooks from your repo with: pre-commit uninstall","title":"Pre-Commit Hooks"},{"location":"tutorials/pre_commit/#pre-commit-hooks","text":"We provide hooks for the pre-commit framework to catch and fix uncleaned and unexported notebooks, locally, without having to wait for continuous integration pipelines to run. They might also be useful as an alternative to the Jupyter clean hook if you\u2019re using a notebook editor that isn\u2019t yet supported (e.g. VSCode).","title":"Pre-Commit Hooks"},{"location":"tutorials/pre_commit/#install-nbdev-and-pre-commit","text":"To get started, install nbdev: #### pip pip install -U nbdev #### conda conda install -c fastai nbdev \u2026then install pre-commit (check their latest instructions if you have any difficulty with these commands): #### pip pip install pre-commit #### conda conda install -c conda-forge pre-commit #### homebrew (macOS) brew install pre-commit","title":"Install nbdev and pre-commit"},{"location":"tutorials/pre_commit/#configure-pre-commit-for-your-repo","text":"Create a file named .pre-commit-config.yaml in the root of your repo, with the following contents: repos : - repo : https://github.com/fastai/nbdev rev : 2.2.10 hooks : - id : nbdev_clean - id : nbdev_export Include only the hook(s) you\u2019d like to run, as well as any other supported hooks . > **Tip** > > If you expect all collaborators to use pre-commit, add the > `.pre-commit-config.yaml` file to your repo. Otherwise, add it to your > `.gitignore`. Install pre-commit hooks into your repo: pre-commit install","title":"Configure pre-commit for your repo"},{"location":"tutorials/pre_commit/#make-a-commit-and-enjoy-pre-commit-in-action","text":"When you do a git commit in a repo that has pre-commit hooks installed, your new workflow will be as follows: pre-commit runs each hook on your staged changes (as in, changes that you git add ed) If a hook changes files \u2013 for example, if a commited notebook wasn\u2019t cleaned \u2013 pre-commit stops the commit, leaving those changes as unstaged You can now stage those changes and make any edits required to get pre-commit to pass Redo the git commit , and if it succeeds, your commit will be created. Using it in practice isn\u2019t as complicated as it might sound. The best way to figure out if it works for you is to give it a try.","title":"Make a commit and enjoy pre-commit in action"},{"location":"tutorials/pre_commit/#how-to-override-pre-commit-if-you-get-stuck","text":"If you struggle to get pre-commit to pass a commit that you absolutely think is correct, you can temporarily disable a hook like this: SKIP = hook git commit \u2026where hook refers to a valid hook in your configuration, for example, to disable the nbdev_export hook: SKIP = nbdev_export git commit You can also disable pre-commit entirely with the --no-verify flag: git commit --no-verify Finally, if you decide it\u2019s not for you, you can completely remove pre-commit hooks from your repo with: pre-commit uninstall","title":"How to override pre-commit if you get stuck"},{"location":"tutorials/qmd_intro/","text":"Qmd Documents \u00a4 Qmd documents are Markdown documents, but with loads of extra functionality provided by Quarto and Pandoc . nbdev uses Quarto to render its pages (with some extra functionality), and Quarto uses Pandoc to render its pages (with some extra functionality). Every markdown cell in an nbdev notebook is treated as qmd, and nbdev can publish plain qmd text files, and qmd RenderScripts . Therefore, it\u2019s a good idea to be familiar with the main features of qmd. Just like with RenderScripts, you can use hot/live reloading with plain qmd text files \u2013 so as soon as you save the file, you\u2019ll see the new output in your web browser (assuming you\u2019ve got nbdev_preview running). Computations \u00a4 You can generate data-driven documents using qmd files. For instance, consider this table (also shown in the RenderScript tutorial for comparison), containing a list of the people with testimonials on nbdev\u2019s home page: The table above is generated using an embedded qmd computation block from the following python list: testimonials = [ ( 'chris-lattner.png' , 'Chris Lattner' , 'Inventor of Swift and LLVM' ), ( 'fernando-p\u00e9rez.jpeg' , 'Fernando P\u00e9rez' , 'Creator of Jupyter' ), ( 'david-berg.jpeg' , 'David Berg' , 'Software Engineer, Netflix' ), ( 'erik-gaasedelen.jpeg' , 'Erik Gaasedelen' , 'Software Engineer, Lyft' ), ( 'roxanna-pourzand.jpeg' , 'Roxanna Pourzand' , 'Product Manager, Transform' ), ( 'hugo-bowne-anderson.jpeg' , 'Hugo Bowne-Anderson' , 'Head of Developer Relations, Outerbounds' ) ] Just like in the RenderScript example, to produce the table from this python list, the following four lines of code are used: print ( qmd . tbl_row ([ '' , 'Name' , 'Position' ])) print ( qmd . tbl_sep ([ 1 , 3 , 4 ])) for fname , name , position in testimonials : print ( qmd . tbl_row ([ im ( fname , 60 ), name , position ])) For data-driven documents such as this one, we add the following to the YAML frontmatter, which hides the code used to produce outputs, and also does not add any extra formatting to outputs: --- execute: echo: false output: asis --- Compare the source code of the RenderScript example and of the current page to see how computations are used in RenderScripts compared to plain qmd text files. We find that we like to use Notebooks for most pages we build, since they\u2019ve got so much helpful functionality (such as pasting images directly into cells). We use RenderScripts for complex web pages like the nbdev home page, and qmd files for pages that are mainly markdown and don\u2019t need any notebook functionality. Formatting \u00a4 In addition to the standard markdown formatting , Quarto qmd adds many additional features. Look at the full quarto docs to see everything it can do \u2013 we\u2019ll just highlight a few of our favorites here. Divs and classes \u00a4 You can create HTML divs , by surrounding lines with ::: . Divs can include classes by placing {.classname} after the opening ::: . Here\u2019s an example: ::: {.border} This content can be styled with a border ::: This is how that\u2019s rendered: This content can be styled with a border You might be wondering where that border class comes from\u2026 Quarto comes with support for Bootstrap 5 and Bootswatch themes so there\u2019s lots of classes available you can use in your documents. Remember, all notebook markdown cells are also considered qmd, and can also use all the formatting tricks discussed in this section. Callouts \u00a4 A special kind of block you can use is the callout block . Here\u2019s an example: :::{.callout-note} Note that there are five types of callouts, including: `note` , `warning` , `important` , `tip` , and `caution` . ::: \u2026and here\u2019s how it\u2019s rendered: > **Note** > > Note that there are five types of callouts, including: `note`, > `warning`, `important`, `tip`, and `caution`. Images \u00a4 You can add images (quarto calls them figures to your document, along with captions, and you can even arrange them into layouts. Here\u2019s an example: ::: {layout-ncol=3} ![ Jupyter ]( /images/jupyter.svg ) ![ Vscode ]( /images/vscode.svg ) ![ Git ]( /images/git.svg ) ::: Jupyter Vscode Git","title":"Qmd Documents"},{"location":"tutorials/qmd_intro/#qmd-documents","text":"Qmd documents are Markdown documents, but with loads of extra functionality provided by Quarto and Pandoc . nbdev uses Quarto to render its pages (with some extra functionality), and Quarto uses Pandoc to render its pages (with some extra functionality). Every markdown cell in an nbdev notebook is treated as qmd, and nbdev can publish plain qmd text files, and qmd RenderScripts . Therefore, it\u2019s a good idea to be familiar with the main features of qmd. Just like with RenderScripts, you can use hot/live reloading with plain qmd text files \u2013 so as soon as you save the file, you\u2019ll see the new output in your web browser (assuming you\u2019ve got nbdev_preview running).","title":"Qmd Documents"},{"location":"tutorials/qmd_intro/#computations","text":"You can generate data-driven documents using qmd files. For instance, consider this table (also shown in the RenderScript tutorial for comparison), containing a list of the people with testimonials on nbdev\u2019s home page: The table above is generated using an embedded qmd computation block from the following python list: testimonials = [ ( 'chris-lattner.png' , 'Chris Lattner' , 'Inventor of Swift and LLVM' ), ( 'fernando-p\u00e9rez.jpeg' , 'Fernando P\u00e9rez' , 'Creator of Jupyter' ), ( 'david-berg.jpeg' , 'David Berg' , 'Software Engineer, Netflix' ), ( 'erik-gaasedelen.jpeg' , 'Erik Gaasedelen' , 'Software Engineer, Lyft' ), ( 'roxanna-pourzand.jpeg' , 'Roxanna Pourzand' , 'Product Manager, Transform' ), ( 'hugo-bowne-anderson.jpeg' , 'Hugo Bowne-Anderson' , 'Head of Developer Relations, Outerbounds' ) ] Just like in the RenderScript example, to produce the table from this python list, the following four lines of code are used: print ( qmd . tbl_row ([ '' , 'Name' , 'Position' ])) print ( qmd . tbl_sep ([ 1 , 3 , 4 ])) for fname , name , position in testimonials : print ( qmd . tbl_row ([ im ( fname , 60 ), name , position ])) For data-driven documents such as this one, we add the following to the YAML frontmatter, which hides the code used to produce outputs, and also does not add any extra formatting to outputs: --- execute: echo: false output: asis --- Compare the source code of the RenderScript example and of the current page to see how computations are used in RenderScripts compared to plain qmd text files. We find that we like to use Notebooks for most pages we build, since they\u2019ve got so much helpful functionality (such as pasting images directly into cells). We use RenderScripts for complex web pages like the nbdev home page, and qmd files for pages that are mainly markdown and don\u2019t need any notebook functionality.","title":"Computations"},{"location":"tutorials/qmd_intro/#formatting","text":"In addition to the standard markdown formatting , Quarto qmd adds many additional features. Look at the full quarto docs to see everything it can do \u2013 we\u2019ll just highlight a few of our favorites here.","title":"Formatting"},{"location":"tutorials/qmd_intro/#divs-and-classes","text":"You can create HTML divs , by surrounding lines with ::: . Divs can include classes by placing {.classname} after the opening ::: . Here\u2019s an example: ::: {.border} This content can be styled with a border ::: This is how that\u2019s rendered: This content can be styled with a border You might be wondering where that border class comes from\u2026 Quarto comes with support for Bootstrap 5 and Bootswatch themes so there\u2019s lots of classes available you can use in your documents. Remember, all notebook markdown cells are also considered qmd, and can also use all the formatting tricks discussed in this section.","title":"Divs and classes"},{"location":"tutorials/qmd_intro/#callouts","text":"A special kind of block you can use is the callout block . Here\u2019s an example: :::{.callout-note} Note that there are five types of callouts, including: `note` , `warning` , `important` , `tip` , and `caution` . ::: \u2026and here\u2019s how it\u2019s rendered: > **Note** > > Note that there are five types of callouts, including: `note`, > `warning`, `important`, `tip`, and `caution`.","title":"Callouts"},{"location":"tutorials/qmd_intro/#images","text":"You can add images (quarto calls them figures to your document, along with captions, and you can even arrange them into layouts. Here\u2019s an example: ::: {layout-ncol=3} ![ Jupyter ]( /images/jupyter.svg ) ![ Vscode ]( /images/vscode.svg ) ![ Git ]( /images/git.svg ) ::: Jupyter Vscode Git","title":"Images"},{"location":"tutorials/renderscript/","text":"RenderScripts \u00a4 RenderScripts are regular Python scripts, except that: Rather than just having the extension .py , they have an extension like .qmd.py They contain a module docstring containing frontmatter (i.e three hyphens on a line, then some yaml, then another three hyphens on a line). These scripts are run when your site is rendered. Anything that they print to stdout becomes a new file in your site. The name of the file is the same as the name of the .py script, but without the .py extension. For instance, the page you\u2019re reading right now page is created by a script called renderscript.qmd.py , which you\u2019ll find here . Hot/live reloading even works with these .py scripts \u2013 so as soon as you save the script, you\u2019ll see the new output in your web browser. This approach can be particularly helpful for generating data-driven documents. For instance, consider this table, containing a list of the people with testimonials on nbdev\u2019s home page: Name Position Chris Lattner Inventor of Swift and LLVM Fernando P\u00e9rez Creator of Jupyter David Berg Software Engineer, Netflix Erik Gaasedelen Software Engineer, Lyft Roxanna Pourzand Product Manager, Transform Hugo Bowne-Anderson Head of Developer Relations, Outerbounds When creating a table like this, it can be tricky to ensure that markdown is correct and consistent for every row. It can be easier and more maintainable to programatically generate it. The table above is generated from the following python list: testimonials = [ ( 'chris-lattner.png' , 'Chris Lattner' , 'Inventor of Swift and LLVM' ), ( 'fernando-p\u00e9rez.jpeg' , 'Fernando P\u00e9rez' , 'Creator of Jupyter' ), ( 'david-berg.jpeg' , 'David Berg' , 'Software Engineer, Netflix' ), ( 'erik-gaasedelen.jpeg' , 'Erik Gaasedelen' , 'Software Engineer, Lyft' ), ( 'roxanna-pourzand.jpeg' , 'Roxanna Pourzand' , 'Product Manager, Transform' ), ( 'hugo-bowne-anderson.jpeg' , 'Hugo Bowne-Anderson' , 'Head of Developer Relations, Outerbounds' ) ] To produce the table from this python list, the following four lines of code are used: print ( qmd . tbl_row ([ '' , 'Name' , 'Position' ])) print ( qmd . tbl_sep ([ 1 , 3 , 4 ])) for fname , name , position in testimonials : print ( qmd . tbl_row ([ im ( fname , 60 ), name , position ])) tbl_hdr and tbl_row are two functions imported from the module nbdev.qmd . nbdev.qmd is a small module that has some convenient functions for creating .qmd documents, such as the table creation functions used above. You can see more examples of their use in index.qmd.py , which is the RenderScript which creates the nbdev home page . The nbdev home page is a more idiomatic example of how to use RenderScripts than the current page\u2019s source code \u2013 we\u2019re only using RenderScript for the current page to provide a more simple example. In practice, we find that RenderScripts are best used for pages containing a lot of data-driven content, reusable components, and so forth. You can use RenderScripts to create any kind of file. For instance, the SVG below is created dynamically using this script : Once you\u2019ve run nbdev_preview or nbdev_docs you\u2019ll find your rendered document in the _proc directory, along with all of your processed notebooks. This can be helpful for debugging. You can also simply call your script directly from the shell (e.g. python renderscript.qmd.py ) to view the printed output.","title":"RenderScripts"},{"location":"tutorials/renderscript/#renderscripts","text":"RenderScripts are regular Python scripts, except that: Rather than just having the extension .py , they have an extension like .qmd.py They contain a module docstring containing frontmatter (i.e three hyphens on a line, then some yaml, then another three hyphens on a line). These scripts are run when your site is rendered. Anything that they print to stdout becomes a new file in your site. The name of the file is the same as the name of the .py script, but without the .py extension. For instance, the page you\u2019re reading right now page is created by a script called renderscript.qmd.py , which you\u2019ll find here . Hot/live reloading even works with these .py scripts \u2013 so as soon as you save the script, you\u2019ll see the new output in your web browser. This approach can be particularly helpful for generating data-driven documents. For instance, consider this table, containing a list of the people with testimonials on nbdev\u2019s home page: Name Position Chris Lattner Inventor of Swift and LLVM Fernando P\u00e9rez Creator of Jupyter David Berg Software Engineer, Netflix Erik Gaasedelen Software Engineer, Lyft Roxanna Pourzand Product Manager, Transform Hugo Bowne-Anderson Head of Developer Relations, Outerbounds When creating a table like this, it can be tricky to ensure that markdown is correct and consistent for every row. It can be easier and more maintainable to programatically generate it. The table above is generated from the following python list: testimonials = [ ( 'chris-lattner.png' , 'Chris Lattner' , 'Inventor of Swift and LLVM' ), ( 'fernando-p\u00e9rez.jpeg' , 'Fernando P\u00e9rez' , 'Creator of Jupyter' ), ( 'david-berg.jpeg' , 'David Berg' , 'Software Engineer, Netflix' ), ( 'erik-gaasedelen.jpeg' , 'Erik Gaasedelen' , 'Software Engineer, Lyft' ), ( 'roxanna-pourzand.jpeg' , 'Roxanna Pourzand' , 'Product Manager, Transform' ), ( 'hugo-bowne-anderson.jpeg' , 'Hugo Bowne-Anderson' , 'Head of Developer Relations, Outerbounds' ) ] To produce the table from this python list, the following four lines of code are used: print ( qmd . tbl_row ([ '' , 'Name' , 'Position' ])) print ( qmd . tbl_sep ([ 1 , 3 , 4 ])) for fname , name , position in testimonials : print ( qmd . tbl_row ([ im ( fname , 60 ), name , position ])) tbl_hdr and tbl_row are two functions imported from the module nbdev.qmd . nbdev.qmd is a small module that has some convenient functions for creating .qmd documents, such as the table creation functions used above. You can see more examples of their use in index.qmd.py , which is the RenderScript which creates the nbdev home page . The nbdev home page is a more idiomatic example of how to use RenderScripts than the current page\u2019s source code \u2013 we\u2019re only using RenderScript for the current page to provide a more simple example. In practice, we find that RenderScripts are best used for pages containing a lot of data-driven content, reusable components, and so forth. You can use RenderScripts to create any kind of file. For instance, the SVG below is created dynamically using this script : Once you\u2019ve run nbdev_preview or nbdev_docs you\u2019ll find your rendered document in the _proc directory, along with all of your processed notebooks. This can be helpful for debugging. You can also simply call your script directly from the shell (e.g. python renderscript.qmd.py ) to view the printed output.","title":"RenderScripts"},{"location":"tutorials/tutorial/","text":"End-To-End Walkthrough \u00a4 The written tutorial below shows you how to create a Python package from scratch using nbdev. Alternatively, you can watch this video tutorial where Jeremy Howard and Hamel Husain guide you through a similar process step by step: Installation \u00a4 You\u2019ll need the following software to complete the tutorial, read on for specific installation instructions: Python A Python package manager: we recommend conda or pip Jupyter Notebook nbdev Quarto If you haven\u2019t worked with Python before, we recommend getting started with the Anaconda Individual Edition and using the conda package manager. Install Jupyter Notebook \u00a4 Launch a terminal and install Jupyter Notebook by entering: conda install notebook \u2026or pip install notebook \u2026if you\u2019re using the pip package manager. Enter y (for yes) if prompted. Installation should take a few seconds, during which text will be printed in the terminal. You\u2019ll know its completed when you see the terminal prompt and are able to type again. You can now launch Jupyter by entering: jupyter notebook This should open the Jupyter home page in a new browser tab: > **Why not Jupyter Lab?** > > As Jupyter power users we still prefer Jupyter Notebook (with > [customizations](#install-collapsible-headings-and-toc2)) over more > feature-full alternatives like Jupyter Lab, VSCode, or PyCharm. We > find Jupyter Notebook simpler, faster, and more robust. Install nbdev \u00a4 The next step is to install nbdev itself. Jupyter Notebook comes with its own terminal, so we\u2019ll use that moving forward. In the Jupyter home page (shown in the previous section), click the \u201cNew\u201d dropdown on the right side, then \u201cTerminal\u201d. A browser tab should open with a blank terminal: Enter: conda install -c fastai nbdev \u2026or pip install nbdev \u2026if you\u2019re using pip. Type y (for yes) when prompted, and wait a few seconds until nbdev is installed. Install Quarto \u00a4 nbdev provides a command to install the latest version of Quarto. In the terminal, enter: nbdev_install_quarto Your password may be requested at this point. Since nbdev is open source, you can read the source code of this command to verify that it isn\u2019t doing anything malicious. Or, if you prefer, you may instead follow Quarto\u2019s official installation instructions . First steps \u00a4 By the end of this section you\u2019ll have your own nbdev repo with tests, continuous integration, streamlined PyPI & conda packaging, and a documentation website. Create an empty GitHub repo \u00a4 Create an empty GitHub repo using the convenient link github.com/new . If you get stuck, you might find GitHub\u2019s Create a repo page helpful. Remember to add a description, since nbdev will use that later. Don\u2019t add a README file, .gitignore, or license file just yet. If you\u2019re using the web interface, it should look something like this before you click \u201cCreate Repository\u201d: You should then be redirected to your new repo: > **Try GitHub\u2019s powerful CLI** > > GitHub\u2019s web interface is a great way to get started. As you grow more > experienced, you might want to explore [the GitHub > CLI](https://github.com/cli/cli) (command line interface). We often > prefer to use command line tools for repetitive tasks where we\u2019re > likely to make mistakes. Having those tasks written as small scripts > in your terminal means that you can repeat them with little effort. Initialise your repo with nbdev \u00a4 Now clone your repo from the Jupyter terminal you started earlier (or create a new terminal following those instructions if needed). If you get stuck here, you might find GitHub\u2019s Cloning a repository page helpful. Since we created a repo named nbev-hello-world with the fastai user, we can clone it as follows: git clone https://github.com/fastai/nbdev-hello-world.git Then cd (change directory) to our repo: cd nbdev-hello-world You may have seen this message while cloning: You appear to have cloned an empty repository. \u2026since the repo is completely empty. Let\u2019s add some files! nbdev provides the nbdev_new command to initialise an empty git repository. It\u2019ll infer information about your project from git and GitHub, and ask you to input anything remaining. It will create files in your repo that: Streamline publishing Python packages to PyPI and conda. Configure Quarto for publication-grade technical documentation. Setup GitHub actions to test notebooks and build and deploy Quarto docs to GitHub pages. Initialise your nbdev repo by entering: nbdev_new It may ask you to enter information that it couldn\u2019t infer from git or GitHub. > **Note** > > [`nbdev_new`](https://nbdev.fast.ai/api/cli.html#nbdev_new) assumes > that your package name is the same as your repo name (with `-` > replaced by `_`). Use the `--lib_name` option if that isn\u2019t the case. Double-check your settings.ini file to ensure that it has all of the correct information. Then commit and push your additions to GitHub: git add . git commit -m 'Initial commit' git push It\u2019s time to see all of the goodies nbdev gives you! Check out your workflows \u00a4 Open GitHub Actions by clicking the \u201cActions\u201d tab near the top of your repo page. You should see two workflow runs: If you opened this page shortly after pushing your initial commit, the runs may not have a green check (\u2705) because they\u2019re still \u201cIn progress\u201d or \u201cQueued\u201d. That\u2019s no problem, they shouldn\u2019t take much more than a minute to complete. If you see a red cross (\u274c), that means something failed. Click on the cross, then click Details , and you\u2019ll be able to see what failed. If you can\u2019t figure out what\u2019s wrong, search the forum in case someone else resolved the same issue, otherwise create a new post describing your issue in as much detail as you can, and we\u2019ll try our best to help you. Remember that including a link to an actual repo and/or GitHub Action is the best way for us to quickly identify what\u2019s wrong. What do these workflows do? CI \u2013 The CI (continuous integration) workflow streamlines your developer workflow, particularly with multiple collaborators. Every time you push to GitHub, it ensures that: Your notebooks and libraries are in sync Your notebooks are cleaned of unwanted metadata (which pollute pull requests and git histories and lead to merge conflicts) Your notebook tests all pass Deploy to GitHub Pages \u2013 Builds your docs with Quarto and deploys it to GitHub Pages. We provide these basic workflows out-of-the-box, however, you can edit their corresponding YAML files in the .github/workflows/ folder to your liking. Note that you\u2019ll need to enable GitHub Pages for your repo before you can access your docs website. We\u2019ll do that now. Check out your docs \u00a4 nbdev hosts your docs on GitHub Pages\u2014an excellent (and free!) way to host websites. Enabling GitHub Pages \u00a4 > **Enabling GitHub Pages Is Not Required For Everyone** > > nbdev makes a best effort to automatically enable GitHub Pages for > you, however, there some cases where this is not possible such as > private repos or where your organization\u2019s permissions are restricted. > If you are having trouble seeing your site, we suggest checking if > Pages are enabled for your repo by following the below instructions. > > You can enable it for your repo by clicking on the \u201cSettings\u201d tab near > the top-right of your repo page, then \u201cPages\u201d on the left, then > setting the \u201cBranch\u201d to \u201cgh-pages\u201d, and finally clicking \u201cSave\u201d. > > It should look similar to this after you click \u201cSave\u201d: > > class=\"pb-2 border rounded shadow-sm\" data-fig-align=\"center\" /> Head back to GitHub Actions and you should see a new workflow run: \u201cpages build and deployment\u201d. As the name says, this workflow deploys your website contents to GitHub Pages. Wait for the workflow run to complete, then open your website. By default it should be available at: https://{user}.github.io/{repo} . For example, you can view fastai \u2019s nbdev-hello-world docs at https://fastai.github.io/nbdev-hello-world . > **Note** > > nbdev uses GitHub Pages by default because its easily accessible. > However, you can use any host you like. See [these > docs](../explanations/docs.ipynb#deploying-your-docs-on-other-platforms) > for more information on this. Recap \u00a4 You now have a base nbdev repo with continuous integration and hosted documentation! Here\u2019s a recap of the steps you took: Created a GitHub repo Initialised your repo with nbdev_new Pushed to GitHub. Make your first edit \u00a4 In this section, you\u2019ll make your first edit to the repo you created in First steps . Install hooks for git-friendly notebooks \u00a4 Step one when working with Jupyter notebooks in a new repo is to install nbdev\u2019s hooks (you can think of \u201chooks\u201d as plugins or extensions to an application). Install them by entering this command in your terminal: nbdev_install_hooks > **Note** > > The [clean hook](#nbdev_clean-on-saving-notebooks-in-jupyter) > currently only supports Jupyter Notebook and Jupyter Lab. If you\u2019re > using another notebook editor, like VSCode or PyCharm, you might want > to use [nbdev\u2019s pre-commit hooks](/tutorials/pre_commit.ipynb) as > well. See Git-friendly Jupyter for more about how nbdev hooks work and how to customise them. Here\u2019s a short summary: Fix broken notebooks due to git merge conflicts so that they can be opened and resolved directly in Jupyter. Each time you save a Jupyter notebook, automatically clean unwanted metadata to remove unnecessary changes in pull requests and reduce the chance of git merge conflicts. Automatically trust notebooks in the repo so that you can view widgets from collaborators\u2019 commits. For this reason, you should not install hooks into a repo you don\u2019t trust . > **Tip** > > nbdev hooks works on *any* git repo, even if it doesn\u2019t use the > broader nbdev system. Build your library \u00a4 You should now create your package from your notebook by running: nbdev_export This will create Python modules for your notebooks. These modules will make up the contents of your Python package. Install your package \u00a4 You might have noticed that nbdev_new created a Python package in your repo. In our case, it was automatically named nbdev_hello_world by using our repo name nbdev-hello-world and replacing - with _ to make it a valid Python package. The next step is to install your package by entering this into your terminal: pip install -e '.[dev]' This is the recommended way to make a Python package importable from anywhere in your current environment: -e \u2013 short for \u201ceditable\u201d, lets you immediately use changes made to your package during development. . \u2013 refers to the current directory. [dev] \u2013 includes \u201cdevelopment\u201d requirements: other packages that your notebooks use solely for documentation or testing. Preview your docs \u00a4 nbdev is an interactive programming environment that values fast feedback loops. The nbdev_preview command helps achieve this by using Quarto to render your docs on your computer and keep them updated as your edit your notebooks. Start the preview by entering this into your terminal: nbdev_preview It may say Preparing to preview for a few seconds while it gets started, and will eventually display something like: Watching files for changes Browse at http://localhost:3000/ Click the link to open the preview in a new browser tab. It should look exactly like your online docs. > **Tip** > > We often find it useful to keep a preview window open on the side > while we\u2019re editing our notebooks in Jupyter. Edit 00_core.ipynb \u00a4 Now, run jupyter notebook , and click 00_core.ipynb (note: if you started this tutorial using nbdev_new then this file will be in the nbs folder). You don\u2019t have to start your notebook names with a number, but we find it helpful to show the order that your project should be read in \u2013 even though it could have been created in a different order. Add your own frontmatter \u00a4 You\u2019ll see something that looks a bit like this: **core** > Fill in a module description here #| default_exp core Let\u2019s explain what these special cells means: The first is a markdown cell with nbdev\u2019s markdown frontmatter syntax that defines notebook metadata used by Quarto, our documentation engine (see the frontmatter reference page for more). It contains: H1 header (\u201ccore\u201d) \u2013 defining the page title Quote (\u201cFill in a module description here\u201d) \u2013 defining the page description The second is a code cell with a directive default_exp which decides which module this notebook will export to (see the Directives explanation for more). Currently, it exports to the core module. Next, rename the notebook, replace the title and description, and change the default export module for your own project. Once you\u2019re done, save the notebook. The live preview started in the previous section should update with your latest changes. Rerun all cells in your notebook to ensure that they work, and to export the updated modules. > **Tip** > > We find the \u201crestart kernel and run all cells\u201d Jupyter command (the \u23e9 > button) so invaluable that we bind it to a keyboard shortcut. A common > criticism of notebooks is that out-of-order execution leads to > irreproducible notebooks. In our experience, making \u201crestart and > rerun\u201d a habit solves this problem. Running the notebook exports Python modules because of the last cell which contains: #| hide import nbdev ; nbdev . nbdev_export () What does this mean? #| hide is a directive (like #| default_exp ) which excludes a cell from both your exported module and docs nbdev_export is the command used to export your notebooks to Python modules. We recommend including a cell like this at the bottom of all of the notebooks you want to export. > **Warning** > > Remember to delete any unused modules that aren\u2019t exported by a > notebook or otherwise needed by your package. This is likely to happen > if you change the default export of a notebook \u2013 nbdev doesn\u2019t remove > the old module. This is intended, since nbdev is designed to work with > hybrid packages that use .py modules (with no corresponding notebook) > as well as those exported from notebooks. Add your own function \u00a4 Add a new code cell below the #| default_exp cell with a function. For example: #| export def say_hello ( to ): \"Say hello to somebody\" return f 'Hello { to } !' Notice how it includes #| export at the top \u2013 this is a directive (like #| default_exp ) that tells nbdev to include the cell in your exported module and in your documentation. The documentation should look like this: ------------------------------------------------------------------------ source ### say_hello > say_hello (to) Say hello to somebody Add your own examples, tests, and docs \u00a4 One of the superpowers of notebook-driven development is that you can very easily add examples, tests, and documentation right below your code. Include regular code cells, and they\u2019ll appear (with output) in your docs, for example: say_hello ( \"Isaac\" ) 'Hello Isaac!' This is a test too! When you run nbdev_test it will execute this cell (and all other test cells) and fail if they raise any exceptions. For tests, it\u2019s preferred to use more explicit assert s: assert say_hello ( \"Hamel\" ) == \"Hello Hamel!\" \u2026or functions from fastcore.test , which behave like assert but also display the actual and expected values if they differ: from fastcore.test import * test_eq ( say_hello ( \"Hamel\" ), \"Hello Hamel!\" ) Another superpower of notebook-driven development is that your examples can include plots, images, and even JavaScript widgets. For example, here\u2019s an SVG circle: from IPython.display import display , SVG display ( SVG ( '<svg height=\"100\" xmlns=\"http://www.w3.org/2000/svg\"><circle cx=\"50\" cy=\"50\" r=\"40\"/></svg>' )) Prepare your changes \u00a4 Before commiting your changes to GitHub we recommend running nbdev_prepare in the terminal, which bundles the following commands: nbdev_export : Builds the .py modules from Jupyter notebooks nbdev_test : Tests your notebooks nbdev_clean : Cleans your notebooks to get rid of extreanous output for Github nbdev_readme : Updates README.md from your index notebook. Edit index.ipynb \u00a4 Now you\u2019re ready to create your documentation home page and README.md file; these are both generated automatically from index.ipynb. Open the Jupyter Notebook home page, then click on index.ipynb to open it. We recommend including a longer description about what your package does, how to install it, and how to use it (with a few examples which import and use your package). Remember, examples can be code cells with real outputs rather than plain markdown text. Push to Github \u00a4 You can now commit and push your changes to GitHub. As we mentioned before, always remember to run nbdev_prepare before you commit to ensure your modules are exported and your tests pass. You can use git status to check which files have been generated or changed. Then: git add . git commit -m 'Add `say_hello`; update index' # Update this text with your own message git push This will kick-off your GitHub Actions. Wait a minute or two for those to complete, then check your updated repo and documentation. Recap \u00a4 Congratulations, you\u2019ve used all of the basics needed to build delightful projects with nbdev! Here\u2019s a recap of the steps you took: Installed hooks for git-friendly notebooks with nbdev_install_hooks Installed your package with pip install -e '.[dev]' Previewed your docs with nbdev_preview Added your own frontmatter, function, tests, and docs to 00_core.ipynb Prepared your changes with nbdev_prepare Updated index.ipynb with your own information Pushed to GitHub. Read on to learn about more advanced nbdev functionality. Also see our Explanations in the sidebar on the left for deep-dives on specific topics. Advanced functionality \u00a4 Add a class \u00a4 Create a class in 00_core.ipynb as follows: #| export class HelloSayer : \"Say hello to `to` using `say_hello`\" def __init__ ( self , to ): self . to = to def say ( self ): \"Do the saying\" return say_hello ( self . to ) This will automatically appear in the docs like this: HelloSayer \u00a4 HelloSayer (to) Say hello to to using say_hello Document with show_doc \u00a4 However, methods aren\u2019t automatically documented. To add method docs, use show_doc : show_doc ( HelloSayer . say ) HelloSayer.say \u00a4 HelloSayer.say () Do the saying And add some examples and/or tests: o = HelloSayer ( \"Alexis\" ) o . say () 'Hello Alexis!' Add links with backticks \u00a4 Notice above there is a link from our new class documentation to our function. That\u2019s because we used backticks in the docstring: \"Say hello to `to` using `say_hello`\" These are automatically converted to hyperlinks wherever possible. For instance, here are hyperlinks to HelloSayer and say_hello created using backticks. Set up autoreload \u00a4 Since you\u2019ll be often updating your modules from one notebook, and using them in another, it\u2019s helpful if your notebook automatically reads in the new modules as soon as the Python file changes. To make this happen, just add these lines to the top of your notebook: %load_ext autoreload %autoreload 2 Set up prerequisites \u00a4 If your module requires other modules as dependencies, you can add those prerequisites to your settings.ini in the requirements section. The requirements should be separated by a space and if the module requires at least or at most a specific version of the requirement this may be specified here, too. For example if your module requires the fastcore module of at least version 1.0.5, the torchvision module of at most version 0.7 and any version of matplotlib , then the prerequisites would look like this: requirements = fastcore >= 1.0.5 torchvision < 0.7 matplotlib In addition to requirements you can specify dependencies with other keywords that have different scopes. Below is a list of all possible dependency keywords: requirements : Passed to both pip and conda setup pip_requirements : Passed to pip setup only conda_requirements : Passed to conda setup only dev_requirements : Passed to pip setup as a development requirement For more information about the format of dependencies, see the pypi and conda docs on creating specifications in setup.py and meta.yaml , respectively. Set up console scripts \u00a4 Behind the scenes, nbdev uses that standard package setuptools for handling installation of modules. One very useful feature of setuptools is that it can automatically create cross-platform console scripts . nbdev surfaces this functionality; to use it, use the same format as setuptools , with whitespace between each script definition (if you have more than one). console_scripts = nbdev_export=nbdev.cli:nbdev_export Upload to pypi \u00a4 If you want people to be able to install your project by just typing pip install your-project then you need to upload it to pypi . The good news is, we\u2019ve already created a fully pypi compliant installer for your project! So all you need to do is register at pypi (click \u201cRegister\u201d on pypi) if you haven\u2019t previously done so, and then create a file called ~/.pypirc with your login details. It should have these contents: [pypi] username = your_pypi_username password = your_pypi_password Another thing you will need is twine , so you should run once pip install twine To upload your project to pypi, just type nbdev_pypi in your project root directory. Once it\u2019s complete, a link to your project on pypi is displayed. Upload to conda \u00a4 Similar to pip install support, we have provided an anaconda compliant installer to upload your project to anaconda . Once uploaded, your package can be installed by typing conda install -c your_anaconda_username your-project . You need to register at anaconda (fill out the form to Sign Up ) which will create a username and password. You will then need to install the following packages pip install anaconda-client conda-build conda-verify Before running the anaconda uploader, you need to login to conda using the CLI command (you will be prompted to enter your username and password) anaconda login To upload to anaconda, just type nbdev_conda in your project root directory. Upload to pypi and conda \u00a4 The command nbdev_release_both from the root of your nbdev repo will upload your project to both conda and pypi. Install collapsible headings and toc2 \u00a4 There are two jupyter notebook extensions that I highly recommend when working with projects like this. They are: Collapsible headings : This lets you fold and unfold each section in your notebook, based on its markdown headings. You can also hit left to go to the start of a section, and right to go to the end TOC2 : This adds a table of contents to your notebooks, which you can navigate either with the Navigate menu item it adds to your notebooks, or the TOC sidebar it adds. These can be modified and/or hidden using its settings. Math equation support \u00a4 nbdev supports equations (using Quarto ). You can include math in your notebook\u2019s documentation using the following methods. Using $$ , e.g.: $$\\sum_{i=1}^{k+1}i$$ Which is rendered as: \\[\\sum_{i=1}^{k+1}i\\] Using $ , e.g.: This version is displayed inline: $\\sum_{i=1}^{k+1}i$ . You can include text before and after. Which is rendered as: This version is displayed inline: \\(\\sum_{i=1}^{k+1}i\\) . You can include text before and after. For more information, see the Quarto Docs Look at nbdev \u201csource\u201d for more ideas \u00a4 Don\u2019t forget that nbdev itself is written in nbdev! It\u2019s a good place to look to see how fast.ai uses it in practice, and get a few tips. You\u2019ll find the nbdev notebooks here in the nbs folder on Github. Quarto Features \u00a4 nbdev supports most Quarto features. We encourage you to read the Quarto documentation to discover all the features available to you. For example, this is how you can incorporate mermaid charts : Here is another example of using Graphviz : It is worth taking a look at the documentation for figures , callouts , markdown , widgets , layouts , conditional content and quarto extensions to name a few useful things we have encountered.","title":"End-To-End Walkthrough"},{"location":"tutorials/tutorial/#end-to-end-walkthrough","text":"The written tutorial below shows you how to create a Python package from scratch using nbdev. Alternatively, you can watch this video tutorial where Jeremy Howard and Hamel Husain guide you through a similar process step by step:","title":"End-To-End Walkthrough"},{"location":"tutorials/tutorial/#installation","text":"You\u2019ll need the following software to complete the tutorial, read on for specific installation instructions: Python A Python package manager: we recommend conda or pip Jupyter Notebook nbdev Quarto If you haven\u2019t worked with Python before, we recommend getting started with the Anaconda Individual Edition and using the conda package manager.","title":"Installation"},{"location":"tutorials/tutorial/#install-jupyter-notebook","text":"Launch a terminal and install Jupyter Notebook by entering: conda install notebook \u2026or pip install notebook \u2026if you\u2019re using the pip package manager. Enter y (for yes) if prompted. Installation should take a few seconds, during which text will be printed in the terminal. You\u2019ll know its completed when you see the terminal prompt and are able to type again. You can now launch Jupyter by entering: jupyter notebook This should open the Jupyter home page in a new browser tab: > **Why not Jupyter Lab?** > > As Jupyter power users we still prefer Jupyter Notebook (with > [customizations](#install-collapsible-headings-and-toc2)) over more > feature-full alternatives like Jupyter Lab, VSCode, or PyCharm. We > find Jupyter Notebook simpler, faster, and more robust.","title":"Install Jupyter Notebook"},{"location":"tutorials/tutorial/#install-nbdev","text":"The next step is to install nbdev itself. Jupyter Notebook comes with its own terminal, so we\u2019ll use that moving forward. In the Jupyter home page (shown in the previous section), click the \u201cNew\u201d dropdown on the right side, then \u201cTerminal\u201d. A browser tab should open with a blank terminal: Enter: conda install -c fastai nbdev \u2026or pip install nbdev \u2026if you\u2019re using pip. Type y (for yes) when prompted, and wait a few seconds until nbdev is installed.","title":"Install nbdev"},{"location":"tutorials/tutorial/#install-quarto","text":"nbdev provides a command to install the latest version of Quarto. In the terminal, enter: nbdev_install_quarto Your password may be requested at this point. Since nbdev is open source, you can read the source code of this command to verify that it isn\u2019t doing anything malicious. Or, if you prefer, you may instead follow Quarto\u2019s official installation instructions .","title":"Install Quarto"},{"location":"tutorials/tutorial/#first-steps","text":"By the end of this section you\u2019ll have your own nbdev repo with tests, continuous integration, streamlined PyPI & conda packaging, and a documentation website.","title":"First steps"},{"location":"tutorials/tutorial/#create-an-empty-github-repo","text":"Create an empty GitHub repo using the convenient link github.com/new . If you get stuck, you might find GitHub\u2019s Create a repo page helpful. Remember to add a description, since nbdev will use that later. Don\u2019t add a README file, .gitignore, or license file just yet. If you\u2019re using the web interface, it should look something like this before you click \u201cCreate Repository\u201d: You should then be redirected to your new repo: > **Try GitHub\u2019s powerful CLI** > > GitHub\u2019s web interface is a great way to get started. As you grow more > experienced, you might want to explore [the GitHub > CLI](https://github.com/cli/cli) (command line interface). We often > prefer to use command line tools for repetitive tasks where we\u2019re > likely to make mistakes. Having those tasks written as small scripts > in your terminal means that you can repeat them with little effort.","title":"Create an empty GitHub repo"},{"location":"tutorials/tutorial/#initialise-your-repo-with-nbdev","text":"Now clone your repo from the Jupyter terminal you started earlier (or create a new terminal following those instructions if needed). If you get stuck here, you might find GitHub\u2019s Cloning a repository page helpful. Since we created a repo named nbev-hello-world with the fastai user, we can clone it as follows: git clone https://github.com/fastai/nbdev-hello-world.git Then cd (change directory) to our repo: cd nbdev-hello-world You may have seen this message while cloning: You appear to have cloned an empty repository. \u2026since the repo is completely empty. Let\u2019s add some files! nbdev provides the nbdev_new command to initialise an empty git repository. It\u2019ll infer information about your project from git and GitHub, and ask you to input anything remaining. It will create files in your repo that: Streamline publishing Python packages to PyPI and conda. Configure Quarto for publication-grade technical documentation. Setup GitHub actions to test notebooks and build and deploy Quarto docs to GitHub pages. Initialise your nbdev repo by entering: nbdev_new It may ask you to enter information that it couldn\u2019t infer from git or GitHub. > **Note** > > [`nbdev_new`](https://nbdev.fast.ai/api/cli.html#nbdev_new) assumes > that your package name is the same as your repo name (with `-` > replaced by `_`). Use the `--lib_name` option if that isn\u2019t the case. Double-check your settings.ini file to ensure that it has all of the correct information. Then commit and push your additions to GitHub: git add . git commit -m 'Initial commit' git push It\u2019s time to see all of the goodies nbdev gives you!","title":"Initialise your repo with nbdev"},{"location":"tutorials/tutorial/#check-out-your-workflows","text":"Open GitHub Actions by clicking the \u201cActions\u201d tab near the top of your repo page. You should see two workflow runs: If you opened this page shortly after pushing your initial commit, the runs may not have a green check (\u2705) because they\u2019re still \u201cIn progress\u201d or \u201cQueued\u201d. That\u2019s no problem, they shouldn\u2019t take much more than a minute to complete. If you see a red cross (\u274c), that means something failed. Click on the cross, then click Details , and you\u2019ll be able to see what failed. If you can\u2019t figure out what\u2019s wrong, search the forum in case someone else resolved the same issue, otherwise create a new post describing your issue in as much detail as you can, and we\u2019ll try our best to help you. Remember that including a link to an actual repo and/or GitHub Action is the best way for us to quickly identify what\u2019s wrong. What do these workflows do? CI \u2013 The CI (continuous integration) workflow streamlines your developer workflow, particularly with multiple collaborators. Every time you push to GitHub, it ensures that: Your notebooks and libraries are in sync Your notebooks are cleaned of unwanted metadata (which pollute pull requests and git histories and lead to merge conflicts) Your notebook tests all pass Deploy to GitHub Pages \u2013 Builds your docs with Quarto and deploys it to GitHub Pages. We provide these basic workflows out-of-the-box, however, you can edit their corresponding YAML files in the .github/workflows/ folder to your liking. Note that you\u2019ll need to enable GitHub Pages for your repo before you can access your docs website. We\u2019ll do that now.","title":"Check out your workflows"},{"location":"tutorials/tutorial/#check-out-your-docs","text":"nbdev hosts your docs on GitHub Pages\u2014an excellent (and free!) way to host websites.","title":"Check out your docs"},{"location":"tutorials/tutorial/#enabling-github-pages","text":"> **Enabling GitHub Pages Is Not Required For Everyone** > > nbdev makes a best effort to automatically enable GitHub Pages for > you, however, there some cases where this is not possible such as > private repos or where your organization\u2019s permissions are restricted. > If you are having trouble seeing your site, we suggest checking if > Pages are enabled for your repo by following the below instructions. > > You can enable it for your repo by clicking on the \u201cSettings\u201d tab near > the top-right of your repo page, then \u201cPages\u201d on the left, then > setting the \u201cBranch\u201d to \u201cgh-pages\u201d, and finally clicking \u201cSave\u201d. > > It should look similar to this after you click \u201cSave\u201d: > > class=\"pb-2 border rounded shadow-sm\" data-fig-align=\"center\" /> Head back to GitHub Actions and you should see a new workflow run: \u201cpages build and deployment\u201d. As the name says, this workflow deploys your website contents to GitHub Pages. Wait for the workflow run to complete, then open your website. By default it should be available at: https://{user}.github.io/{repo} . For example, you can view fastai \u2019s nbdev-hello-world docs at https://fastai.github.io/nbdev-hello-world . > **Note** > > nbdev uses GitHub Pages by default because its easily accessible. > However, you can use any host you like. See [these > docs](../explanations/docs.ipynb#deploying-your-docs-on-other-platforms) > for more information on this.","title":"Enabling GitHub Pages"},{"location":"tutorials/tutorial/#recap","text":"You now have a base nbdev repo with continuous integration and hosted documentation! Here\u2019s a recap of the steps you took: Created a GitHub repo Initialised your repo with nbdev_new Pushed to GitHub.","title":"Recap"},{"location":"tutorials/tutorial/#make-your-first-edit","text":"In this section, you\u2019ll make your first edit to the repo you created in First steps .","title":"Make your first edit"},{"location":"tutorials/tutorial/#install-hooks-for-git-friendly-notebooks","text":"Step one when working with Jupyter notebooks in a new repo is to install nbdev\u2019s hooks (you can think of \u201chooks\u201d as plugins or extensions to an application). Install them by entering this command in your terminal: nbdev_install_hooks > **Note** > > The [clean hook](#nbdev_clean-on-saving-notebooks-in-jupyter) > currently only supports Jupyter Notebook and Jupyter Lab. If you\u2019re > using another notebook editor, like VSCode or PyCharm, you might want > to use [nbdev\u2019s pre-commit hooks](/tutorials/pre_commit.ipynb) as > well. See Git-friendly Jupyter for more about how nbdev hooks work and how to customise them. Here\u2019s a short summary: Fix broken notebooks due to git merge conflicts so that they can be opened and resolved directly in Jupyter. Each time you save a Jupyter notebook, automatically clean unwanted metadata to remove unnecessary changes in pull requests and reduce the chance of git merge conflicts. Automatically trust notebooks in the repo so that you can view widgets from collaborators\u2019 commits. For this reason, you should not install hooks into a repo you don\u2019t trust . > **Tip** > > nbdev hooks works on *any* git repo, even if it doesn\u2019t use the > broader nbdev system.","title":"Install hooks for git-friendly notebooks"},{"location":"tutorials/tutorial/#build-your-library","text":"You should now create your package from your notebook by running: nbdev_export This will create Python modules for your notebooks. These modules will make up the contents of your Python package.","title":"Build your library"},{"location":"tutorials/tutorial/#install-your-package","text":"You might have noticed that nbdev_new created a Python package in your repo. In our case, it was automatically named nbdev_hello_world by using our repo name nbdev-hello-world and replacing - with _ to make it a valid Python package. The next step is to install your package by entering this into your terminal: pip install -e '.[dev]' This is the recommended way to make a Python package importable from anywhere in your current environment: -e \u2013 short for \u201ceditable\u201d, lets you immediately use changes made to your package during development. . \u2013 refers to the current directory. [dev] \u2013 includes \u201cdevelopment\u201d requirements: other packages that your notebooks use solely for documentation or testing.","title":"Install your package"},{"location":"tutorials/tutorial/#preview-your-docs","text":"nbdev is an interactive programming environment that values fast feedback loops. The nbdev_preview command helps achieve this by using Quarto to render your docs on your computer and keep them updated as your edit your notebooks. Start the preview by entering this into your terminal: nbdev_preview It may say Preparing to preview for a few seconds while it gets started, and will eventually display something like: Watching files for changes Browse at http://localhost:3000/ Click the link to open the preview in a new browser tab. It should look exactly like your online docs. > **Tip** > > We often find it useful to keep a preview window open on the side > while we\u2019re editing our notebooks in Jupyter.","title":"Preview your docs"},{"location":"tutorials/tutorial/#edit-00_coreipynb","text":"Now, run jupyter notebook , and click 00_core.ipynb (note: if you started this tutorial using nbdev_new then this file will be in the nbs folder). You don\u2019t have to start your notebook names with a number, but we find it helpful to show the order that your project should be read in \u2013 even though it could have been created in a different order.","title":"Edit 00_core.ipynb"},{"location":"tutorials/tutorial/#add-your-own-frontmatter","text":"You\u2019ll see something that looks a bit like this: **core** > Fill in a module description here #| default_exp core Let\u2019s explain what these special cells means: The first is a markdown cell with nbdev\u2019s markdown frontmatter syntax that defines notebook metadata used by Quarto, our documentation engine (see the frontmatter reference page for more). It contains: H1 header (\u201ccore\u201d) \u2013 defining the page title Quote (\u201cFill in a module description here\u201d) \u2013 defining the page description The second is a code cell with a directive default_exp which decides which module this notebook will export to (see the Directives explanation for more). Currently, it exports to the core module. Next, rename the notebook, replace the title and description, and change the default export module for your own project. Once you\u2019re done, save the notebook. The live preview started in the previous section should update with your latest changes. Rerun all cells in your notebook to ensure that they work, and to export the updated modules. > **Tip** > > We find the \u201crestart kernel and run all cells\u201d Jupyter command (the \u23e9 > button) so invaluable that we bind it to a keyboard shortcut. A common > criticism of notebooks is that out-of-order execution leads to > irreproducible notebooks. In our experience, making \u201crestart and > rerun\u201d a habit solves this problem. Running the notebook exports Python modules because of the last cell which contains: #| hide import nbdev ; nbdev . nbdev_export () What does this mean? #| hide is a directive (like #| default_exp ) which excludes a cell from both your exported module and docs nbdev_export is the command used to export your notebooks to Python modules. We recommend including a cell like this at the bottom of all of the notebooks you want to export. > **Warning** > > Remember to delete any unused modules that aren\u2019t exported by a > notebook or otherwise needed by your package. This is likely to happen > if you change the default export of a notebook \u2013 nbdev doesn\u2019t remove > the old module. This is intended, since nbdev is designed to work with > hybrid packages that use .py modules (with no corresponding notebook) > as well as those exported from notebooks.","title":"Add your own frontmatter"},{"location":"tutorials/tutorial/#add-your-own-function","text":"Add a new code cell below the #| default_exp cell with a function. For example: #| export def say_hello ( to ): \"Say hello to somebody\" return f 'Hello { to } !' Notice how it includes #| export at the top \u2013 this is a directive (like #| default_exp ) that tells nbdev to include the cell in your exported module and in your documentation. The documentation should look like this: ------------------------------------------------------------------------ source ### say_hello > say_hello (to) Say hello to somebody","title":"Add your own function"},{"location":"tutorials/tutorial/#add-your-own-examples-tests-and-docs","text":"One of the superpowers of notebook-driven development is that you can very easily add examples, tests, and documentation right below your code. Include regular code cells, and they\u2019ll appear (with output) in your docs, for example: say_hello ( \"Isaac\" ) 'Hello Isaac!' This is a test too! When you run nbdev_test it will execute this cell (and all other test cells) and fail if they raise any exceptions. For tests, it\u2019s preferred to use more explicit assert s: assert say_hello ( \"Hamel\" ) == \"Hello Hamel!\" \u2026or functions from fastcore.test , which behave like assert but also display the actual and expected values if they differ: from fastcore.test import * test_eq ( say_hello ( \"Hamel\" ), \"Hello Hamel!\" ) Another superpower of notebook-driven development is that your examples can include plots, images, and even JavaScript widgets. For example, here\u2019s an SVG circle: from IPython.display import display , SVG display ( SVG ( '<svg height=\"100\" xmlns=\"http://www.w3.org/2000/svg\"><circle cx=\"50\" cy=\"50\" r=\"40\"/></svg>' ))","title":"Add your own examples, tests, and docs"},{"location":"tutorials/tutorial/#prepare-your-changes","text":"Before commiting your changes to GitHub we recommend running nbdev_prepare in the terminal, which bundles the following commands: nbdev_export : Builds the .py modules from Jupyter notebooks nbdev_test : Tests your notebooks nbdev_clean : Cleans your notebooks to get rid of extreanous output for Github nbdev_readme : Updates README.md from your index notebook.","title":"Prepare your changes"},{"location":"tutorials/tutorial/#edit-indexipynb","text":"Now you\u2019re ready to create your documentation home page and README.md file; these are both generated automatically from index.ipynb. Open the Jupyter Notebook home page, then click on index.ipynb to open it. We recommend including a longer description about what your package does, how to install it, and how to use it (with a few examples which import and use your package). Remember, examples can be code cells with real outputs rather than plain markdown text.","title":"Edit index.ipynb"},{"location":"tutorials/tutorial/#push-to-github","text":"You can now commit and push your changes to GitHub. As we mentioned before, always remember to run nbdev_prepare before you commit to ensure your modules are exported and your tests pass. You can use git status to check which files have been generated or changed. Then: git add . git commit -m 'Add `say_hello`; update index' # Update this text with your own message git push This will kick-off your GitHub Actions. Wait a minute or two for those to complete, then check your updated repo and documentation.","title":"Push to Github"},{"location":"tutorials/tutorial/#recap_1","text":"Congratulations, you\u2019ve used all of the basics needed to build delightful projects with nbdev! Here\u2019s a recap of the steps you took: Installed hooks for git-friendly notebooks with nbdev_install_hooks Installed your package with pip install -e '.[dev]' Previewed your docs with nbdev_preview Added your own frontmatter, function, tests, and docs to 00_core.ipynb Prepared your changes with nbdev_prepare Updated index.ipynb with your own information Pushed to GitHub. Read on to learn about more advanced nbdev functionality. Also see our Explanations in the sidebar on the left for deep-dives on specific topics.","title":"Recap"},{"location":"tutorials/tutorial/#advanced-functionality","text":"","title":"Advanced functionality"},{"location":"tutorials/tutorial/#add-a-class","text":"Create a class in 00_core.ipynb as follows: #| export class HelloSayer : \"Say hello to `to` using `say_hello`\" def __init__ ( self , to ): self . to = to def say ( self ): \"Do the saying\" return say_hello ( self . to ) This will automatically appear in the docs like this:","title":"Add a class"},{"location":"tutorials/tutorial/#hellosayer","text":"HelloSayer (to) Say hello to to using say_hello","title":"HelloSayer"},{"location":"tutorials/tutorial/#document-with-show_doc","text":"However, methods aren\u2019t automatically documented. To add method docs, use show_doc : show_doc ( HelloSayer . say )","title":"Document with show_doc"},{"location":"tutorials/tutorial/#hellosayersay","text":"HelloSayer.say () Do the saying And add some examples and/or tests: o = HelloSayer ( \"Alexis\" ) o . say () 'Hello Alexis!'","title":"HelloSayer.say"},{"location":"tutorials/tutorial/#add-links-with-backticks","text":"Notice above there is a link from our new class documentation to our function. That\u2019s because we used backticks in the docstring: \"Say hello to `to` using `say_hello`\" These are automatically converted to hyperlinks wherever possible. For instance, here are hyperlinks to HelloSayer and say_hello created using backticks.","title":"Add links with backticks"},{"location":"tutorials/tutorial/#set-up-autoreload","text":"Since you\u2019ll be often updating your modules from one notebook, and using them in another, it\u2019s helpful if your notebook automatically reads in the new modules as soon as the Python file changes. To make this happen, just add these lines to the top of your notebook: %load_ext autoreload %autoreload 2","title":"Set up autoreload"},{"location":"tutorials/tutorial/#set-up-prerequisites","text":"If your module requires other modules as dependencies, you can add those prerequisites to your settings.ini in the requirements section. The requirements should be separated by a space and if the module requires at least or at most a specific version of the requirement this may be specified here, too. For example if your module requires the fastcore module of at least version 1.0.5, the torchvision module of at most version 0.7 and any version of matplotlib , then the prerequisites would look like this: requirements = fastcore >= 1.0.5 torchvision < 0.7 matplotlib In addition to requirements you can specify dependencies with other keywords that have different scopes. Below is a list of all possible dependency keywords: requirements : Passed to both pip and conda setup pip_requirements : Passed to pip setup only conda_requirements : Passed to conda setup only dev_requirements : Passed to pip setup as a development requirement For more information about the format of dependencies, see the pypi and conda docs on creating specifications in setup.py and meta.yaml , respectively.","title":"Set up prerequisites"},{"location":"tutorials/tutorial/#set-up-console-scripts","text":"Behind the scenes, nbdev uses that standard package setuptools for handling installation of modules. One very useful feature of setuptools is that it can automatically create cross-platform console scripts . nbdev surfaces this functionality; to use it, use the same format as setuptools , with whitespace between each script definition (if you have more than one). console_scripts = nbdev_export=nbdev.cli:nbdev_export","title":"Set up console scripts"},{"location":"tutorials/tutorial/#upload-to-pypi","text":"If you want people to be able to install your project by just typing pip install your-project then you need to upload it to pypi . The good news is, we\u2019ve already created a fully pypi compliant installer for your project! So all you need to do is register at pypi (click \u201cRegister\u201d on pypi) if you haven\u2019t previously done so, and then create a file called ~/.pypirc with your login details. It should have these contents: [pypi] username = your_pypi_username password = your_pypi_password Another thing you will need is twine , so you should run once pip install twine To upload your project to pypi, just type nbdev_pypi in your project root directory. Once it\u2019s complete, a link to your project on pypi is displayed.","title":"Upload to pypi"},{"location":"tutorials/tutorial/#upload-to-conda","text":"Similar to pip install support, we have provided an anaconda compliant installer to upload your project to anaconda . Once uploaded, your package can be installed by typing conda install -c your_anaconda_username your-project . You need to register at anaconda (fill out the form to Sign Up ) which will create a username and password. You will then need to install the following packages pip install anaconda-client conda-build conda-verify Before running the anaconda uploader, you need to login to conda using the CLI command (you will be prompted to enter your username and password) anaconda login To upload to anaconda, just type nbdev_conda in your project root directory.","title":"Upload to conda"},{"location":"tutorials/tutorial/#upload-to-pypi-and-conda","text":"The command nbdev_release_both from the root of your nbdev repo will upload your project to both conda and pypi.","title":"Upload to pypi and conda"},{"location":"tutorials/tutorial/#install-collapsible-headings-and-toc2","text":"There are two jupyter notebook extensions that I highly recommend when working with projects like this. They are: Collapsible headings : This lets you fold and unfold each section in your notebook, based on its markdown headings. You can also hit left to go to the start of a section, and right to go to the end TOC2 : This adds a table of contents to your notebooks, which you can navigate either with the Navigate menu item it adds to your notebooks, or the TOC sidebar it adds. These can be modified and/or hidden using its settings.","title":"Install collapsible headings and toc2"},{"location":"tutorials/tutorial/#math-equation-support","text":"nbdev supports equations (using Quarto ). You can include math in your notebook\u2019s documentation using the following methods. Using $$ , e.g.: $$\\sum_{i=1}^{k+1}i$$ Which is rendered as: \\[\\sum_{i=1}^{k+1}i\\] Using $ , e.g.: This version is displayed inline: $\\sum_{i=1}^{k+1}i$ . You can include text before and after. Which is rendered as: This version is displayed inline: \\(\\sum_{i=1}^{k+1}i\\) . You can include text before and after. For more information, see the Quarto Docs","title":"Math equation support"},{"location":"tutorials/tutorial/#look-at-nbdev-source-for-more-ideas","text":"Don\u2019t forget that nbdev itself is written in nbdev! It\u2019s a good place to look to see how fast.ai uses it in practice, and get a few tips. You\u2019ll find the nbdev notebooks here in the nbs folder on Github.","title":"Look at nbdev \u201csource\u201d for more ideas"},{"location":"tutorials/tutorial/#quarto-features","text":"nbdev supports most Quarto features. We encourage you to read the Quarto documentation to discover all the features available to you. For example, this is how you can incorporate mermaid charts : Here is another example of using Graphviz : It is worth taking a look at the documentation for figures , callouts , markdown , widgets , layouts , conditional content and quarto extensions to name a few useful things we have encountered.","title":"Quarto Features"}]}